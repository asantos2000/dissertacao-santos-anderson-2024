@inproceedings{10.1145/2002259.2002281,
author = {Linehan, Mark H. and Dehors, Sylvain and Rabinovich, Ella and Fournier, Fabiana},
title = {Controlled english language for production and event processing rules},
year = {2011},
isbn = {9781450304238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2002259.2002281},
doi = {10.1145/2002259.2002281},
abstract = {In recent years, event processing has matured from an emerging technology to one with pervasive uses in various industries. There is a growing segment of applications comprising a diversity of rule types that are developed by high-level users, who have business logic and process expertise rather than software development skills.Technical rule languages for business (production) rules systems differ from event processing rules because they target different execution modes. Corresponding differences exist in the respective rule languages employed to date. This paper describes an integrated rule language that supports both kinds of rules, thus enabling business applications that combine them. The integrated language targets non-technical "business users" who write rules that employ both production and event processing rule functions.The language proposed here is a textual "controlled natural language" based on the Semantics of Business Vocabulary and Business Rules (SBVR) specification of the Object Management Group (OMG). We describe an implementation that uses an SBVR parser, and an SBVR "vocabulary" that defines the syntax and semantics for event processing rules. The parser treats business rule and event processing concepts indifferently, and can be extended to other language concepts by additional vocabularies. Knowledge of the event processing aspects is limited to a conversion utility that transforms rules written using this language to an event processing network.},
booktitle = {Proceedings of the 5th ACM International Conference on Distributed Event-Based System},
pages = {149–158},
numpages = {10},
keywords = {structured english, semantics of business vocabulary and business rules, sbvr, event processing language, controlled natural language, complex event processing},
location = {New York, New York, USA},
series = {DEBS '11}
}

@inproceedings{10.5555/3101290.3101300,
author = {Siqueira, Fabio Levy and de Sousa, Thiago C. and Silva, Paulo S. Muniz},
title = {Using BDD and SBVR to refine business goals into an event-B model: a research idea},
year = {2017},
isbn = {9781538604229},
publisher = {IEEE Press},
abstract = {The transition from a requirements document to a formal specification in Event-B is usually manual and ad-hoc. In order to bridge this gap, we propose a method based on Behavior-Driven Development, an agile approach, and that uses a structured natural language conformant to the formalism of the Semantics of Business Vocabulary and Business Rules (SBVR) standard. This method will successively refine a list of high-level business goals into an Event-B model using transformations. In this paper we present our research idea, describing the steps of this method and showing an example based on the Train System scenario described by Abrial.},
booktitle = {Proceedings of the 5th International FME Workshop on Formal Methods in Software Engineering},
pages = {31–36},
numpages = {6},
keywords = {requirements, method, formal methods, event-B, SBVR, BDD},
location = {Buenos Aires, Argentina},
series = {FormaliSE '17}
}

@inproceedings{10.1145/1953355.1953363,
author = {Agrawal, Ashish},
title = {Semantics of business process vocabulary and process rules},
year = {2011},
isbn = {9781450305594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1953355.1953363},
doi = {10.1145/1953355.1953363},
abstract = {Semantics of Business Vocabulary and Business Rules (SBVR), an OMG standard, provides a meta-model for the semantic and declarative models of business vocabulary and business rules. Logical formulation of SBVR facilitates IT people to interpret these models generated by business people. However, an important aspect of a business is process model, and it is outside the scope of SBVR. Knowledge intensive and dynamic nature of business processes require such a declarative meta-model for process modeling in order to provide flexibility and adaptability. In this work, an approach for process modeling using SBVR's methodology is proposed. We have made an initial attempt to define a declarative meta-model, Semantics of Business Process Vocabulary and Process Rules (SBPVR). SBPVR divides knowledge of business processes into three parts; process concept types, process fact types and process rules. Process concept types and fact types represent structure of processes and process rules provide guidance over the structure and flow of processes at execution time. In the paper, these types are further categorized to represent the various elements of process models. SBPVR provides flexibility and adaptability to the process model through its declarative nature and fact oriented approach.},
booktitle = {Proceedings of the 4th India Software Engineering Conference},
pages = {61–68},
numpages = {8},
keywords = {process design methods and methodologies, fact oriented modeling, SBVR},
location = {Thiruvananthapuram, Kerala, India},
series = {ISEC '11}
}

@inproceedings{10.1145/3368640.3368641,
author = {Danenas, Paulius and Skersys, Tomas and Butleris, Rimantas},
title = {Enhancing the extraction of SBVR business vocabularies and business rules from UML use case diagrams with natural language processing},
year = {2019},
isbn = {9781450372923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368640.3368641},
doi = {10.1145/3368640.3368641},
abstract = {Being among the best-selling and most advanced features of model-driven development, model-to-model transformation could help improving one of the most time- and resource-consuming efforts in the process of model-driven information systems engineering, namely, discovery and specification of business vocabularies and business rules within the problem domain. Nonetheless, despite the relatively high levels of automation throughout the whole systems' model-driven development process, business modeling stage remains among the most under re-searched areas throughout the whole process. In this paper, we introduce a novel natural language processing (NLP) technique to one of our latest developments for the automatic extraction of SBVR business vocabularies and business rules from UML use case diagrams. This development remains arguably the most comprehensive development of this kind currently available in public. The experiment provided proof that the developed NLP enhancement delivered even better extraction results compared to the already satisfactory performance of the previous development. This work contributes to the research in the areas of model transformations and NLP within the model-driven development of information systems, and beyond.},
booktitle = {Proceedings of the 23rd Pan-Hellenic Conference on Informatics},
pages = {1–8},
numpages = {8},
keywords = {use case diagram, natural language processing, model transformation, business vocabulary, business rules, UML, SBVR},
location = {Nicosia, Cyprus},
series = {PCI '19}
}

@article{10.1145/3397619.3397623,
author = {Calvanese, Diego and Fodor, Paul and Montali, Marco},
title = {Report on the 3rd International Joint Conference on Rules and Reasoning (RuleML+RR 2019)},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3397619.3397623},
doi = {10.1145/3397619.3397623},
abstract = {The annual International Joint Conference on Rules and Reasoning (RuleML+RR) is an international conference on research, applications, languages and standards for rule technologies, rule-based programming and rule-based systems including production rules systems, logic programming rule engines, as well as business-rule engines and management systems; Semantic Web rule languages and rule standards, including RuleML (e.g., Datalog+ RuleML, Reaction RuleML and LegalRuleML), SWRL, RIF, Common Logic, PRR, decision rules and Decision Model and Notation (DMN), as well as Semantics of Business Vocabulary and Business Rules (SBVR); rule-based Event Processing Languages (EPLs) and technologies; and foundational research on inference rules, transformation rules, decision rules, production rules, and Event-Condition-Action (ECA) rules. In 2017, RuleML+RR joined the efforts of two wellestablished conference series: the International Web Rule Symposia (RuleML) and the Web Reasoning and Rule Systems (RR) conferences, and it is now the leading conference to build bridges between academia and industry in the field of Web rules and its applications, especially as part of the Semantic Technology stack. RuleML+RR is commonly listed together with and related to other major high-impact Artificial Intelligence conferences worldwide, starting with IJCAI in 2011 and 2016, ECAI in 2012, AAAI in 2013, ECAI in 2014, the AI Summit London in 2017, and GCAI in 2018 and 2019. The RuleML symposia and RR conferences have been held since 2002 and 2007, respectively. The RR conferences have been a forum for discussion and dissemination of new results on Web reasoning and rule systems, with an emphasis on rule-based approaches and languages. The RuleML symposia have been devoted to disseminating research, applications, languages, and standards for rule technologies, with attention to both theoretical and practical developments, to challenging new ideas, and to industrial applications. Building on the tradition of both, RuleML and RR, the joint conference series RuleML+RR aims at bridging academia and industry in the field of rules, and at fostering the cross-fertilization between the different communities focused on the research, development, and applications of rule-based systems. RuleML+RR aims at being the leading conference series for all subjects concerning theoretical advances, novel technologies, and innovative applications about knowledge representation and reasoning with rules.},
journal = {ACM SIGLOG News},
month = {apr},
pages = {16–18},
numpages = {3}
}

@inproceedings{10.5555/1386957.1386977,
author = {zur Muehlen, Michael and Indulska, Marta and Kamp, Gerrit},
title = {Business process and business rule modeling languages for compliance management: a representational analysis},
year = {2007},
isbn = {9781920682644},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Organizations are under increasing scrutiny to document their compliance to regulatory requirements. To this end, they have to formally document their operating procedures to support their compliance management efforts. Both process modeling languages and rule modeling languages are candidates for the documentation of organizational policies and procedures. While both types of languages are currently used to document organizational practices, little work has been done to understand their synergies and overlap. Accordingly, in this paper we use the Bunge-Wand-Weber (BWW) representation theory as a basis for such an analysis. We perform a representational analysis of two popular rule modeling languages, viz., SRML and SBVR. We compare their representation capabilities with those of four popular conceptual business process modeling languages, and focus on the aspects of maximum ontological completeness and minimum ontological overlap. The outcome of this study shows that a combination of two languages, viz. SRML and BPMN, is more suitable for documenting compliance than any single modeling language, and that the combination of process and rule modeling languages shows synergies.},
booktitle = {Tutorials, Posters, Panels and Industrial Contributions at the 26th International Conference on Conceptual Modeling - Volume 83},
pages = {127–132},
numpages = {6},
location = {<conf-loc>, <city>Auckland</city>, <country>New Zealand</country>, </conf-loc>},
series = {ER '07}
}

@inproceedings{10.5555/2093889.2093932,
author = {Rubiera, Emilio and de Sainte Marie, Christian},
title = {ONTORULE: from business knowledge to ontology- and rules-based applications},
year = {2011},
publisher = {IBM Corp.},
address = {USA},
abstract = {The development of a business rule application involves many different people, from the business owners of the rules to the IT developers of the application. It also involves many different kinds of knowledge, from the trade and organisation specific vocabularies to the inside working of the inference engines.In the recent years, advances in standardization of modeling and knowledge representation languages and in methodologies and theoretical foundations for policy acquisition and execution made it increasingly feasible to reduce the coupling between policies and their implementations, and to empower users to independently interact with the part of a business application that is relevant to them, including the decision modeling processThe objective of ONTORULE is to enable users, from business executives over business analysts to IT developers, to interact in their own way with the part of a business application that is relevant to them.We believe that one essential step towards achieving that objective is the ability to separate cleanly the domain ontology from the actual business rules, on the one hand; and the representation of the knowledge from its operationalization in IT applications, on the other hand.Leading vendors of knowledge-based and business rules management systems and top research institutions join their efforts, in the EC-funded ONTORULE project The ONTORULE project is partially funded by the European Commission under Grant Agreement n° 231875., to develop the integrated technology that will empower business professionals in the knowledge economy of the future.Today, the development of business rules application is usually approached with a heavy IT bias, if only because it starts, most often, with the specification of the application data model.Starting with the application data model has at least two negative consequences, from the ONTORULE point of view:1. part of the domain knowledge is embedded into the implementation dependent data model;2. the part of the domain knowledge that cannot be fit into the data model end up being mixed with the operational rules.The implementation dependent representation of the domain knowledge is not easily accessible to its business owner, nor to the business user in general. As a consequence, starting with the application data model amounts to transfer the ownership (maintenance, evolution) of the domain knowledge to the IT department.On the other hand, the absence of a clean separation between the conceptual and structural domain knowledge and the operational business rules makes sharing and re-use more difficult, because they have different scopes; it makes maintenance and evolution more risky, because they have different life cycles; and it makes the different kinds and forms of knowledge less accessible to their respective owners.The ONTORULE project is motivated by the belief that the development of business rule applications must start from the business knowledge, not from the IT application. If the knowledge is to be owned by the business user, it must be based on the business user's own concepts and vocabulary. The approach must support the acquisition of the knowledge from business people and policy documents, and its maintenance and management by business people for business people.The other key is to keep the conceptual domain model separate from the business policies and from the operational rules for acquisition, maintenance and re-use purposes, but to recombine them effectively in applications.ONTORULE puts semantic technologies to action to build effective bridges between the textual sources, the less structured and less formal representations that are preferred by the business users, and the different kinds of formal knowledge that computers can process, thus empowering the various business users and the IT developers to manage change and complexity.},
booktitle = {Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {327–329},
numpages = {3},
location = {Toronto, Ontario, Canada},
series = {CASCON '11}
}

@inproceedings{10.1145/1643823.1643886,
author = {Marinos, Alexandros and Moschoyiannis, Sotiris and Krause, Paul},
title = {Towards a RESTful infrastructure for digital ecosystems},
year = {2009},
isbn = {9781605588292},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1643823.1643886},
doi = {10.1145/1643823.1643886},
abstract = {In this paper, we describe key design aspects of digital ecosystems and how these can be realised in a web-like environment. In previous work we have discussed digital ecosystems in terms of digital infrastructures and the socio-economic context in which these are called to operate. We have framed the concept of a digital ecosystem around complex interactions between interdependent agents and have focused the discussion on important properties such as loose-coupling, no central point of control or failure, sustainability, resilience, and history. In this paper we describe an integrated set of design solutions for operationalising the key principles of digital ecosystems into a software infrastructure. The proposed reference architecture drives the construction of RESTful ecosystems that can support future internet applications, and do this in a way that is backwards compatible with the current web.},
booktitle = {Proceedings of the International Conference on Management of Emergent Digital EcoSystems},
articleno = {51},
numpages = {5},
keywords = {digital ecosystems, complex systems, architecture, REST},
location = {France},
series = {MEDES '09}
}

@inproceedings{10.1145/1774088.1774119,
author = {Meertens, L. O. and Iacob, M. E. and Nieuwenhuis, L. J. M.},
title = {Goal and model driven design of an architecture for a care service platform},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774119},
doi = {10.1145/1774088.1774119},
abstract = {Service-Oriented Architecture holds the potential of allowing the development on-the-fly of flexible applications that can adapt rapidly by combining and reusing existing services. We believe that in order to react swiftly and coherently to changes, an architecture must provide a capability to capture how services, and the more complex applications based on them, realize business motivations. This research develops a framework and a method for goal-driven, model-driven, and service-oriented design. The framework includes goal modeling in the MDA stack, from CIM to code. By using this framework, we are able to create a system that is compatible with its business goals, and thus is flexible when business demands change. A case study demonstrates how our framework can be used to combine MDA, SOA, and goal modeling with business rules as an architecture for a care service platform.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {158–164},
numpages = {7},
keywords = {web services, healthcare, goals, business rules, architecture, SOA, MDA},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.5555/2399776.2399786,
author = {Mat\'{e}, Alejandro and Trujillo, Juan and Mylopoulos, John},
title = {Conceptualizing and specifying key performance indicators in business strategy models},
year = {2012},
publisher = {IBM Corp.},
address = {USA},
abstract = {Key Performance Indicators (KPI) measure the performance of an organization relative to its objectives. To monitor organizational performance, such KPIs need to be manually implemented in the form of data warehouse queries, to be used in dashboards or scorecards. However, dashboards include little if any information about business strategy and offer a scattered view of KPIs and what do they mean relative to business concerns. In this paper, we propose an integrated view of strategic business models and conceptual data warehouse models. The main benefit of our proposal is that it links strategic business models to the data through which objectives can be monitored and assessed. In our proposal, KPIs are defined in Structured English and are implemented in a semi-automatic way, allowing for quick modifications. This enables real-time monitoring and what-if analysis, thereby helping analysts compare expectations with reported results.},
booktitle = {Proceedings of the 2012 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {102–115},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {CASCON '12}
}

@inproceedings{10.1145/2245276.2231944,
author = {Silva Souza, V\'{\i}tor E. and Maz\'{o}n, Jose-Norberto and Garrig\'{o}s, Irene and Trujillo, Juan and Mylopoulos, John},
title = {Monitoring strategic goals in data warehouses with awareness requirements},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231944},
doi = {10.1145/2245276.2231944},
abstract = {A data warehouse (DW) system stores data from multiple data sources in integrated form and provides capabilities for monitoring business operations to ensure compliance to strategic goals. As such, DWs constitute a fundamental building block for Business Intelligence (BI) operations. In this paper, we introduce the notion of Awareness Requirements (AwReqs) in the requirements analysis and elicitation phase for DWs. In this context, AwReqs provide analysts with the means for eliciting and modeling requirements over performance measures (indicators) to appraise the success or failure of strategic goals. To demonstrate the benefit of our approach, we present a typical business example throughout the paper and show how we can establish in the early stages of DW design the adequacy of the design for BI operations.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1075–1082},
numpages = {8},
keywords = {requirements, monitoring, key performance indicators, goals, data warehouse, awareness},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/1966901.1966903,
author = {F\"{u}rber, Christian and Hepp, Martin},
title = {Towards a vocabulary for data quality management in semantic web architectures},
year = {2011},
isbn = {9781450306089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1966901.1966903},
doi = {10.1145/1966901.1966903},
abstract = {Reliable decision-making and reliable information based on Semantic Web data requires methodologies and techniques for managing the quality of the published data. To make things more complicated, the judgment of what is "good" data will often depend on the task at hand or the subjective requirements of data owners or data consumers. Some data quality requirements can be modeled using data quality rules, i.e. executable definitions that allow the identification and measurement of data quality problems. In this paper, we provide a conceptual model that allows the representation of such rules and other quality-related knowledge using the Resource Description Framework (RDF) and the Web Ontology Language (OWL). Based on our model, it is possible to monitor and assess the quality of data sources and to automate data cleansing tasks. The use of a generic conceptual model based on Semantic Web formalisms supports the definition of reusable, broadly applicable SPARQL queries and portable applications for data quality management (DQM). Furthermore, the explicit representation of rules in RDF/OWL facilitates rule management tasks, e.g. for analyzing consistency among the rules, and allows to collaborate and create a shared understanding.},
booktitle = {Proceedings of the 1st International Workshop on Linked Web Data Management},
pages = {1–8},
numpages = {8},
keywords = {trust, semantic web, ontology, linked data management, knowledge representation, information quality, data quality management, SPARQL},
location = {Uppsala, Sweden},
series = {LWDM '11}
}

@inproceedings{10.1145/2729104.2729129,
author = {Lipuntsov, Yuri P.},
title = {Three Types of Data Exchange in the Open Government Information Projects},
year = {2014},
isbn = {9781450334013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2729104.2729129},
doi = {10.1145/2729104.2729129},
abstract = {Open government as a new system of public administration requires a qualitatively new level of information support for digital interactions of agencies, as well as between government and citizens, experts, and businesses. This article examines three categories of government counterparties, interactions with which are based on different principles: community of interest; subject areas; a loosely coupled environment. The public sector has now many information projects, and most of them deal with the data exchange, data delivery from and to the environment. The understanding of an environment is various for different projects. The categorization of projects depends on nature and the level of intellectual interaction with the external environment needed for the correct definition of project objectives, assessment of effectiveness. With the growing number of users and the transition to an open world, semantic principles are becoming more significant. Given the shift from systems integration to the semantic method, the role of subject matter expert is growing substantially.},
booktitle = {Proceedings of the 2014 Conference on Electronic Governance and Open Society: Challenges in Eurasia},
pages = {88–94},
numpages = {7},
keywords = {Shared Environment, Open Government, Open Data, Linked Data, Data Standardization, Core Component},
location = {St. Petersburg, Russian Federation},
series = {EGOSE '14}
}

@inproceedings{10.1145/2095654.2095665,
author = {Burden, H\r{a}kan and Heldal, Rogardt},
title = {Natural language generation from class diagrams},
year = {2011},
isbn = {9781450309141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2095654.2095665},
doi = {10.1145/2095654.2095665},
abstract = {A Platform-Independent Model (PIM) is supposed to capture the requirements specified in the Computational Independent Model (CIM). It can be hard to validate that this is the case since the stakeholders might lack the necessary training to access the information of the software models in the PIM. In contrast, a description of the PIM in natural language will enable all stakeholders to be included in the validation.We have conducted a case study to investigate the possibilities to generate natural language text from Executable and Translatable UML. In our case study we have considered a static part of the PIM; the structure of the class diagram. The transformation was done in two steps. In the first step, the class diagram was transformed into an intermediate linguistic model using Grammatical Framework. In the second step, the linguistic model is transformed into natural language text. The PIM was enhanced in such a way that the generated texts can both paraphrase the original software models as well as include the underlying motivations behind the design decisions.},
booktitle = {Proceedings of the 8th International Workshop on Model-Driven Engineering, Verification and Validation},
articleno = {8},
numpages = {8},
keywords = {model-driven architecture, model transformations},
location = {Wellington, New Zealand},
series = {MoDeVVa}
}

@inproceedings{10.1145/2514601.2514603,
author = {Athan, Tara and Boley, Harold and Governatori, Guido and Palmirani, Monica and Paschke, Adrian and Wyner, Adam},
title = {OASIS LegalRuleML},
year = {2013},
isbn = {9781450320801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2514601.2514603},
doi = {10.1145/2514601.2514603},
abstract = {In this paper we present the motivation, use cases, design principles, abstract syntax, and initial core of LegalRuleML. The LegalRuleML-core is sufficiently rich for expressing legal sources, time, defeasibility, and deontic operators. An example is provided. LegalRuleMLis compared to related work.},
booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law},
pages = {3–12},
numpages = {10},
keywords = {LegalRuleML},
location = {Rome, Italy},
series = {ICAIL '13}
}

@inproceedings{10.1145/3167132.3167331,
author = {Camilleri, John J. and Haghshenas, Mohammad Reza and Schneider, Gerardo},
title = {A web-based tool for analysing normative documents in english},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167331},
doi = {10.1145/3167132.3167331},
abstract = {Our goal is to use formal methods to analyse normative documents written in English, such as privacy policies and regulations. This requires the combination of a number of different elements, including information extraction from natural language, formal languages for model representation, and an interface for property specification and verification. A number of components for performing these tasks have separately been developed: a natural language extraction tool, a suitable formalism for representing such documents, an interface for building models in this formalism, and methods for answering queries asked of a given model. In this work, each of these concerns is brought together in a web-based tool, providing a single interface for analysing normative texts in English. Through the use of a running example, we describe each component and demonstrate the workflow established by our tool.},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {1865–1872},
numpages = {8},
keywords = {normative texts, model checking, information extraction, controlled natural language, contract analysis},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1145/2539150.2539179,
author = {Mach, Werner and Pittl, Benedikt and Schikuta, Erich},
title = {A Business Rules Driven Framework for Consumer-Provider Contracting of Web Services},
year = {2013},
isbn = {9781450321136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2539150.2539179},
doi = {10.1145/2539150.2539179},
abstract = {In this paper we present a scalable and extensible architecture of a business rule management framework. This representation can be used for agent based automatic negotiation and re-negotiation of web services. To ensure scalability and extensibility our architecture is based on the service oriented design pattern using ontologies. Finally we develop a prototype based on our business rules framework which simplifies business logic modification and maintenance for both service-provider and -consumer.},
booktitle = {Proceedings of International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {229–239},
numpages = {11},
keywords = {Workflow, Semantic Web, Ontology, Business Rules, Blackboard},
location = {Vienna, Austria},
series = {IIWAS '13}
}

@inproceedings{10.1145/2072069.2072111,
author = {Gong, Yiwei and Janssen, Marijn},
title = {Creating dynamic business processes using semantic web services and business rules},
year = {2011},
isbn = {9781450307468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072069.2072111},
doi = {10.1145/2072069.2072111},
abstract = {Service Oriented Architecture (SOA) and Business Rules (BR) are used by organization to adapt to changes. The disadvantage of this approach is that processes need to be defined in advance often requiring labor-intensive and time-consuming modeling processes. Usually, only a limited number of variations in processes are supported which have to be defined in design time. Hence, a shift from static to dynamic business processes creation is required. Semantic Web Services (SWS) can be used as a technology to create dynamic processes. Although there has been extensive research in the field of SWS and BR, there is scant research on the combination of them. In this paper, we propose an architecture based on BR and SWS to create dynamic business processes. Using a pre-agreed domain ontology to ensure the compatibility between SWSs and BRs, a new process is created by selecting the decision services using BRs and composing decision services with necessary assistant services. An illustrative study is used to demonstrate and evaluate the architecture on its feasibility in dynamic process creation. In this way, SOA systems in government environment can create a process with their services dynamically without having to hardcode the process. This can help the organization to efficiently adapt to changes in policies and legislation.},
booktitle = {Proceedings of the 5th International Conference on Theory and Practice of Electronic Governance},
pages = {249–258},
numpages = {10},
keywords = {semantic web services, ontology, composition, business rule, business processes, SOA},
location = {Tallinn, Estonia},
series = {ICEGOV '11}
}

@inproceedings{10.1145/2513456.2513459,
author = {Edwards, Craig and Gruner, Stefan},
title = {A new tool for URDAD to Java EE EJB transformations},
year = {2013},
isbn = {9781450321129},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2513456.2513459},
doi = {10.1145/2513456.2513459},
abstract = {Following the Object Management Group's (OMG) Model-Driven Architecture (MDA) approach, the semi-formal, service-orientated "Use Case, Responsibility Driven Analysis and Design" (URDAD) method is used by requirements engineers to specify a software system's functional properties in a Platform Independent Model (PIM). PIMs are represented using the URDAD Domain Specific Language (DSL), and thus conform to the URDAD MOF meta model. As a result, they can be transformed into Platform-Specific Models (PSM) for frameworks such as Java Platform Enterprise Edition (JEE) Enterprise Java Beans (EJB). This paper describes the semi-automatic transformation of a URDAD PIM into a EJB PSM, which is the basis for the further generation of EJB program code. For this purpose, a new prototype CASE tool was implemented to facilitate such transformations. The tool was evaluated using a non-trivial example project, with results indicating that it produces the PSM and template code that constitutes the static Java EE EJB structural representation of the example PIM.},
booktitle = {Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference},
pages = {144–153},
numpages = {10},
keywords = {model transformation, URDAD, QVT, MOF, MDA, JaMoPP, EJB, CASE tool},
location = {East London, South Africa},
series = {SAICSIT '13}
}

@inproceedings{10.1145/1774088.1774118,
author = {Aveiro, David and Silva, A. Rito and Tribolet, Jos\'{e}},
title = {Towards a GOD-theory for organizational engineering: continuously modeling the continuous (re)generation, operation and deletion of the enterprise},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774118},
doi = {10.1145/1774088.1774118},
abstract = {Much time is lost, in organizations, in the handling of unknown exceptions because organizational models are not current or coherent with reality and there is a lack of concepts and methods in organizational engineering (OE), for a continuous and timely update of models of organizational reality. To address these problems, a renowned methodology for OE -- DEMO (Design and Engineering Methodology for Organizations) and its underlying theory are improved and extended enabling a precise and integrated modeling of three aspects that we consider to be part of the function perspective of an organization: (1) viability -- specification of vital norms of operation that ensure the viability of the organization, dysfunctions and their causing exceptions, (2) change -- specification of the organizational engineering processes responsible for Generation, Operation and Discontinuation of organizational artifacts (OAs) -- for example, business rules or organizational actors -- in order to solve dysfunctions and (3) architecture -- specification of design rules that guide the referred engineering processes, restricting the "shape" of their end result -- OAs.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {150–157},
numpages = {8},
keywords = {organizational self-awareness, organizational engineering, organizational change, function, exception},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/1342211.1342221,
author = {Raj, Amit and Prabhakar, T. V. and Hendryx, Stan},
title = {Transformation of SBVR business design to UML models},
year = {2008},
isbn = {9781595939173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1342211.1342221},
doi = {10.1145/1342211.1342221},
abstract = {This paper presents a methodology for transforming business designs written in OMG's standard Semantics of Business Vocabulary and Rules (SBVR) framework, into a set of UML models. It involves the transformation of business vocabulary and rules written in SBVR's "Structured English" into a set of UML diagrams, which includes Activity Diagram(AD), Sequence Diagram(SD), and Class Diagram(CD). This transformation works by detecting the distinction between rules which will participate in the construction of Activity Diagram and rules which do not. These rules are imperative in nature. The work in the paper also includes the detection of activities embedded implicitly in those rules and establishment of sequence between those activities. These activities incur some action. We also detect their owner and refer to them as the doer of the action. This plays a very important role in the development of Class Diagrams},
booktitle = {Proceedings of the 1st India Software Engineering Conference},
pages = {29–38},
numpages = {10},
keywords = {production rule representation, model driven architecture, business rules, business design, UML, SBVR},
location = {Hyderabad, India},
series = {ISEC '08}
}

@inproceedings{10.1145/2975941.2975943,
author = {Chittimalli, Pavan Kumar and Anand, Kritika},
title = {Domain-independent method of detecting inconsistencies in SBVR-based business rules},
year = {2016},
isbn = {9781450342148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2975941.2975943},
doi = {10.1145/2975941.2975943},
abstract = {Traditionally, business rules are expressed informally in English, captured eventually, as a part of UML use-cases. Detecting anomalies in business rules is extremely difficult to automate, due to their informal nature, and manually error-prone due to the size and complexity. In recent times, business rules are being expressed increasingly using standard representations (such as Semantics of Business Vocabularies and Rules (SBVR)). We present a method to detect inconsistencies amongst the rules, based on the model checking. We exploit the First Order Logic (FOL) basis of SBVR representation to propose a method that is independent of the business domain. We present a case-study of business rules for well-known example of car-rental, and our method shows promising results to detect inconsistencies.},
booktitle = {Proceedings of the International Workshop on Formal Methods for Analysis of Business Systems},
pages = {9–16},
numpages = {8},
keywords = {SBVR, Rule Verification, Business Rules},
location = {Singapore, Singapore},
series = {ForMABS 2016}
}

@inproceedings{10.1145/3299771.3299786,
author = {Chittimalli, Pavan Kumar and Bhattacharyya, Abhidip},
title = {SBVR-based Business Rule Creation for Legacy Programs using Variable Provenance},
year = {2019},
isbn = {9781450362153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299771.3299786},
doi = {10.1145/3299771.3299786},
abstract = {Functionality of a software system that implements business operations can be captured using business processes and rules. To understand the 'as-is' processes and rules, the source-code is arguably the best source of knowledge. We present a novel method that combines program analysis and domain knowledge to create the descriptions for "IT rules", as a critical step towards extracting business rules automatically. We introduce and use the concept of 'variable provenance' to propagate the domain descriptions into the source code to create Semantics of Business Vocabularies and Rules (SBVR) rules. In our experiments on sample, near-real-life systems, we could successfully annotate very large percentage (&gt; 90%) of IT rules and enable to create SBVR rules. We present and describe the ProgAnnotator tool which is based on variable provenance and generates descriptions for IT rules in the source code and subsequently create SBVR rules automatically.},
booktitle = {Proceedings of the 12th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {16},
numpages = {11},
keywords = {Business Rule Extraction, Rule Annotation, SBVR, Static Program Analysis, Variable Provenance},
location = {<conf-loc>, <city>Pune</city>, <country>India</country>, </conf-loc>},
series = {ISEC '19}
}

@inproceedings{10.1145/3385032.3385046,
author = {Chittimalli, Pavan Kumar and Prakash, Chandan and Naik, Ravindra and Bhattacharyya, Abhidip},
title = {An Approach to Mine SBVR Vocabularies and Rules from Business Documents},
year = {2020},
isbn = {9781450375948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385032.3385046},
doi = {10.1145/3385032.3385046},
abstract = {Enterprises model the behavior of their business to prepare a communication standard for business analysts and to specify requirements to Information Technology (IT) people. The communication gap between IT group and business analysts, who lie on the opposite end of the business spectrum exists due to the different terminologies used in their respective fields regarding the same context. This gap has led to major software failures which prompted the OMG group has come up with a new standard - Semantic of Business Vocabulary and Business Rules (SBVR). Declarative models are provided by SBVR to represent Business Vocabulary and Business Rules which can be understood by everyone working throughout the business spectrum. Each business is governed by business rules which are constrained by the regulation policy set up by the policy guidelines of the organization and government regulations set up on the organization. Business rules are specified in documents like user guides, requirement documents, terms and conditions, do's and don'ts. Typically a Business Analyst interprets the document and manually extracts rules based on his understanding which leads to potential discrepancies, ambiguities and quality issues in the software system. To minimize such errors, in this paper we present an unsupervised approach to automatically extract SBVR vocabularies and rules from domain-specific business documents. We also present our initial results and comparative study with our earlier approach.},
booktitle = {Proceedings of the 13th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {12},
numpages = {11},
keywords = {Business Rules Extraction, Natural Language Processing, Rule Components, Rule Document, SBVR, Text Mining},
location = {<conf-loc>, <city>Jabalpur</city>, <country>India</country>, </conf-loc>},
series = {ISEC '20}
}

@inproceedings{10.1145/3452383.3452396,
author = {Prakash, Chandan and Chittimalli, Pavan Kumar and Naik, Ravindra},
title = {Open Information Extraction Using Dependency Parser for Business Rule Mining in SBVR Format},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452396},
doi = {10.1145/3452383.3452396},
abstract = {Business Rules exists at the core of any Business Organization. For efficient execution of the business system, all the business rules must be in machine-interpretable format. There is an absence of such a system that can convert the business rule sentences into corresponding structured format automatically. We present BRMiner, a system which automatically converts business rules represented as Natural Language sentences to the corresponding SBVR format which is a structured representation that can be further converted to the machine-interpretable format. BRMiner is based on the idea of Open Information Extraction (OIE). We have shown that existing OIE systems are not suitable for SBVR rule formation that leads to the development of a new OIE system BRMiner, with more accurate prediction and additional capabilities. BRMiner uses the state of the art dependency parser to convert an unstructured business rule to the corresponding structured format. We have used internal as well as publically available datasets for our system evaluation and the results are encouraging which we have shown in the paper.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {13},
numpages = {11},
keywords = {Business Rules, Controlled Natural Language, Dependency Parser, Open Information Extraction, SBVR},
location = {<conf-loc>, <city>Bhubaneswar, Odisha</city>, <country>India</country>, </conf-loc>},
series = {ISEC '21}
}

@inproceedings{10.1109/ASE.2019.00134,
author = {Chittimalli, Pavan Kumar and Anand, Kritika and Pradhan, Shrishti and Mitra, Sayandeep and Prakash, Chandan and Shere, Rohit and Naik, Ravindra},
title = {BuRRiTo: a framework to extract, specify, verify and analyze business rules},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00134},
doi = {10.1109/ASE.2019.00134},
abstract = {An enterprise system operates business by providing various services that are guided by set of certain business rules (BR) and constraints. These BR are usually written using plain Natural Language in operating procedures, terms and conditions, and other documents or in source code of legacy enterprise systems. For implementing the BR in a software system, expressing them as UML use-case specifications, or preparing for Merger &amp; Acquisition (M&amp;A) activity, analysts manually interpret the documents or try to identify constraints from the source code, leading to potential discrepancies and ambiguities. These issues in the software system can be resolved only after testing, which is a very tedious and expensive activity. To minimize such errors and efforts, we propose BuRRiTo framework consisting of automatic extraction of BR by mining documents and source code, ability to clean them of various anomalies like inconsistency, redundancies, conflicts, etc. and able to analyze the functional gaps present and performing semantic querying and searching.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1190–1193},
numpages = {4},
keywords = {text mining, source code, search and query, rule document, rule components, natural language processing, match and gap, graphs, business rules extraction, SBVR},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3136014.3136018,
author = {Roychoudhury, Suman and Sunkle, Sagar and Kholkar, Deepali and Kulkarni, Vinay},
title = {A domain-specific controlled English language for automated regulatory compliance (industrial paper)},
year = {2017},
isbn = {9781450355254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136014.3136018},
doi = {10.1145/3136014.3136018},
abstract = {Modern enterprises operate in an unprecedented regulatory environment where increasing regulation and heavy penalties on non-compliance have placed regulatory compliance among the topmost concerns of enterprises worldwide. Previous research in the field of compliance has established that the manual specification of the regulations used by GRC frameworks not only fails to ensure their proper coverage but also negatively affects the turnaround time both in proving and maintaining the compliance. Our key contribution in this paper is an implementation of a controlled natural English like (domain-specific) language that can be used by domain experts to specify regulations for automated compliance checking. We demonstrate this language using examples from industry regulations in banking and financial services domain.},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {175–181},
numpages = {7},
keywords = {text-to-model transformation, controlled natural English, SBVR, Regulatory compliance},
location = {Vancouver, BC, Canada},
series = {SLE 2017}
}

@article{10.1007/s00165-020-00512-5,
author = {Williams, David M. and Darwish, Salaheddin and Schneider, Steve and Michael, David R.},
title = {Legislation-driven development of a Gift Aid system using Event-B},
year = {2020},
issue_date = {Jul 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {2–3},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-020-00512-5},
doi = {10.1007/s00165-020-00512-5},
abstract = {This work presents our approach to formally model the Swiftaid system design, a digital platform that enables donors to automatically add Gift Aid to donations made via card payments. Following principles of Behaviour-Driven Development, we use Gherkin to capture requirements specified in legislation, specifically the UK Charity (Gift Aid Declarations) Regulations 2016. The Gherkin scenarios provide a basis for subsequent formal modelling and analysis using Event-B, Rodin and ProB. Interactive model simulations assist communication between domain experts, software architects and other stakeholders during requirements capture and system design, enabling the emergent system behaviour to be validated. Our approach was employed within the development of the real Swiftaid product, launched by Streeva in February 2019. Our analysis helped conclude that there was not a strong enough business case for one of the features, whichwas shown to provide nominal user convenience at the expense of increased complexity. This work provides a case study in allying formal and agile software development to enable rapid development of robust software.},
journal = {Form. Asp. Comput.},
month = {jul},
pages = {251–273},
numpages = {23},
keywords = {Swiftaid, Gift Aid, Event-B, Gherkin, Formal modelling, Behaviour-driven development}
}

@inproceedings{10.1145/2345396.2345522,
author = {Naeem, M. Asif and Bajwa, Imran Sarwar},
title = {Generating OLAP queries from natural language specification},
year = {2012},
isbn = {9781450311960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2345396.2345522},
doi = {10.1145/2345396.2345522},
abstract = {Automatic translation of natural language (NL) questions to Structured Query Language (SQL) queries is a challenging task. It is a common knowledge that writing Online Analytical Processing (OLAP) queries for data warehouses is difficult, particularly, for the novice users. In this paper, we present a natural language processing based approach to automatically generate OLAP queries those can be used to communicate with the a data warehouse. In the presented approach, user provides queries in English and our approach process English queries and generate OLAP queries. In our approach, we incorporate OMG's recent standard Semantic of Business Vocabulary and Business Rules (SBVR) to simplify the translation process of English to OLAP. SBVR is used in detailed semantic analysis of English queries. The presented approach is also implemented in Java as a prototype tool. To test the performance of the tool, an experimental study is also conducted. Results of the experimental study imply that our approach is capable in communicating with a data warehouse.},
booktitle = {Proceedings of the International Conference on Advances in Computing, Communications and Informatics},
pages = {768–773},
numpages = {6},
location = {Chennai, India},
series = {ICACCI '12}
}

@inproceedings{10.1145/2668904.2668940,
author = {James, Stuart and Collomosse, John},
title = {Interactive video asset retrieval using sketched queries},
year = {2014},
isbn = {9781450331852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668904.2668940},
doi = {10.1145/2668904.2668940},
abstract = {We present a new algorithm for searching video repositories using free-hand sketches. Our queries express both appearance (color, shape) and motion attributes, as well as semantic properties (object labels) enabling hybrid queries to be specified. Unlike existing sketch based video retrieval (SBVR) systems that enable hybrid queries of this form, we do not adopt a model fitting/optimization approach to match at query-time. Rather, we create an efficiently searchable index via a novel space-time descriptor that encapsulates all these properties. The real-time performance yielded by our indexing approach enables interactive refinement of search results within a relevance feedback (RF) framework; a unique contribution to SBVR. We evaluate our system over 700 sports footage clips exhibiting a variety of clutter and motion conditions, demonstrating significant accuracy and speed gains over the state of the art.},
booktitle = {Proceedings of the 11th European Conference on Visual Media Production},
articleno = {11},
numpages = {8},
keywords = {sketch based video retrieval, relevance feedback, computer vision},
location = {London, United Kingdom},
series = {CVMP '14}
}

@inproceedings{10.1145/3172871.3172884,
author = {Bhattacharyya, Abhidip and Chittimalli, Pavan Kumar and Naik, Ravindra},
title = {Relation Identification in Business Rules for Domain-specific Documents},
year = {2018},
isbn = {9781450363983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172871.3172884},
doi = {10.1145/3172871.3172884},
abstract = {This paper focuses on an approach to mine business rules from documents and facilitates a methodology to represent them in a formal notation. Businesses are operated abiding by some rules and complying with respect to regulation and guidelines. The business rules are often written using English in operating procedures, terms and conditions, and various other supporting documents. The manual analysis of these rules for activities like impact analysis, maintenance, business transformation leads to potential discrepancies, ambiguities, and quality issues. In this paper, we discuss our approach of mining relations among the rule intents (atomic facts) defined for business rules. We also present our preliminary studies on a couple of openly available documents.},
booktitle = {Proceedings of the 11th Innovations in Software Engineering Conference},
articleno = {14},
numpages = {5},
keywords = {Natural Language Processing, Maximum Entropy, Document Mining, Business Rule Extraction},
location = {Hyderabad, India},
series = {ISEC '18}
}

@inproceedings{10.5555/3351736.3351788,
author = {Sunkle, Sagar and Kholkar, Deepali and Kulkarni, Vinay},
title = {Model-driven regulatory compliance: a case study of "know your customer" regulations},
year = {2015},
isbn = {9781467369084},
publisher = {IEEE Press},
abstract = {Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.},
booktitle = {Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems},
pages = {436–445},
numpages = {10},
location = {Ottawa, Ontario, Canada},
series = {MODELS '15}
}

@inproceedings{10.1145/3021460.3021470,
author = {Bhattacharyya, Abhidip and Chittimalli, Pavan Kumar and Naik, Ravindra},
title = {An Approach to Mine Business Rule Intents from Domain-specific Documents},
year = {2017},
isbn = {9781450348560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3021460.3021470},
doi = {10.1145/3021460.3021470},
abstract = {An enterprise system enables business by providing various services that are guided by set of well-defined processes, and adhere to certain business rules and constraints. The business rules are usually written using English in operating procedures, terms and conditions, and various other supporting documents. For implementing the business rules in a software system, or expressing them as UML use-case specifications, analysts manually interpret the documents, leading to potential discrepancies, ambiguities, and quality issues in the software system that can be resolved only after testing.To minimize such errors, we propose a novel method to mine the documents automatically to extract the fundamental atomic facts in every sentence - called as business rule intents. We adopt dependency tree parser to parse the rule sentences and extract rule intents from them. Our experiments using few publicly available sample documents in the financial domain yielded very promising results, where rule intents extraction produced an average precision of 78% and recall of 80%.},
booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
pages = {96–106},
numpages = {11},
location = {Jaipur, India},
series = {ISEC '17}
}

@inproceedings{10.1145/3460620.3460768,
author = {M. Maatuk, Abdelsalam and A. Abdelnabi, Esra},
title = {Generating UML Use Case and Activity Diagrams Using NLP Techniques and Heuristics Rules},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460620.3460768},
doi = {10.1145/3460620.3460768},
abstract = {The process of generating Unified Modeling Language (UML) Diagrams from Natural Language (NL) requirements is considered a complex and challenging task. Software requirements specification is often written in NL format, which causes potential problems. Requirement's analysts analyze and process natural language requirements manually to extract the UML elements. The manual analysis takes a lot of time and effort, which justifies the need for automated support. This paper proposes an approach to facilitate the NL requirements analysis process and UML diagrams extraction from NL textual requirements using natural language processing (NLP) techniques and heuristics rules. This approach focuses on generating use-case and activity diagrams. The approach has been applied to a case study and evaluated through an experimental. The evaluation of the approach will be conducted through a comparative study. The experimental results prove that the proposed approach is considerably improved as compared to the other approaches.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {271–277},
numpages = {7},
keywords = {UML diagrams, Software Requirement Specification, Requirement Analysis, NLP},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@inproceedings{10.1145/1774088.1774117,
author = {de Moura Araujo, Bruno and Schmitz, Eber Assis and Correa, Alexandre Luis and Alencar, Antonio Juarez},
title = {A method for validating the compliance of business processes to business rules},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774117},
doi = {10.1145/1774088.1774117},
abstract = {Regulatory compliance of business operations and practices is increasingly becoming an area of great concern for management, costing tens of billions of dollars in compliance actions a year. This paper presents a method for validating business processes with respect to the business rules. In the proposed method, business processes are modeled with UML activity diagrams, whilst business rules are represented as OCL expressions attached to process activities and the business conceptual model. The model validation is based on the simulation of the execution of process instances based on specific scenarios. The simulation algorithm steps through the process model executing the actions associated to the activities with the help of the USE tool and checking for violations of the associated business rules. The proposed method allows the modeler to have an early feedback of possible defects that may exist in a business process model.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {145–149},
numpages = {5},
keywords = {compliance validation, business rules, business process, UML, OCL},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/3041048.3041054,
author = {Turner, Ronald C.},
title = {Proposed Model for Natural Language ABAC Authoring},
year = {2017},
isbn = {9781450349109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3041048.3041054},
doi = {10.1145/3041048.3041054},
abstract = {Authorization policy authoring has required tools from the start. With access policy governance now an executive-level responsibility, it is imperative that such a tool expose the policy to business users' with little or no IT intervention-as natural language. NIST SP 800-162 [1] first prescribes natural language policies (NLPs) as the preferred expression of policy and then implicitly calls for automated translation of NLP to machine-executable code. This paper therefore proposes an interoperable model for the NLP's human expression. It furthermore documents the research and development of a tool set for end-to-end authoring and translation. This R&amp;D journey-focusing constantly on end users' has debunked certain myths, has responded to steadily increasing market sophistication, has applied formal disciplines (e.g. ontologies, grammars and compiler design) and has motivated an informal demonstration of autonomic code generation. The lessons learned should be of practical value to the entire ABAC community. The research in progress' increasingly complex policies, proactive rule analytics, and expanded NLP authoring language support will require collaboration with an ever-expanding technical community from industry and academia.},
booktitle = {Proceedings of the 2nd ACM Workshop on Attribute-Based Access Control},
pages = {61–72},
numpages = {12},
keywords = {policy semantics, natural language policies, business rules, XACML authoring tool, SPARQL queries, RDF analytics, ABAC},
location = {Scottsdale, Arizona, USA},
series = {ABAC '17}
}

@inproceedings{10.1145/3220228.3220255,
author = {Apaza, Ren\'{a}n Dar\'{\i}o Gonzales and Barrios, Jhon Edilberto Monroy and Becerra, Diego Alonso Iquira and Quispe, Jos\'{e} Alfredo Herrera},
title = {ERS-TOOL: hybrid model for software requirements elicitation in Spanish language},
year = {2018},
isbn = {9781450364454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220228.3220255},
doi = {10.1145/3220228.3220255},
abstract = {The nature of the software requirements is subjective and varied. For this reason the level of complexity increases according to the volume, especially when the requirements are made in a natural language. Therefore obtain quality software requirements that are understandable and unambiguous in the Spanish language becomes a necessity. First, a controlled syntax was proposed to express software requirements taking into account the static and dynamic behavior among the different actors of the system, where the expressions are elaborated based on the Backus-Naur form (BNF). Then a set of writing rules were adapted to the Spanish language, creating four additional rules. Finally, the results of the case study had high accuracy in understandability; also the ambiguity of requirements elicitation was reduced. In addition to improving the development of software engineering activities, since there are no tools available for the elicitation of software requirements with language Spanish.},
booktitle = {Proceedings of the International Conference on Geoinformatics and Data Analysis},
pages = {27–30},
numpages = {4},
keywords = {requirements engineering, controlled syntax, ambiguity of requirements},
location = {Prague, Czech Republic},
series = {ICGDA '18}
}

@inproceedings{10.1145/2993318.2993329,
author = {Ford, Reginald and Denker, Grit and Elenius, Daniel and Moore, Wesley and Abi-Lahoud, Elie},
title = {Automating Financial Regulatory Compliance Using Ontology+Rules and Sunflower},
year = {2016},
isbn = {9781450347525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993318.2993329},
doi = {10.1145/2993318.2993329},
abstract = {Compliance departments in the international finance industry are struggling to use traditional methods to keep up with the demands of new and more stringent regulatory and policy requirements. One initiative supported by many institutions is definition of a common Financial Industry Business Ontology (FIBO). We regard a common ontology as an important step, but in order to support real-world uses cases, the ontology needs to be augmented, and further supplemented by rules that encode the meaning of regulations and policies. We use Sunflower, which is built on top of the Flora-2 knowledge representation languages and reasoner, to add automation to the compliance lifecycle. Sunflower is domain-agnostic, and financial regulatory compliance is one of its many application areas.},
booktitle = {Proceedings of the 12th International Conference on Semantic Systems},
pages = {113–120},
numpages = {8},
keywords = {Sunflower, Rules, Regulatory Compliance, Reasoning, Ontologies, Integrated Development Environment, Explanation},
location = {Leipzig, Germany},
series = {SEMANTiCS 2016}
}

@inproceedings{10.1145/3229345.3229373,
author = {de Almeida Bordignon, Ana Cl\'{a}udia and Thom, Lucin\'{e}ia Heloisa and Silva, Thanner Soares and Dani, Vinicius Stein and Fantinato, Marcelo and Ferreira, Renato Cesar Borges},
title = {Natural Language Processing in Business Process Identification and Modeling: A Systematic Literature Review},
year = {2018},
isbn = {9781450365598},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229345.3229373},
doi = {10.1145/3229345.3229373},
abstract = {Business Process Management (BPM) has been receiving increasing attention in recent years. Many organizations have been adapting their business to a process-centered view since they started noticing its potential to reduce costs, improve productivity and achieve higher levels of quality. However, implementing BPM in organizations requires time, making the automation of process identification and discovery highly desirable. To achieve this expectation, the application of Natural Language Processing (NLP) techniques and tools has emerged to generate process models from unstructured text. In this paper, we provide the results of a systematic literature review conducted in preparation and processing of natural language text aiming the extraction of business processes and process quality assurance. The study presents techniques applied to the BPM life-cycle phases of process identification, process discovery and process analysis as well as tools to support process discovery. This review covered papers from 2009 up to 2016 and identifies 518 articles of which 33 were selected as relevant to our work. The results of the present study may be valuable to support research in extraction of business process models from natural language text.},
booktitle = {Proceedings of the XIV Brazilian Symposium on Information Systems},
articleno = {25},
numpages = {8},
keywords = {Systematic Literature Review, Process Discovery, Process Analysis, Natural Language Processing, Business Process Management},
location = {Caxias do Sul, Brazil},
series = {SBSI '18}
}

@article{10.1145/3632857,
author = {Popescu, Andrei},
title = {Nominal Recursors as Epi-Recursors},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632857},
doi = {10.1145/3632857},
abstract = {We study nominal recursors from the literature on syntax with bindings and compare them with respect to expressiveness. The term "nominal" refers to the fact that these recursors operate on a syntax representation where the names of bound variables appear explicitly, as in nominal logic. We argue that nominal recursors can be viewed as epi-recursors, a concept that captures abstractly the distinction between the constructors on which one actually recurses, and other operators and properties that further underpin recursion. We develop an abstract framework for comparing epi-recursors and instantiate it to the existing nominal recursors, and also to several recursors obtained from them by cross-pollination. The resulted expressiveness hierarchies depend on how strictly we perform this comparison, and bring insight into the relative merits of different axiomatizations of syntax. We also apply our methodology to produce an expressiveness hierarchy of nominal corecursors, which are principles for defining functions targeting infinitary non-well-founded terms (which underlie lambda-calculus semantics concepts such as B\"{o}hm trees). Our results are validated with the Isabelle/HOL theorem prover.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {15},
numpages = {32},
keywords = {epi-(co)recuror, formal reasoning, nominal logic, nominal recursion and corecursion, syntax with bindings, theorem proving}
}

@article{10.1145/2501187.2501193,
author = {Samuel, Hamman},
title = {Upcoming SIGWEB supported conferences},
year = {2013},
issue_date = {Summer 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2013},
number = {Summer},
issn = {1931-1745},
url = {https://doi.org/10.1145/2501187.2501193},
doi = {10.1145/2501187.2501193},
abstract = {The Special Interest Group on Hypertext and the Web, SIGWEB was created in 1989 to support the community participating in the annual ACM Hypertext Conference. Now in its third decade, SIGWEB has grown considerably and now sponsors five annual conferences of different sizes and covering a wide range of topics. SIGWEB supports several specialized conferences, short courses, and workshops, as well as the Annual Hypertext Conference. SIGWEB sponsored conferences focus on timely topics in applied and computational hypertext and Web disciplines and provide a place for members and the entire applied Hypermedia and Web community to exchange ideas and to meet with and expand their network of colleagues. In this article, we provide a brief overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SIGWEB.},
journal = {SIGWEB Newsl.},
month = {jul},
articleno = {6},
numpages = {4}
}

@inproceedings{10.1145/2023607.2023625,
author = {Vasilecas, Olegas and Normantas, Kestutis},
title = {Deriving business rules from the models of existing information systems},
year = {2011},
isbn = {9781450309172},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2023607.2023625},
doi = {10.1145/2023607.2023625},
abstract = {Business rules tend to change in the course of time influencing modifications in business supporting information systems. Unfortunately, business rules most often are embedded in the source code of software systems, poorly or even not documented, and implementation details are known only for the developers. The paper addresses these issues and considers a model-driven process for derivation of business rules from the models of existing information systems, providing supporting tools, and supplementing the overall modernization process.},
booktitle = {Proceedings of the 12th International Conference on Computer Systems and Technologies},
pages = {95–100},
numpages = {6},
keywords = {knowledge extraction, knowledge discovery metamodel, business rules derivation, business rules, architecture driven modernization},
location = {Vienna, Austria},
series = {CompSysTech '11}
}

@inproceedings{10.1109/ICSE-SEIP58684.2023.00024,
author = {Rajbhoj, Asha and Nistala, Padmalata and Kulkarni, Vinay and Soni, Shivani and Pathan, Ajim},
title = {DocToModel: Automated Authoring of Models from Diverse Requirements Specification Documents},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP58684.2023.00024},
doi = {10.1109/ICSE-SEIP58684.2023.00024},
abstract = {Early stages of Software Development Life Cycle (SDLC) namely requirement elicitation and requirements analysis have remained document-centric in the industry for market-driven, complex, large-scale business applications and products. The documentation typically runs into hundreds of Natural Language (NL) text documents which requirements engineers need to sift looking for the relevant information and also maintain these documents in-sync over time - a time-consuming and error-prone activity. Much of this difficulty can be overcome if the information is available in a structured form that is amenable to automated processing. Purposive models offer a way out. However, for easy adoption by industry practitioners, these models must be populated from NL text documents in a largely automated manner. This task is characterized by high variability with several documents containing different information conforming to different structures and styles. As a result, purposive information extractors need to be developed for each project/ product. Moreover, being an open-ended space there is no upper bound on the information extractors that need to be developed. To overcome this difficulty, we propose a document structure agnostic and meta-model agnostic tool, DocToModel, for the automated authoring of models from NL text documents. It provides a pattern mapping language to specify a mapping of structured and unstructured document information to meta-model elements, and a pattern interpreter to automate model authoring. The configurable and extensible architecture of DocToModel makes it generic and amenable to easy repurposing for other NL documents. This paper, describes the approach and illustrates its utility and efficacy on multiple real-world case studies.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
pages = {199–210},
numpages = {12},
keywords = {pattern interpreter, meta-model pattern, NLP, document parser, model extraction, automated model authoring, meta-model},
location = {Melbourne, Australia},
series = {ICSE-SEIP '23}
}

@article{10.1145/2451836.2451841,
author = {Samuel, Hamman},
title = {Upcoming SIGWEB supported conferences},
year = {2013},
issue_date = {Spring 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2013},
number = {Spring},
issn = {1931-1745},
url = {https://doi.org/10.1145/2451836.2451841},
doi = {10.1145/2451836.2451841},
abstract = {The Special Interest Group on Hypertext and the Web, SIGWEB was created in 1989 to support the community participating in the annual ACM Hypertext Conference. Now in its third decade, SIGWEB has grown considerably and now sponsors five annual conferences of different sizes and covering a wide range of topics. SIGWEB supports several specialized conferences, short courses, and workshops, as well as the Annual Hypertext Conference. SIGWEB sponsored conferences focus on timely topics in applied and computational hypertext and Web disciplines and provide a place for members and the entire applied Hypermedia and Web community to exchange ideas and to meet with and expand their network of colleagues. In this article, we provide a brief overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SIGWEB.},
journal = {SIGWEB Newsl.},
month = {apr},
articleno = {5},
numpages = {6}
}

@article{10.1145/2430733.2430739,
author = {Samuel, Hamman},
title = {Upcoming SIGWEB supported conferences},
year = {2013},
issue_date = {Winter 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2013},
number = {Winter},
issn = {1931-1745},
url = {https://doi.org/10.1145/2430733.2430739},
doi = {10.1145/2430733.2430739},
abstract = {The Special Interest Group on Hypertext and the Web, SIGWEB was created in 1989 to support the community participating in the annual ACM Hypertext Conference. Now in its third decade, SIGWEB has grown considerably and now sponsors five annual conferences of different sizes and covering a wide range of topics. SIGWEB supports several specialized conferences, short courses, and workshops, as well as the Annual Hypertext Conference. SIGWEB sponsored conferences focus on timely topics in applied and computational hypertext and Web disciplines and provide a place for members and the entire applied Hypermedia and Web community to exchange ideas and to meet with and expand their network of colleagues. In this article, we provide a brief overview of SIGWEB sponsored conferences, in addition to events that are in cooperation with SIGWEB.},
journal = {SIGWEB Newsl.},
month = {jan},
articleno = {6},
numpages = {6}
}

@inproceedings{10.1145/1839379.1839394,
author = {Vasilecas, Olegas and Normantas, Kestutis},
title = {Decision table based approach for business rules modelling in UML/OCL},
year = {2010},
isbn = {9781450302432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839379.1839394},
doi = {10.1145/1839379.1839394},
abstract = {The Unified Modelling Language (UML) is widely used language for the specification of object-oriented designs. The Object Constraint Language (OCL) supplements this language by providing possibility to specify models in precise and unambiguous manner. However, the OCL is less suited for business rules (BR) modelling and validating with business people because it requires appropriate technical knowledge. This paper presents a decision table (DT) based approach for definition of business rules within UML/OCL models. The relevance between DT and different kinds of OCL expressions has been determined and approach to construct OCL expressions with DT has been considered.},
booktitle = {Proceedings of the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies},
pages = {77–82},
numpages = {6},
keywords = {decision tables, business rules, UML, OCL},
location = {Sofia, Bulgaria},
series = {CompSysTech '10}
}

@inproceedings{10.1145/3368691.3368709,
author = {Alsaadi, Mohmood and Lisitsa, Alexei and Qasaimeh, Malik},
title = {Minimizing the ambiguities in medical devices regulations based on software requirement engineering techniques},
year = {2019},
isbn = {9781450372848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368691.3368709},
doi = {10.1145/3368691.3368709},
abstract = {Trusted medical software devices, must comply with one of the healthcare regulations such as Food and Drug Administration (FDA), EU Medical Device Regulation (MDR), and Health Insurance Portability and Accountability Act (HIPAA). Since these regulations are enacted by law legislators and written in a legal text, these regulations are typically written with ambiguities. However, people have a different interpretation for the legal text for example, software developers faced challenges in identifying and understanding the regulatory requirements that are related to the software development process. Moreover, ambiguous in regulatory requirements play a big role in software compliance with regulatory particularly, when the requirements are legal text.In this paper, we intend to minimize the ambiguities in EU MDR requirements based on requirement engineering techniques in order to make MDR requirements clear and precise for software developers. In our previous work, we extracted the requirements of MDR that would affect the software development life cycle (SDLC) directly or indirectly. Herein, we will identify the ambiguity types in the extracted requirements of MDR. Moreover, this paper will present a method to minimize the ambiguities in MDR requirements based on requirement engineering techniques (user story and use case diagram). Finally, this work will be evaluated by the critical-to-quality tree measurement technique.},
booktitle = {Proceedings of the Second International Conference on Data Science, E-Learning and Information Systems},
articleno = {18},
numpages = {5},
keywords = {requirement engineering techniques, medical devices regulations, ambiguity of MD requirements, MDR software requirements, CTQ tree},
location = {Dubai, United Arab Emirates},
series = {DATA '19}
}

@inproceedings{10.5555/2667691.2667695,
author = {Sch\"{u}tz, Christoph and Schrefl, Michael},
title = {Variability in artifact-centric process modeling: the hetero-homogeneous approach},
year = {2014},
isbn = {9781921770364},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {Today's dynamic business environment demands from companies variable and flexible processes. Rather than imposing a single fixed process, process models must account for the variability of real-world business problems. Many companies are hierarchically organized with top-down decision making processes. On the one hand, company policies and legal regulations often require compliance with standard process models prescribed by higher-level management. On the other hand, lower-level employees should be flexible within the prescribed boundaries. In this paper, we propose a hetero-homogeneous approach to modeling process variability. We employ the multilevel business artifact (MBA) in order to represent within a single object the homogeneous schema of an abstraction hierarchy of processes. We employ multilevel concretization for the introduction of heterogeneities into sub-hierarchies which comply with the homogeneous global schema.},
booktitle = {Proceedings of the Tenth Asia-Pacific Conference on Conceptual Modelling - Volume 154},
pages = {29–38},
numpages = {10},
keywords = {process variability, process flexibility, multilevel modeling, business artifact},
location = {Auckland, New Zealand},
series = {APCCM '14}
}

@inproceedings{10.1145/2383276.2383286,
author = {Normantas, Kestutis and Sosunovas, Sergejus and Vasilecas, Olegas},
title = {An overview of the knowledge discovery meta-model},
year = {2012},
isbn = {9781450311939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2383276.2383286},
doi = {10.1145/2383276.2383286},
abstract = {Modernization of existing software systems is expensive and not always successive process that involves many challenging activities. In order to support these activities, the Object Management Group within the Architecture-Driven Modernization initiative proposes a number of standard representations of views on existing software systems. The Knowledge Discovery Meta-model plays the fundamental role in this set of representations as it defines common concepts of software assets and their operational environments. This paper addresses issues related to the extraction of knowledge from the software assets and the representation according to the Knowledge Discovery Meta-model in order to abstract the business logic implemented in the system. It observes that although this meta-model minimizes the effort required to obtain representation, it has several drawbacks that limits its capability to express domain specific knowledge. It is believed that this paper will enable researchers and practitioners to get a better understanding of this kind of representation, prepare for the modernization activities, and provide a basis for the further research.},
booktitle = {Proceedings of the 13th International Conference on Computer Systems and Technologies},
pages = {52–57},
numpages = {6},
keywords = {model-driven reverse engineering, knowledge discovery meta-model, architecture-driven modernization},
location = {Ruse, Bulgaria},
series = {CompSysTech '12}
}

@inproceedings{10.5555/2874916.2874968,
author = {Veynberg, Roman R. and Varfolomeeva, Aleksandra and Grigoryeva, Kseniya},
title = {Intelligent simulation models based on business rules approach in banking sector (WIP)},
year = {2015},
isbn = {9781510810594},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {In this paper, we discuss business rules management systems (BRMS) and their use in bank scoring models. Business rules are considered as an effective tool in determination of trustworthiness and solvency of borrowers, taking into account their socio-demographic and personal characteristics. This article will be informative for scientists in applied IT field, finance, banking, as well as for practicing risk managers and insurers.},
booktitle = {Proceedings of the Conference on Summer Computer Simulation},
pages = {1–6},
numpages = {6},
keywords = {scoring, intelligent system, global rule flow, embedded rule flow, credits, business rules, bank client, BRMS},
location = {Chicago, Illinois},
series = {SummerSim '15}
}

@inproceedings{10.5555/2735522.2735543,
author = {Mat\'{e}, Alejandro and Zoumpatianos, Kostas and Palpanas, Themis and Trujillo, Juan and Mylopoulos, John and Koci, Elvis},
title = {A systematic approach for dynamic targeted monitoring of KPIs},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {There has been growing interest for more than a decade in Business Analytics as a means for improving business performance. One of the most popular Business Analytics technique involves monitoring performance by means of Key Performance Indicators (KPIs). A KPI is a powerful tool that relates enterprise data to business goals, thereby enabling managers to guide the analytic process and identify deviations in their strategic plan. Nevertheless, monitoring KPIs requires that they are evaluated at multiple levels of detail, in order to identify potential problems earlier instead of being noted after the fact. Unfortunately, there are obstacles to the generation and enactment of such monitoring processes. In particular, there is no systematic, tool-supported process for defining what is to be monitored given a strategic plan, nor are there tools for automatically generating monitoring queries. As a result, monitoring consists of a manual process whereby queries are generated for high level indicators across a few scorecards and dashboards. In this paper we present a systematic semi-automatic approach that covers the entire monitoring process. Our approach performs a partial search guided by the KPIs of the company, generating queries required during the monitoring process. Thanks to our approach, users become aware of the existence of problems and where they are located, without requiring a priori information about the nature of the problem being searched. Moreover, we have implemented our approach in our CASE tool HERMES and evaluated the results on a case study using real data.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {192–206},
numpages = {15},
keywords = {monitoring, intelligent search, business intelligence, business analytics, KPI},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/3550356.3561542,
author = {Cabot, Jordi and Delgado, David and Burgue\~{n}o, Lola},
title = {Combining OCL and natural language: a call for a community effort},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561542},
doi = {10.1145/3550356.3561542},
abstract = {The growing popularity and availability of pretrained natural language models opens the door to many interesting applications combining natural language (NL) with software artefacts. A couple of examples are the generation of code excerpts from NL instructions or the verbalization of programs in NL to facilitate their comprehension.Many of these language models have been trained with open source software datasets and therefore "understand" a variety of programming languages, but not OCL.We argue that OCL needs to jump into the machine learning bandwagon or it will risk losing its appeal as a constraint specification language. For that, the key first task is to create together an OCL corpus dataset amenable for natural language processing.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {908–912},
numpages = {5},
keywords = {natural language, dataset, corpus, community, OCL},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2665008.2665036,
author = {Gianni, Daniele and Bocciarelli, Paolo and D'Ambrogio, Andrea},
title = {Temporal capabilities in support of conceptual process modeling using object-role modeling},
year = {2014},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Conceptual data modeling languages must be provided with temporal capabilities to support the data evolution throughout the execution of a conceptual process model. Asides from supporting the storage of historical data, temporal capabilities must also provide the means for verifying the consistency between the data temporal properties and the data modification resulting from the process execution. The Object-Role Modeling (ORM) language is a conceptual data modeling language that is based on the concepts of Fact (i.e. true statements on the represented world), Fact Type, and Fact Base (i.e. the set of all the Facts). Currently, the ORM language does not address the specification of Facts temporal properties, and therefore does not also support the verification of Facts variations during a process execution. The paper introduces an initial ORM overlay methodology that aims to laying the foundation of the conceptual modeling structures that can support the verification of temporal evolution of conceptual data models (i.e., whether a Fact can be asserted or retracted, depending on its temporal properties). Moreover, the overlay methodology also defines a temporal visual notation and an initial semi-formal temporal verbalization that eases the use of the methodology to the ORM modelers. A simple example illustrates the potential application of the overlay methodology.},
booktitle = {Proceedings of the Symposium on Theory of Modeling &amp; Simulation - DEVS Integrative},
articleno = {28},
numpages = {6},
keywords = {temporal modeling, process modeling, object-role modeling, conceptual data modeling},
location = {Tampa, Florida},
series = {DEVS '14}
}

@inproceedings{10.1145/2072221.2072247,
author = {Solms, Fritz and Edwards, Craig and Paar, Alexander and Gruner, Stefan},
title = {A domain-specific language for URDAD based requirements elicitation},
year = {2011},
isbn = {9781450308786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072221.2072247},
doi = {10.1145/2072221.2072247},
abstract = {Use-Case Responsibility-Driven Analysis and Design (URDAD) is a service-oriented software analysis and design methodology. It is used by requirements engineers to develop technology-neutral, semi-formal platform-independent models (PIM) within the OMG's MDA. In the past, URDAD models were denoted in UML. However, that was tedious and error-prone. The resulting models were often of rather poor quality. In this paper we introduce and discuss a new Domain-Specific Language (DSL) for URDAD. Its meta model is consistent and satisfiable. We show that URDAD DSL specifications are simpler and allow for more complete service contract specifications than their corresponding UML expressions. They also enable traceability and test case generation.},
booktitle = {Proceedings of the South African Institute of Computer Scientists and Information Technologists Conference on Knowledge, Innovation and Leadership in a Diverse, Multidisciplinary Environment},
pages = {224–230},
numpages = {7},
keywords = {service orientation, requirements engineering, platform independent model, model driven development, meta model, domain specific language},
location = {Cape Town, South Africa},
series = {SAICSIT '11}
}

@inproceedings{10.1145/1750405.1750419,
author = {Bollen, Peter},
title = {Enterprise modeling in a service oriented architecture},
year = {2009},
isbn = {9781450373012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1750405.1750419},
doi = {10.1145/1750405.1750419},
abstract = {Service-oriented computing (SOC) is a new paradigm that allows organizations to tailor their business processes, in such a way that efficiency and effectiveness goals will be achieved by outsourcing (parts of) business processes to web-based service-providers. In order to find the computing service-providers that provide the organizations with the biggest benefits, it is paramount that the service-requesting organization (SRO) has a precise description of the service it wants to have delivered by the service delivering organization (SDO). In this paper we will illustrate how enterprises that play the SDO and SRO roles can be conceptually integrated by creating conceptual models that share the definitions of the business processes within the service oriented architecture (SOA) framework.},
booktitle = {Proceedings of the International Workshop on Enterprises &amp; Organizational Modeling and Simulation},
articleno = {12},
numpages = {15},
keywords = {service-oriented architecture, object-role modeling, fact-orientation, SOA, ORM},
location = {Amsterdam, The Netherlands},
series = {EOMAS '09}
}

@inproceedings{10.5555/2527198.2527199,
author = {Schrefl, Michael and Neumayr, Bernd and Stumptner, Markus},
title = {The decision-scope approach to specialization of business rules: application in business process modeling and data warehousing},
year = {2013},
isbn = {9781921770289},
publisher = {Australian Computer Society, Inc.},
address = {AUS},
abstract = {It is common in organizational contexts and in law to apply a decision-scope approach to decision making. Higher organization levels set a decision scope within which lower organization levels may operate. In case of conflict the regulations and rules of a higher level (e.g. European Union) take precedence over those of a lower level (e.g. a member state). This approach can also be beneficially applied to the specialization of the most important kind of business rules in information systems, action rules. Such rules define under which conditions certain actions may, must not, or need to be taken.Applying the decision scope approach to business process modeling based on BPMN means that business rules should not be buried in decision tasks but be made explicit at the flow level. This requires a rethinking of the current BPMN modeling paradigm in that several aspects in conditional flow so far modeled jointly are separately captured: (a) potential ordering of tasks, (b) conditions under which a task may or may not be invoked, and (c) conditions under which a particular task needs to be invoked. Rather than re-defining BPMN as such, an appropriate extension may be provided on-top of BPMN and mapped to standard BPMN primitives.Applying the decision scope approach to active data warehousing, where analysis rules express actionable knowledge, requires to consider two alternative hierarchies: (1) hierarchies of sets of points at the same granularity and (2) the roll-up hierarchy of points in multi-dimensional space.This paper presents the decision scope approach, outlines how it complements inheritance and specialization approaches typically followed in object-oriented systems, and introduces consistency rules for business rule specialization as well as auto-correction rules, which rectify an inconsistent lower-level business rule such that it becomes consistent with higher-level business rules.},
booktitle = {Proceedings of the Ninth Asia-Pacific Conference on Conceptual Modelling - Volume 143},
pages = {3–18},
numpages = {16},
keywords = {specialization, inheritance, data warehousing, business rules, business processes, BPMN},
location = {Adelaide, Australia},
series = {APCCM '13}
}

@inproceedings{10.5555/2662398.2662404,
author = {Attwood, Katrina and Conmy, Philippa},
title = {Nuanced term-matching to assist in compositional safety assurance},
year = {2013},
isbn = {9781467363242},
publisher = {IEEE Press},
abstract = {Increased complexity in the design, technology and supply chains for software-intensive safety-critical systems has resulted in a growing demand for a compositional approach to safety assurance. Assurance data relating to independently-derived components must be melded together into a compelling case for overall system safety. One of the barriers to composition is the lack of consistency in the terminology used to describe and share assurance data. Linguistic mismatches highlight various problems for the composition of peer modules and their integration into an overall case. In this paper, we propose the application of a linguistic model of understanding to identify mismatches and to provide guidance on composition and integration. The approach is illustrated using a simple example.},
booktitle = {Proceedings of the 1st International Workshop on Assurance Cases for Software-Intensive Systems},
pages = {18–23},
numpages = {6},
keywords = {natural language, goal structuring notation, compositional safety assurance, component},
location = {San Francisco, California},
series = {ASSURE '13}
}

@inproceedings{10.1145/1814392.1814398,
author = {Goknil, Arda and Kurtev, Ivan and van den Berg, Klaas},
title = {Tool support for generation and validation of traces between requirements and architecture},
year = {2010},
isbn = {9781605589930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1814392.1814398},
doi = {10.1145/1814392.1814398},
abstract = {Traceability is considered crucial for establishing and maintaining consistency between software development artifacts. Although considerable research has been devoted to relating requirements and design artifacts with source code, less attention has been paid to relating requirements with architecture by using well-defined semantics of traces. We present a tool that provides trace establishment by using semantics of traces between R&amp;A (Requirements and Architecture). The tool provides the following: (1) generation/validation of traces by using requirements relations and/or verification of architecture, (2) generation/validation of requirements relations by using traces. The tool uses the semantics of traces together with requirements relations and verification results for generating and validating traces. It is based on model transformations in ATL and term-rewriting logic in Maude.},
booktitle = {Proceedings of the 6th ECMFA Traceability Workshop},
pages = {39–46},
numpages = {8},
keywords = {traceability, tools, requirements and architectural models, generation and validation of traces, architecture verification},
location = {Paris, France},
series = {ECMFA-TW '10}
}

@inproceedings{10.1145/3019612.3019619,
author = {Costa, Mateus Barcellos and Tamzalit, Dalila},
title = {Recommendation patterns for business process imperative modeling},
year = {2017},
isbn = {9781450344869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3019612.3019619},
doi = {10.1145/3019612.3019619},
abstract = {With the wide acceptance of the Imperative Business Process Modeling, supporting this activity has becoming increasingly important. In this sense, the difficulties faced by modelers while mapping business concerns into correct process models is a key issue. This paper presents the idea of Imperative Modeling Recommendation Patterns in order to tackle this issue. Recommendation Patterns aim at supporting modelers to decide between modeling structure options while preserving both process and modeling concerns. By doing so, these patterns enable the achievement of correct modeling solutions without, however, forcing a unique solution. The application of the Recommendation Patterns is discussed in the context of a methodology for Business Process Imperative Modeling support.},
booktitle = {Proceedings of the Symposium on Applied Computing},
pages = {735–742},
numpages = {8},
keywords = {recommendation methodology, modeling, business processes},
location = {Marrakech, Morocco},
series = {SAC '17}
}

@inproceedings{10.1145/1839707.1839729,
author = {Barnickel, Nils and B\"{o}ttcher, Johannes and Paschke, Adrian},
title = {Incorporating semantic bridges into information flow of cross-organizational business process models},
year = {2010},
isbn = {9781450300148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1839707.1839729},
doi = {10.1145/1839707.1839729},
abstract = {In this paper we propose an approach for incorporating semantic bridges into cross-organizational business process models to facilitate information flow design across heterogeneous conceptualizations. Independent corporate ontology-based information models are exploited for explicit semantic modeling of information flow within each organization. Furthermore, description logic rule-based semantic bridges are applied in the design phase to enable an automated mediation between the different corporate conceptualizations. This allows for seamless information flow design across organizational borders, as well as for mediation between the abstract business perspective and the underlying IT perspective. We prototyped the approach as a functional extension to an existing BPMN modeling editor and perform an experts-driven evaluation based on a cross-organizational e-business scenario.},
booktitle = {Proceedings of the 6th International Conference on Semantic Systems},
articleno = {17},
numpages = {9},
keywords = {semantic mediation, semantic business process management, ontology mapping, loosely-coupled information models, business-IT alignment},
location = {Graz, Austria},
series = {I-SEMANTICS '10}
}

@inproceedings{10.5555/3351736.3351781,
author = {Kulkarni, Vinay and Barat, Souvik and Clark, Tony and Barn, Balbir},
title = {Toward overcoming accidental complexity in organisational decision-making},
year = {2015},
isbn = {9781467369084},
publisher = {IEEE Press},
abstract = {This paper takes a practitioner's perspective on the problem of organisational decision-making. Industry practice follows a refinement based iterative method for organizational decision-making. However, existing enterprise modelling tools are not complete with respect to the needs of organizational decision-making. As a result, today, a decision maker is forced to use a chain of non-interoperable tools supporting paradigmatically diverse modelling languages with the onus of their co-ordinated use lying entirely on the decision maker. This paper argues the case for a model-based approach to overcome this accidental complexity. A bridge meta-model, specifying relationships across models created by individual tools, ensures integration and a method, describing what should be done when and how, and ensures better tool integration. Validation of the proposed solution using a case study is presented with current limitations and possible means of overcoming them outlined.},
booktitle = {Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems},
pages = {368–377},
numpages = {10},
keywords = {organizational decision making, method, meta modelling, enterprise modeling tools},
location = {Ottawa, Ontario, Canada},
series = {MODELS '15}
}

@inproceedings{10.1145/3021460.3021462,
author = {Barat, Souvik and Clark, Tony and Barn, Balbir and Kulkarni, Vinay},
title = {A Model-Based Approach to Systematic Review of Research Literature},
year = {2017},
isbn = {9781450348560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3021460.3021462},
doi = {10.1145/3021460.3021462},
abstract = {A systematic approach to develop a literature review is attractive because it aims to achieve a repeatable, unbiased and evidence-based outcome. However the existing form of systematic review such as Systematic Literature Review (SLR) and Systematic Mapping Study (SMS) are known to be an effort, time, and intellectual intensive endeavour. To address these issues, this paper proposes a model-based approach to Systematic Review (SR) production. The approach uses a domain-specific language expressed as a meta-model to represent research literature, a meta-model to specify SR constructs in a uniform manner, and an associated development process all of which can benefit from computer-based support. The meta-models and process are validated using real-life case study. We claim that the use of meta-modeling and model synthesis lead to a reduction in time, effort and the current dependence on human expertise.},
booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
pages = {15–25},
numpages = {11},
keywords = {Systematic Mapping Study, Systematic Literature Review, Model Based Literature Review, Meta Modeling, Literature Review},
location = {Jaipur, India},
series = {ISEC '17}
}

@inproceedings{10.1145/3229147.3229166,
author = {Giunchi, Daniele and James, Stuart and Steed, Anthony},
title = {3D sketching for interactive model retrieval in virtual reality},
year = {2018},
isbn = {9781450358927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229147.3229166},
doi = {10.1145/3229147.3229166},
abstract = {We describe a novel method for searching 3D model collections using free-form sketches within a virtual environment as queries. As opposed to traditional sketch retrieval, our queries are drawn directly onto an example model. Using immersive virtual reality the user can express their query through a sketch that demonstrates the desired structure, color and texture. Unlike previous sketch-based retrieval methods, users remain immersed within the environment without relying on textual queries or 2D projections which can disconnect the user from the environment. We perform a test using queries over several descriptors, evaluating the precision in order to select the most accurate one. We show how a convolutional neural network (CNN) can create multi-view representations of colored 3D sketches. Using such a descriptor representation, our system is able to rapidly retrieve models and in this way, we provide the user with an interactive method of navigating large object datasets. Through a user study we demonstrate that by using our VR 3D model retrieval system, users can perform search more quickly and intuitively than with a naive linear browsing method. Using our system users can rapidly populate a virtual environment with specific models from a very large database, and thus the technique has the potential to be broadly applicable in immersive editing systems.},
booktitle = {Proceedings of the Joint Symposium on Computational Aesthetics and Sketch-Based Interfaces and Modeling and Non-Photorealistic Animation and Rendering},
articleno = {1},
numpages = {12},
keywords = {virtual reality, sketch, HCI, CNN},
location = {Victoria, British Columbia, Canada},
series = {Expressive '18}
}

@inproceedings{10.1145/2514601.2514605,
author = {Boella, Guido and Janssen, Marijn and Hulstijn, Joris and Humphreys, Llio and van der Torre, Leendert},
title = {Managing legal interpretation in regulatory compliance},
year = {2013},
isbn = {9781450320801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2514601.2514605},
doi = {10.1145/2514601.2514605},
abstract = {Maintaining regulatory compliance is an increasing area of concern for business. Legal Knowledge Management systems that combine repositories of legislation with legal ontologies can support the work of in-house compliance managers. But there are challenges to overcome, of interpreting legal knowledge and mapping that knowledge onto business processes, and developing systems that can adequately handle the complexity with clarity and ease. In this paper we extend the Legal Knowledge Management system Eunomos to deal with alternative interpretations of norms connecting it with Business Process Management systems. Moreover, we propose a workflow involving the different roles in a company, which takes legal interpretation into account in mapping norms and processes, using Eunomos as a support.},
booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law},
pages = {23–32},
numpages = {10},
location = {Rome, Italy},
series = {ICAIL '13}
}

@inproceedings{10.1145/3086512.3086528,
author = {Neill, James O' and Buitelaar, Paul and Robin, Cecile and Brien, Leona O'},
title = {Classifying sentential modality in legal language: a use case in financial regulations, acts and directives},
year = {2017},
isbn = {9781450348911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3086512.3086528},
doi = {10.1145/3086512.3086528},
abstract = {Texts expressed in legal language are often difficult and time consuming for lawyers to read through, particularly for the purpose of identifying relevant deontic modalities (obligations, prohibitions and permissions). By nature, the language of law is strict, hence the predominant use of modal logic as a substitute for the syntactical ambiguity in natural language, specifically, deontic and alethic logic for the respective modalities. However, deontic modalities which express obligations, prohibitions and permissions, can have varying degree and preciseness to which they correspond to a matter, strict deontic logic does not allow for such quantitative measures. Therefore, this paper outlines a data-driven approach by classifying deontic modalities using ensembled Artificial Neural Networks (ANN) that incorporate domain specific legal distributional semantic model (DSM) representations, in combination with, a general DSM representation. We propose to use well calibrated probability estimates from these classifiers as an approximation to the degree which an obligation/prohibition or permission belongs to a given class based on SME annotated sentences. Best results show 82.33 % accuracy on a held-out test set.},
booktitle = {Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law},
pages = {159–168},
numpages = {10},
keywords = {sentence classification, financial law, deontic modality},
location = {London, United Kingdom},
series = {ICAIL '17}
}

@inproceedings{10.5555/2486788.2486883,
author = {Petre, Marian},
title = {UML in practice},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {UML has been described by some as "the lingua franca" of software engineering. Evidence from industry does not necessarily support such endorsements. How exactly is UML being used in industry if it is? This paper presents a corpus of interviews with 50 professional software engineers in 50 companies and identifies 5 patterns of UML use.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {722–731},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@article{10.1145/2685615,
author = {Lara, Juan De and Guerra, Esther and Cuadrado, Jes\'{u}s S\'{a}nchez},
title = {When and How to Use Multilevel Modelling},
year = {2014},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/2685615},
doi = {10.1145/2685615},
abstract = {Model-Driven Engineering (MDE) promotes models as the primary artefacts in the software development process, from which code for the final application is derived. Standard approaches to MDE (like those based on MOF or EMF) advocate a two-level metamodelling setting where Domain-Specific Modelling Languages (DSMLs) are defined through a metamodel that is instantiated to build models at the metalevel below.Multilevel modelling (also called deep metamodelling) extends the standard approach to metamodelling by enabling modelling at an arbitrary number of metalevels, not necessarily two. Proposers of multilevel modelling claim this leads to simpler model descriptions in some situations, although its applicability has been scarcely evaluated. Thus, practitioners may find it difficult to discern when to use it and how to implement multilevel solutions in practice.In this article, we discuss those situations where the use of multilevel modelling is beneficial, and identify recurring patterns and idioms. Moreover, in order to assess how often the identified patterns arise in practice, we have analysed a wide range of existing two-level DSMLs from different sources and domains, to detect when their elements could be rearranged in more than two metalevels. The results show this scenario is not uncommon, while in some application domains (like software architecture and enterprise/process modelling) pervasive, with a high average number of pattern occurrences per metamodel.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {dec},
articleno = {12},
numpages = {46},
keywords = {multilevel modelling, metamodelling patterns, metamodelling, domain-specific modelling languages, Model-driven engineering}
}

@article{10.1145/2994205.2994214,
author = {Sharma, Richa and Sureka, Ashish},
title = {A Nine Year Story of the India Software Engineering Conference from 2008 to 2016},
year = {2016},
issue_date = {September 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2994205.2994214},
doi = {10.1145/2994205.2994214},
abstract = {The India Software Engineering Conference (ISEC) is an annual conference in the field of Software Engineering (SE) in India. ISEC started in the year 2008 and completed 9 years in 2016. The ISEC conference has evolved into a high-quality academic event for SE researchers from universities and industry in India with considerable international participation. Assessment and evaluation of ISEC conference quality, status and evolution is important for the national SE scientific community, ISEC steering committee, sponsors and science and technology-related government bodies. In this paper, we conduct scientific paper publication mining and scientometric and bibliometric analysis of 9 years of ISEC publications and programs. We conduct an in-depth multi-dimensional analysis of the conference across various aspects such as a summary of 9 years of ISEC programs (paper submission data, tutorials, workshops, keynotes, invited talks, geographical location, program and general chairs), author-affiliation-based geographical contribution (analysis at the international and national levels), topic analysis, university and industry collaborations, contributions across university types in India, prolific and new authors, gender equality and imbalance, program committee characteristics, open-source or closed-source datasets and citation-based impact. We also present our recommendations for future editions of the ISEC based on our comprehensive analysis study presented in this paper.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {31–44},
numpages = {14},
keywords = {University and Industry Collaboration, Software Engineering, Scientific Paper Publication Mining, Research Assessment, Conference Review, Conference Citation and Impact, Bibliometric Analysis}
}

