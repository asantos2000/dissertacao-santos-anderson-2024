@article{10.1145/3502289,
author = {Cao, Longbing},
title = {AI in Finance: Challenges, Techniques, and Opportunities},
year = {2022},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3502289},
doi = {10.1145/3502289},
abstract = {AI in finance refers to the applications of AI techniques in financial businesses. This area has attracted attention for decades, with both classic and modern AI techniques applied to increasingly broader areas of finance, economy, and society. In contrast to reviews on discussing the problems, aspects, and opportunities of finance benefited from specific or some new-generation AI and data science (AIDS) techniques or the progress of applying specific techniques to resolving certain financial problems, this review offers a comprehensive and dense landscape of the overwhelming challenges, techniques, and opportunities of AIDS research in finance over the past decades. The challenges of financial businesses and data are first outlined, followed by a comprehensive categorization and a dense overview of the decades of AIDS research in finance. We then structure and illustrate the data-driven analytics and learning of financial businesses and data. A comparison, criticism, and discussion of classic versus modern AIDS techniques for finance follows. Finally, the open issues and opportunities to address future AIDS-empowered finance and finance-motivated AIDS research are discussed.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {64},
numpages = {38},
keywords = {smart FinTech, AI in finance, AI in FinTech, FinTech, economics, finance, modeling, mathematics, statistics, machine learning, advanced analytics, data analytics, data science, AI}
}

@inproceedings{10.5555/3566055.3566078,
author = {Hamdani, Syed Waqas and Brealey, Chris and Kontogiannis, Kostas and Giammaria, Alberto},
title = {Evaluating the Impact of NIST 800.53 Security Control Violations},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {In today's data-driven world, an Information System, particularly in a regulated industry, will require a comprehensive security frame­work such as NIST 800.53 to protect against loss of confidentiality, integrity, or availability of data, whether due to malice, accident, or otherwise. Once such a security framework is in place, an organi­zation must constantly monitor and assess the overall compliance of that framework to detect and rectify any issues found. In this short paper we will present initial findings and a novel approach to assess the impact a failed security control has on other controls and evaluate the security risk due to such failed controls. The approach is based first on modeling the dependencies between the different controls in the NIST 800.53 protocol by compiling a corresponding dependency multi-graph, second on devising a risk assessment tech­nique that traverses such a multi-graph and assigning an overall security exposure score when one or more controls fail, and third on identifying those attack strategies against which an organization should defend itself. This research provides organizations with an ability to have a bird's-eye view of its Information System cyber security posture and help triage the security control checks in the most vulnerable parts of the Information System.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {187–192},
numpages = {6},
keywords = {NIST 800.53, Security Controls, Compliance, Risk Analysis, System Security},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1145/3511808.3557498,
author = {Demartini, Gianluca and Yang, Jie and Sadiq, Shazia},
title = {Workshop on Human-in-the-loop Data Curation},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557498},
doi = {10.1145/3511808.3557498},
abstract = {Although data quality is a long-standing and enduring problem, it has recently received a resurgence of attention due to the fast proliferation of data analytics, machine learning, and decision-support applications built upon the wide-scale availability and accessibility of (big) data. The success of such applications heavily relies on not only the quantity, but also the quality of data. Data curation, which may include annotation, cleaning, transformation, integration, etc., is a critical step to provide adequate assurances on the quality of analytics and machine learning results. Such data preparation activities are recognised as time and resource intensive for data scientists as data often comes with a number of challenges that need to be tackled before it can be used in practice. Data re-purposing and the resulting distance between design and use intentions of the data, is a fundamental issue behind many of these challenges. These challenges include a variety of data issues such as noise and outliers, incompleteness, representativeness or biases, heterogeneity of format or semantics, etc. Mishandling these challenges can lead to negative and sometimes damaging effects, especially in critical domains like healthcare, transport, and finance. An observable distinct feature of data quality in these contexts is the increasingly important role played by humans, being often the source of data generation and the active players in data curation. This workshop will provide an opportunity to explore the interdisciplinary overlap between manual, automated, and hybrid human-machine methods of data curation.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {5161–5162},
numpages = {2},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1109/ICSE-SEIS.2019.19,
author = {Lago, Patricia},
title = {Architecture design decision maps for software sustainability},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS.2019.19},
doi = {10.1109/ICSE-SEIS.2019.19},
abstract = {In software engineering, sustainability can be defined as the "capacity to endure" and to "preserve the function of a system over an extended period of time". These definitions mainly point towards technical sustainability over time. Sustainability, however, may entail a much broader scope including economic, social and environmental sustainability as well.In spite of the exciting hype around sustainability, we are very much lacking suitable instruments to design software-intensive systems that are sustainable and enable sustainability goals. To fill this gap, we advocate the treatment of sustainability as a software quality property and define a software sustainability assessment method that helps make sustainability-driven design decisions. The method essentially relies on the definition of so-called decision maps, i.e. views aimed at framing the architecture design concerns around the four sustainability dimensions mentioned above - technical, economic, social and environmental sustainability. This paper presents the notion of decision map. We use two illustrative examples extracted from industrial projects, to summarize our lessons learned and reflections.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Society},
pages = {61–64},
numpages = {4},
keywords = {sustainability, software architecture, decision map, architecture design decisions, architecture assessment},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIS '19}
}

@inproceedings{10.1145/3452383.3452405,
author = {Parashar, Dhruv and Sanagavarapu, Lalit Mohan and Reddy, Y. Raghu},
title = {SQL Injection Vulnerability Identification from Text},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452405},
doi = {10.1145/3452383.3452405},
abstract = {Increasing usage of Information Technology (IT) applications in distributed environment is leading to an increase in security exploits. Vulnerabilities related information is also available on open web in an unstructured format that developers may leverage to fix security weaknesses in their IT applications. SQL Injection (SQLi) is one of the topmost vulnerabilities impacting the security of IT applications. We propose an approach to identify information about SQLi in text using text summarization to process any length of text, and a supervised machine learning model to automate the classification of SQLi. To validate the proposed approach, we created a dataset of 100,019 entries that includes 50,010 entries of SQLi from the National Vulnerability Database, 25,010 near negatives related to other cyber security vulnerabilities, and 24,999 data entries that are unrelated to cyber security. The selected Random Forest model was also tested identify SQLi from Web and Twitter text.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {22},
numpages = {5},
keywords = {Cyber Security, SQL Injection, Supervised Learning, Unstructured Text},
location = {<conf-loc>, <city>Bhubaneswar, Odisha</city>, <country>India</country>, </conf-loc>},
series = {ISEC '21}
}

@inproceedings{10.1145/3457784.3457826,
author = {Maria Bruma, Livia},
title = {Using Cloud Control Matrix to evaluate trust in cloud providers},
year = {2021},
isbn = {9781450388825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457784.3457826},
doi = {10.1145/3457784.3457826},
abstract = {The increase in the number of users of cloud has led to an increase in the number of providers of this technology. The decision to migrate resources to cloud should be made after going through a process that provides relevant information about the security, availability, financial values involved, implicitly the trust that consumers can have in cloud service providers. In the first part of this article is presented the main methods for verifying trust in suppliers, following the proposal of a framework model for analyzing the parameters that can provide information on trust in CSP. In the second part of the article is proposed, a method of using CCM (Cloud control matrix) and CAIQ-Lite (Consensus Assessment Initiative Questionnaire) tools to determine a minimum level of CSP confidence.},
booktitle = {Proceedings of the 2021 10th International Conference on Software and Computer Applications},
pages = {273–278},
numpages = {6},
keywords = {trustworthy, information security, cloud control matrix, cloud computing},
location = {Kuala Lumpur, Malaysia},
series = {ICSCA '21}
}

@inproceedings{10.1145/3241403.3241458,
author = {Ahmed, Yussuf and Naqvi, Syed and Josephs, Mark},
title = {Aggregation of security metrics for decision making: a reference architecture},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241458},
doi = {10.1145/3241403.3241458},
abstract = {Existing security technologies play a significant role in protecting enterprise systems but they are no longer enough on their own given the number of successful cyberattacks against businesses and the sophistication of the tactics used by attackers to bypass the security defences. Security measurement is different to security monitoring in the sense that it provides a means to quantify the security of the systems while security monitoring helps in identifying abnormal events and does not measure the actual state of an infrastructure's security. The goal of enterprise security metrics is to enable understanding of the overall security using measurements to guide decision making. In this paper we present a reference architecture for aggregating the measurement values from the different components of the system in order to enable stakeholders to see the overall security state of their enterprise systems and to assist with decision making. This will provide a newer dimension to security management by shifting from security monitoring to security measurement.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {53},
numpages = {7},
keywords = {security metrics, security measurements, reference architecture, network security, information security},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3537693.3537745,
author = {Gilberta, Gisela and Widuri, Rindang and Kasenda, Faris},
title = {Factors Affecting the Implementation of Remote Audit in the Audit Process in the COVID-19 Pandemic},
year = {2022},
isbn = {9781450396523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3537693.3537745},
doi = {10.1145/3537693.3537745},
abstract = {This study aims to analyze the factors that affect the implementation of a remote audit with the UTAUT model. This study uses a survey method for data collection and uses SmartPLS 3 for data processing. The population of this study is auditors who work at a Public Accounting Firm in DKI Jakarta and use remote auditing while working. A sample of 90 respondents was obtained by purposive sampling. The results showed that the convenience of online access, performance expectations, and social influences significantly affected behavioral intentions. However, effort expectations had no significant impact on behavioral intentions. This study also shows that behavioral intentions significantly affect usage behavior, while the facilitation condition has no significant effect on the behavior of using remote audits.},
booktitle = {Proceedings of the 6th International Conference on E-Commerce, E-Business and E-Government},
pages = {318–324},
numpages = {7},
keywords = {Remote Audit, Pandemic, Audit Process},
location = {Plymouth, United Kingdom},
series = {ICEEG '22}
}

@inproceedings{10.1145/3325917.3325923,
author = {Onwujekwe, Gerald and Thomas, Manoj and Osei-Bryson, Kweku-Muata},
title = {Using Robust Data Governance to Mitigate the Impact of Cybercrime},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325917.3325923},
doi = {10.1145/3325917.3325923},
abstract = {The Deloitte's report (2015) on cybersecurity trends states that emerging technologies, coupled with a shifting threat profile, are challenging organizations to deal more and more with sophisticated "bad actors" that are motivated, skilled, and adaptable [1]. There is little doubt that cybercrime is growing more rapidly than cybersecurity measures are able to deal with and businesses and governments have never been more at risk from cyberattacks. In this paper, we ask the question, 'what are some of the robust data governance practices that can be put in place to forestall cybercrime?' We also asked the question, 'are there some research papers that have been published to address this concern? We then took a deep into extant literature to find out. Furthermore, we proposed a cybercrime mitigation framework using robust data governance. Our literature synthesis revealed that there is little research that investigated the concept of data governance and cybercrime together, which leads us to propose research hypotheses for a future quantitative research.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {70–79},
numpages = {10},
keywords = {cybersecurity, cybercrime, cyberattack, cyber threat, Data governance},
location = {Houston, TX, USA},
series = {ICISDM '19}
}

@article{10.1145/3558766,
author = {Sim, Junsik and Kim, Beomjoong and Jeon, Kiseok and Joo, Moonho and Lim, Jihun and Lee, Junghee and Choo, Kim-Kwang Raymond},
title = {Technical Requirements and Approaches in Personal Data Control},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3558766},
doi = {10.1145/3558766},
abstract = {There has been a trend of moving from simply de-identification to providing extended data control to their owner (e.g., data portability and right to be forgotten), partly due to the introduction of the General Data Protection Regulation (GDPR). Hence, in this paper, we survey the literature to provide an in-depth understanding of the existing approaches for personal data control (e.g., we observe that most existing approaches are generally designed to facilitate compliance), as well as the privacy regulations in Europe, United Kingdom, California, South Korea, and Japan. Based on the review, we identify the associated technical requirements, as well as a number of research gaps and potential future directions (e.g., the need for transparent processing of personal data and establishment of clear procedure in ensuring personal data control).},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {190},
numpages = {30},
keywords = {compliance, control rights, Personal data}
}

@article{10.1145/3623401,
author = {Tang, Hao and Wang, Cheng and Zheng, Jianguo and Jiang, Changjun},
title = {Enabling Graph Neural Networks for Semi-Supervised Risk Prediction in Online Credit Loan Services},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3623401},
doi = {10.1145/3623401},
abstract = {Graph neural networks (GNNs) are playing exciting roles in the application scenarios where features are hidden in information associations. Fraud prediction of online credit loan services (OCLSs) is such a typical scenario. But it has another rather critical challenge, i.e., the scarcity of data labels. Fortunately, GNNs can also cope with this problem due to their good ability of semi-supervised learning by mining structure and feature information within graphs. Nevertheless, the gain of internal information is often too limited to help GNNs handle the extreme deficiency of labels with high performance beyond the basic requirement of fraud prediction in OCLSs. Therefore, adding labels from the experts, such as manually adding labels through rules, has become a logical practice. However, the existing rule engines for OCLSs have the confliction problem among continuously accumulated rules. To address this issue, we propose a Snorkel-based Semi-Supervised GNN (S3GNN). Under S3GNN, we specially design an upgraded version of the rule engines, called Graph-Oriented Snorkel (GOS), a graph-specific extension of Snorkel, a widely used weakly supervised learning framework, to design rules by subject matter experts (SMEs) and resolve confliction. In particular, in the graph of an anti-fraud scenario, each node pair may have multiple different types of edges, so we propose the Multiple Edge-Types Based Attention mechanism. In general, for the heterogeneous information and multiple relations in the graph, we first obtain the embedding of applicant nodes by aggregating the representation of attribute nodes, and then use the attention mechanism to aggregate neighbor nodes on multiple meta-paths to get ultimate applicant node embedding. We conduct experiments over the real-life data of a large financial platform. The results demonstrate that S3GNN can outperform the state-of-the-art methods, including the method of pilot platform.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {jan},
articleno = {13},
numpages = {24},
keywords = {online credit loan services, weak supervision, graph neural networks, Fraud prediction}
}

@inproceedings{10.1145/3530190.3534846,
author = {Jaigirdar, Fariha Tasmin and Rudolph, Carsten and Rashed, Rayhan and Uddin, Nahiyan and Bain, Chris and Islam, A. B. M. Alim Al},
title = {NOTE: Unavoidable Service to Unnoticeable Risks: A Study on How Healthcare Record Management Opens the Doors of Unnoticeable Vulnerabilities for Rohingya Refugees},
year = {2022},
isbn = {9781450393478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530190.3534846},
doi = {10.1145/3530190.3534846},
abstract = {Secure management of healthcare records in dynamic contexts requires an understanding of the overall infrastructure of record flows and poses more challenges for vulnerable environments such as amongst the Rohingya refugees in Bangladesh. Understanding the overall infrastructure of how health clinics are providing medical treatments and how they are collecting and storing patient records is crucial as any changes or mismanagement in these records enables misuse or deliberate misinterpretations of medical data on various levels amongst individuals and Rohingya communities. Through an extensive field study in the Rohingya refugee camps in Bangladesh, we explored the management of healthcare records in different organizations. Over the course of our fieldwork, we interviewed 22 medical service providers from nine healthcare organizations connected to the Rohingya camps. Based on our findings, we design an abstract record management model and analyze it using a data provenance approach to identify the limitations of the existing record management. Our study shows vulnerabilities in ID management and security practices in healthcare record management. We further illustrate potential exploitation of these vulnerabilities through political, financial, and social lenses. To the best of our knowledge, this study is the first to discuss vulnerabilities in Rohingya refugees’ medical record management from political, social and economic views.},
booktitle = {Proceedings of the 5th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {614–622},
numpages = {9},
keywords = {risks associated with healthcare record management, healthcare record management, Rohingya refugee in Bangladesh},
location = {Seattle, WA, USA},
series = {COMPASS '22}
}

@inproceedings{10.1145/3341105.3373855,
author = {Koch, Simon and Sauer, Tim and Johns, Martin and Pellegrino, Giancarlo},
title = {Raccoon: automated verification of guarded race conditions in web applications},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373855},
doi = {10.1145/3341105.3373855},
abstract = {Web applications are distributed, asynchronous applications that can span multiple concurrent processes. They are intended to be used by a large amount of users at the same time. As concurrent applications, web applications have to account for race conditions that may occur when database access happens concurrently. Unlike vulnerability classes, such as XSS or SQL Injection, dbms based race condition flaws have received little attention even though their impact is potentially severe. In this paper, we present Raccoon, an automated approach to detect and verify race condition vulnerabilities in web application. Raccoon identifies potential race conditions through interleaving execution of user traces while tightly monitoring the resulting database activity. Based on our methodology we create a proof of concept implementation. We test four different web applications and ten use cases and discover six race conditions with security implications. Raccoon requires neither security expertise nor knowledge about implementation or database layout, while only reporting vulnerabilities, in which the tool was able to successfully replicate a practical attack. Thus, Raccoon complements previous approaches that did not verify detected possible vulnerabilities.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1678–1687},
numpages = {10},
keywords = {web application security testing, race conditions},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3340764.3344897,
author = {Schweigert, Robin and Schwind, Valentin and Mayer, Sven},
title = {EyePointing: A Gaze-Based Selection Technique},
year = {2019},
isbn = {9781450371988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340764.3344897},
doi = {10.1145/3340764.3344897},
abstract = {Interacting with objects from a distance is not only challenging in the real world but also a common problem in virtual reality (VR). One issue concerns the distinction between attention for exploration and attention for selection -- also known as the Midas-touch problem. Researchers proposed numerous approaches to overcome that challenge using additional devices, gaze input cascaded pointing, and using eye blinks to select the remote object. While techniques such as MAGIC pointing still require additional input for confirming a selection using eye gaze and, thus, forces the user to perform unnatural behavior, there is still no solution enabling a truly natural and unobtrusive device free interaction for selection. In this paper, we propose EyePointing: a technique which combines the MAGIC pointing technique and the referential mid-air pointing gesture to selecting objects in a distance. While the eye gaze is used for referencing the object, the pointing gesture is used as a trigger.},
booktitle = {Proceedings of Mensch Und Computer 2019},
pages = {719–723},
numpages = {5},
keywords = {selection technique, ray casting, mid-air pointing, eye tracking, MAGIC pointing},
location = {Hamburg, Germany},
series = {MuC '19}
}

@article{10.5555/3291125.3291163,
author = {Yousefi, Niloofar and Lei, Yunwen and Kloft, Marius and Mollaghasemi, Mansooreh and Anagnostopoulos, Georgios C.},
title = {Local rademacher complexity-based learning guarantees for multi-task learning},
year = {2018},
issue_date = {January 2018},
publisher = {JMLR.org},
volume = {19},
number = {1},
issn = {1532-4435},
abstract = {We show a Talagrand-type concentration inequality for Multi-Task Learning (MTL), with which we establish sharp excess risk bounds for MTL in terms of the Local Rademacher Complexity (LRC). We also give a new bound on the LRC for any norm regularized hypothesis classes, which applies not only to MTL, but also to the standard Single-Task Learning (STL) setting. By combining both results, one can easily derive fast-rate bounds on the excess risk for many prominent MTL methods, including--as we demonstrate--Schatten norm, group norm, and graph regularized MTL. The derived bounds reflect a relationship akin to a conservation law of asymptotic convergence rates. When compared to the rates obtained via a traditional, global Rademacher analysis, this very relationship allows for trading off slower rates with respect to the number of tasks for faster rates with respect to the number of available samples per task.},
journal = {J. Mach. Learn. Res.},
month = {jan},
pages = {1385–1431},
numpages = {47},
keywords = {multi-task learning, local rademacher complexity, excess risk bounds}
}

@book{10.1145/3581906,
editor = {Koubarakis, Manolis},
title = {Geospatial Data Science: A Hands-on Approach for Building Geospatial Applications Using Linked Data Technologies},
year = {2023},
isbn = {9798400707407},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {51},
abstract = {This introductory textbook teaches the simple development of geospatial applications based on the principles and software tools of geospatial data science. It introduces a new generation of geospatial technologies that have emerged from the development of the Semantic Web and the Linked Data paradigm, and shows how data scientists can use them to build environmental applications easily.Geospatial data science is the science of collecting, organizing, analyzing, and visualizing geospatial data. Since around 2010, there has been extensive work in the area of geospatial data science using semantic technologies and linked data, from researchers in the areas of the Semantic Web, Geospatial Databases and Geoinformatics. The main results of this research have been the publication of the OGC standard GeoSPARQL and the implementation of a number of linked data tools supporting this standard. Up to now, there has been no textbook that enables someone to teach this material to undergraduate or graduate students.The material of the book is developed in a tutorial style and it is appropriate for an introductory course on the subject. This can be an advanced undergraduate course or a graduate course offered by Computer Science or GIS faculty. It is a hands-on approach and every chapter contains exercises that help students master the material.The book is accompanied by a Web site:  where solutions to some of the exercises are given together with supplementary material such as datasets and code. Most of the material in the book has been tried in the “Knowledge Technologies” course taught by the editor in the Department of Informatics and Telecommunications of the National and Kapodistrian University of Athens since 2012.}
}

@proceedings{10.1145/3579142,
title = {BiDEDE '23: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
year = {2023},
isbn = {9798400700934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Seattle</city>, <state>WA</state>, <country>USA</country>, </conf-loc>}
}

@inproceedings{10.1145/3593434.3593436,
author = {Ramos-Vidal, Delfina},
title = {Reengineering legacy document information systems: Challenges and solutions},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593436},
doi = {10.1145/3593434.3593436},
abstract = {Since internet applications have reached a satisfactory level of maturity, large information systems have been developed to manage and facilitate access to documents. Simultaneously, there was an enormous international effort to digitise documents, enabling access via the internet. This endeavour facilitated the access of researchers to extensive document repositories and libraries, while also aiding companies in organising their documents. Two decades later, these vast databases are reasonably clean and well-organised, although the software used to manage and feed them is gradually becoming obsolete. Therefore, it is imperative to continuously reengineer the software to maintain optimal functionality. Furthermore, after the initial effort to digitise documents and create the initial metadata, it is reasonable to augment the metadata information pertaining to the documents. As such, two necessities are apparent: improving support for reengineering legacy document information systems and enabling data model updates and schema evolution to accommodate new information. Our goal is to automate the reengineering process as a whole.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {286–291},
numpages = {6},
keywords = {software reengineering, schema evolution, document information systems, automated development},
location = {Oulu, Finland},
series = {EASE '23}
}

@inproceedings{10.1145/3355166.3355170,
author = {Nabbosa, Veronica L. and Iftikhar, Rehan},
title = {Digital Retail Challenges within the EU: Fulfillment of Holistic Customer Journey Post GDPR},
year = {2019},
isbn = {9781450372565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3355166.3355170},
doi = {10.1145/3355166.3355170},
abstract = {Retail customers are demanding better shopping experience whether shopping online or in-store. To provide this experience, retailers use digital technologies such as Artificial Intelligence, Big Data, to name a few. They also collect personal data from customers, process it and integrate it in their business models. Use of the digital technologies and customers' data poses legal challenges with the introduction of GDPR in EU. This paper analyses the challenges faced by digital retailers as they strive to provide fulfilling customer experiences. The authors address in this study, the influence of GDPR on business and technological aspects of digital retail.},
booktitle = {Proceedings of the 2019 3rd International Conference on E-Education, E-Business and E-Technology},
pages = {51–58},
numpages = {8},
keywords = {Retail Challenges, GDPR, EU, Digital Retail, Customer Journey},
location = {Madrid, Spain},
series = {ICEBT '19}
}

@inproceedings{10.1145/3488560.3498459,
author = {Song, Yu and Sun, Shuai and Lian, Jianxun and Huang, Hong and Li, Yu and Jin, Hai and Xie, Xing},
title = {Show Me the Whole World: Towards Entire Item Space Exploration for Interactive Personalized Recommendations},
year = {2022},
isbn = {9781450391320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488560.3498459},
doi = {10.1145/3488560.3498459},
abstract = {User interest exploration is an important and challenging topic in recommender systems, which alleviates the closed-loop effects between recommendation models and user-item interactions.Contextual bandit (CB) algorithms strive to make a good trade-off between exploration and exploitation so that users' potential interests have chances to expose. However, classical CB algorithms can only be applied to a small, sampled item set (usually hundreds), which forces the typical applications in recommender systems limited to candidate post-ranking, homepage top item ranking, ad creative selection, or online model selection (A/B test). In this paper, we introduce two simple but effective hierarchical CB algorithms to make a classical CB model (such as LinUCB and Thompson Sampling) capable to explore users' interest in the entire item space without limiting to a small item set. We first construct a hierarchy item tree via a bottom-up clustering algorithm to organize items in a coarse-to-fine manner. Then we propose ahierarchical CB (HCB) algorithm to explore users' interest on the hierarchy tree. HCB takes the exploration problem as a series of decision-making processes, where the goal is to find a path from the root to a leaf node, and the feedback will be back-propagated to all the nodes in the path. We further propose aprogressive hierarchical CB (pHCB) algorithm, which progressively extends visible nodes which reach a confidence level for exploration, to avoid misleading actions on upper-level nodes in the sequential decision-making process. Extensive experiments on two public recommendation datasets demonstrate the effectiveness and flexibility of our methods.},
booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
pages = {947–956},
numpages = {10},
keywords = {recommender system, interest exploration, contextual bandit},
location = {Virtual Event, AZ, USA},
series = {WSDM '22}
}

@inproceedings{10.1145/3233027.3233049,
author = {Horcas, Jose-Miguel and Corti\~{n}as, Alejandro and Fuentes, Lidia and Luaces, Miguel R.},
title = {Integrating the common variability language with multilanguage annotations for web engineering},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233049},
doi = {10.1145/3233027.3233049},
abstract = {Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {196–207},
numpages = {12},
keywords = {web engineering, variability, composition, automation, annotations, SPL, CVL},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.5555/3648699.3648863,
author = {Holzm\"{u}ller, David and Zaverkin, Viktor and K\"{a}stner, Johannes and Steinwart, Ingo},
title = {A framework and benchmark for deep batch active learning for regression},
year = {2024},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {The acquisition of labels for supervised learning can be expensive. To improve the sample efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations, and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width neural tangent kernels and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or training code. We provide open-source code that includes efficient implementations of all kernels, kernel transformations, and selection methods, and can be used for reproducing our results.},
journal = {J. Mach. Learn. Res.},
month = {mar},
articleno = {164},
numpages = {81},
keywords = {batch mode deep active learning, regression, tabular data, neural network, Benchmark}
}

@inproceedings{10.1145/3234664.3234665,
author = {Feng, Tao and He, Weiyou},
title = {Research on Privacy Preserving of Searchable Encryption},
year = {2018},
isbn = {9781450364850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234664.3234665},
doi = {10.1145/3234664.3234665},
abstract = {In the cloud computing applications, the researchers proposed a new cryptographic primitive searchable encryption (SE) in order to ensure data security. Searchable encryption can make full use of cloud server computing capacity to search the ciphertext. The privacy of the searchable encryption on this paper is discussed: First of all, security threat model and security definition of searchable encryption is discussed. Secondly, the privacy preserving definition of searchable encryption is established from two aspects of data privacy and identity privacy. Once again the existing searchable encryption schemes are analyzed and evaluated based on data privacy preserving (index privacy preserving, search pattern privacy preserving, access pattern privacy preserving) by treat model and privacy preserving definition. Fourthly, searchable encryption schemes of different application models are introduced based on identity privacy preserving, and anonymous searchable encryption schemes are analyzed and evaluated based on anonymity definitions of different application models. Finally, the design principle and method of safety analysis are provided for privacy preserving scheme of searchable encryption.},
booktitle = {Proceedings of the 2018 2nd High Performance Computing and Cluster Technologies Conference},
pages = {58–68},
numpages = {11},
keywords = {privacy preserving, identity privacy, data privacy, anonymity, Searchable encryption},
location = {Beijing, China},
series = {HPCCT '18}
}

@article{10.1145/3329124,
author = {McDaniel, Melinda and Storey, Veda C.},
title = {Evaluating Domain Ontologies: Clarification, Classification, and Challenges},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3329124},
doi = {10.1145/3329124},
abstract = {The number of applications being developed that require access to knowledge about the real world has increased rapidly over the past two decades. Domain ontologies, which formalize the terms being used in a discipline, have become essential for research in areas such as Machine Learning, the Internet of Things, Robotics, and Natural Language Processing, because they enable separate systems to exchange information. The quality of these domain ontologies, however, must be ensured for meaningful communication. Assessing the quality of domain ontologies for their suitability to potential applications remains difficult, even though a variety of frameworks and metrics have been developed for doing so. This article reviews domain ontology assessment efforts to highlight the work that has been carried out and to clarify the important issues that remain. These assessment efforts are classified into five distinct evaluation approaches and the state of the art of each described. Challenges associated with domain ontology assessment are outlined and recommendations are made for future research and applications.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {70},
numpages = {44},
keywords = {task-ontology fit, ontology development, ontology application, metrics, evaluation, domain ontology, assessment, applied ontology, Ontology}
}

@proceedings{10.1145/3640912,
title = {CNML '23: Proceedings of the 2023 International Conference on Communication Network and Machine Learning},
year = {2023},
isbn = {9798400716683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Zhengzhou</city>, <country>China</country>, </conf-loc>}
}

@proceedings{10.1145/3565287,
title = {MobiHoc '23: Proceedings of the Twenty-fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
year = {2023},
isbn = {9781450399265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ACM MobiHoc is a premier international annual conference with a highly selective single-track technical program dedicated to addressing the challenges emerging from networked systems that must operate in the face of dynamics.},
location = {Washington, DC, USA}
}

@proceedings{10.1145/3566097,
title = {ASPDAC '23: Proceedings of the 28th Asia and South Pacific Design Automation Conference},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer Aided Design (ICCAD), and Embedded SystemsWeek (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunities to learn about the advancements on LSI design and design automation fields, as well as to communicate with each other for researchers and designers around Asia and South Pacific regions.},
location = {<conf-loc>, <city>Tokyo</city>, <country>Japan</country>, </conf-loc>}
}

@proceedings{10.1145/3593434,
title = {EASE '23: Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oulu, Finland}
}

@proceedings{10.1145/3559009,
title = {PACT '22: Proceedings of the International Conference on Parallel Architectures and Compilation Techniques},
year = {2022},
isbn = {9781450398688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {PACT is a long-running and unique conference at the intersection of parallel architectures and compilers that brings together researchers from industry, academia, and national laboratories to present and discuss their latest research results. How applications serve as a driver for innovations in architecture and compilers is an important theme of the conference.},
location = {Chicago, Illinois}
}

@proceedings{10.1109/3655039,
title = {ASPDAC '24: Proceedings of the 29th Asia and South Pacific Design Automation Conference},
year = {2024},
isbn = {9798350393545},
publisher = {IEEE Press},
abstract = {ASP-DAC is a high-quality and premium conference on Electronic Design Automation (EDA) area like other sister conferences such as Design Automation Conference (DAC), Design, Automation &amp; Test in Europe (DATE), International Conference on Computer-Aided Design (ICCAD), and Embedded Systems Week (ESWEEK). ASP-DAC started in 1995 and has continuously offered opportunity to know the recent advanced technologies on LSI design and design automation areas, and to communicate each other for researchers and designers around Asia and South Pacific regions.},
location = {<conf-loc>, <city>Incheon</city>, <country>Republic of Korea</country>, </conf-loc>}
}

@proceedings{10.1145/3551349,
title = {ASE '22: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
year = {2022},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Rochester</city>, <state>MI</state>, <country>USA</country>, </conf-loc>}
}

@proceedings{10.1145/3613424,
title = {MICRO '23: Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Toronto</city>, <state>ON</state>, <country>Canada</country>, </conf-loc>}
}

@proceedings{10.1145/3411764,
title = {CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>}
}

@proceedings{10.1145/3508352,
title = {ICCAD '22: Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Jointly sponsored by ACM and IEEE, ICCAD is the premier forum to explore new challenges, present leading-edge innovative solutions, and identify emerging technologies in the Electronic Design Automation (EDA) research areas. ICCAD covers the full range of Computer-Aided Design (CAD) topics - from device and circuit-level up through system-level, as well as post-CMOS design.},
location = {<conf-loc>, <city>San Diego</city>, <state>California</state>, </conf-loc>}
}

