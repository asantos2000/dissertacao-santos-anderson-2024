@inproceedings{10.5555/3566055.3566078,
author = {Hamdani, Syed Waqas and Brealey, Chris and Kontogiannis, Kostas and Giammaria, Alberto},
title = {Evaluating the Impact of NIST 800.53 Security Control Violations},
year = {2022},
publisher = {IBM Corp.},
address = {USA},
abstract = {In today's data-driven world, an Information System, particularly in a regulated industry, will require a comprehensive security frame­work such as NIST 800.53 to protect against loss of confidentiality, integrity, or availability of data, whether due to malice, accident, or otherwise. Once such a security framework is in place, an organi­zation must constantly monitor and assess the overall compliance of that framework to detect and rectify any issues found. In this short paper we will present initial findings and a novel approach to assess the impact a failed security control has on other controls and evaluate the security risk due to such failed controls. The approach is based first on modeling the dependencies between the different controls in the NIST 800.53 protocol by compiling a corresponding dependency multi-graph, second on devising a risk assessment tech­nique that traverses such a multi-graph and assigning an overall security exposure score when one or more controls fail, and third on identifying those attack strategies against which an organization should defend itself. This research provides organizations with an ability to have a bird's-eye view of its Information System cyber security posture and help triage the security control checks in the most vulnerable parts of the Information System.},
booktitle = {Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering},
pages = {187–192},
numpages = {6},
keywords = {NIST 800.53, Security Controls, Compliance, Risk Analysis, System Security},
location = {Toronto, Canada},
series = {CASCON '22}
}

@inproceedings{10.1109/ICSE-SEIS.2019.19,
author = {Lago, Patricia},
title = {Architecture design decision maps for software sustainability},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIS.2019.19},
doi = {10.1109/ICSE-SEIS.2019.19},
abstract = {In software engineering, sustainability can be defined as the "capacity to endure" and to "preserve the function of a system over an extended period of time". These definitions mainly point towards technical sustainability over time. Sustainability, however, may entail a much broader scope including economic, social and environmental sustainability as well.In spite of the exciting hype around sustainability, we are very much lacking suitable instruments to design software-intensive systems that are sustainable and enable sustainability goals. To fill this gap, we advocate the treatment of sustainability as a software quality property and define a software sustainability assessment method that helps make sustainability-driven design decisions. The method essentially relies on the definition of so-called decision maps, i.e. views aimed at framing the architecture design concerns around the four sustainability dimensions mentioned above - technical, economic, social and environmental sustainability. This paper presents the notion of decision map. We use two illustrative examples extracted from industrial projects, to summarize our lessons learned and reflections.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Society},
pages = {61–64},
numpages = {4},
keywords = {sustainability, software architecture, decision map, architecture design decisions, architecture assessment},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIS '19}
}

@inproceedings{10.1145/3457784.3457826,
author = {Maria Bruma, Livia},
title = {Using Cloud Control Matrix to evaluate trust in cloud providers},
year = {2021},
isbn = {9781450388825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457784.3457826},
doi = {10.1145/3457784.3457826},
abstract = {The increase in the number of users of cloud has led to an increase in the number of providers of this technology. The decision to migrate resources to cloud should be made after going through a process that provides relevant information about the security, availability, financial values involved, implicitly the trust that consumers can have in cloud service providers. In the first part of this article is presented the main methods for verifying trust in suppliers, following the proposal of a framework model for analyzing the parameters that can provide information on trust in CSP. In the second part of the article is proposed, a method of using CCM (Cloud control matrix) and CAIQ-Lite (Consensus Assessment Initiative Questionnaire) tools to determine a minimum level of CSP confidence.},
booktitle = {Proceedings of the 2021 10th International Conference on Software and Computer Applications},
pages = {273–278},
numpages = {6},
keywords = {trustworthy, information security, cloud control matrix, cloud computing},
location = {Kuala Lumpur, Malaysia},
series = {ICSCA '21}
}

@inproceedings{10.1145/3241403.3241458,
author = {Ahmed, Yussuf and Naqvi, Syed and Josephs, Mark},
title = {Aggregation of security metrics for decision making: a reference architecture},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241458},
doi = {10.1145/3241403.3241458},
abstract = {Existing security technologies play a significant role in protecting enterprise systems but they are no longer enough on their own given the number of successful cyberattacks against businesses and the sophistication of the tactics used by attackers to bypass the security defences. Security measurement is different to security monitoring in the sense that it provides a means to quantify the security of the systems while security monitoring helps in identifying abnormal events and does not measure the actual state of an infrastructure's security. The goal of enterprise security metrics is to enable understanding of the overall security using measurements to guide decision making. In this paper we present a reference architecture for aggregating the measurement values from the different components of the system in order to enable stakeholders to see the overall security state of their enterprise systems and to assist with decision making. This will provide a newer dimension to security management by shifting from security monitoring to security measurement.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {53},
numpages = {7},
keywords = {security metrics, security measurements, reference architecture, network security, information security},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3537693.3537745,
author = {Gilberta, Gisela and Widuri, Rindang and Kasenda, Faris},
title = {Factors Affecting the Implementation of Remote Audit in the Audit Process in the COVID-19 Pandemic},
year = {2022},
isbn = {9781450396523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3537693.3537745},
doi = {10.1145/3537693.3537745},
abstract = {This study aims to analyze the factors that affect the implementation of a remote audit with the UTAUT model. This study uses a survey method for data collection and uses SmartPLS 3 for data processing. The population of this study is auditors who work at a Public Accounting Firm in DKI Jakarta and use remote auditing while working. A sample of 90 respondents was obtained by purposive sampling. The results showed that the convenience of online access, performance expectations, and social influences significantly affected behavioral intentions. However, effort expectations had no significant impact on behavioral intentions. This study also shows that behavioral intentions significantly affect usage behavior, while the facilitation condition has no significant effect on the behavior of using remote audits.},
booktitle = {Proceedings of the 6th International Conference on E-Commerce, E-Business and E-Government},
pages = {318–324},
numpages = {7},
keywords = {Remote Audit, Pandemic, Audit Process},
location = {Plymouth, United Kingdom},
series = {ICEEG '22}
}

@inproceedings{10.1145/3325917.3325923,
author = {Onwujekwe, Gerald and Thomas, Manoj and Osei-Bryson, Kweku-Muata},
title = {Using Robust Data Governance to Mitigate the Impact of Cybercrime},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325917.3325923},
doi = {10.1145/3325917.3325923},
abstract = {The Deloitte's report (2015) on cybersecurity trends states that emerging technologies, coupled with a shifting threat profile, are challenging organizations to deal more and more with sophisticated "bad actors" that are motivated, skilled, and adaptable [1]. There is little doubt that cybercrime is growing more rapidly than cybersecurity measures are able to deal with and businesses and governments have never been more at risk from cyberattacks. In this paper, we ask the question, 'what are some of the robust data governance practices that can be put in place to forestall cybercrime?' We also asked the question, 'are there some research papers that have been published to address this concern? We then took a deep into extant literature to find out. Furthermore, we proposed a cybercrime mitigation framework using robust data governance. Our literature synthesis revealed that there is little research that investigated the concept of data governance and cybercrime together, which leads us to propose research hypotheses for a future quantitative research.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {70–79},
numpages = {10},
keywords = {cybersecurity, cybercrime, cyberattack, cyber threat, Data governance},
location = {Houston, TX, USA},
series = {ICISDM '19}
}

@article{10.1145/3623401,
author = {Tang, Hao and Wang, Cheng and Zheng, Jianguo and Jiang, Changjun},
title = {Enabling Graph Neural Networks for Semi-Supervised Risk Prediction in Online Credit Loan Services},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3623401},
doi = {10.1145/3623401},
abstract = {Graph neural networks (GNNs) are playing exciting roles in the application scenarios where features are hidden in information associations. Fraud prediction of online credit loan services (OCLSs) is such a typical scenario. But it has another rather critical challenge, i.e., the scarcity of data labels. Fortunately, GNNs can also cope with this problem due to their good ability of semi-supervised learning by mining structure and feature information within graphs. Nevertheless, the gain of internal information is often too limited to help GNNs handle the extreme deficiency of labels with high performance beyond the basic requirement of fraud prediction in OCLSs. Therefore, adding labels from the experts, such as manually adding labels through rules, has become a logical practice. However, the existing rule engines for OCLSs have the confliction problem among continuously accumulated rules. To address this issue, we propose a Snorkel-based Semi-Supervised GNN (S3GNN). Under S3GNN, we specially design an upgraded version of the rule engines, called Graph-Oriented Snorkel (GOS), a graph-specific extension of Snorkel, a widely used weakly supervised learning framework, to design rules by subject matter experts (SMEs) and resolve confliction. In particular, in the graph of an anti-fraud scenario, each node pair may have multiple different types of edges, so we propose the Multiple Edge-Types Based Attention mechanism. In general, for the heterogeneous information and multiple relations in the graph, we first obtain the embedding of applicant nodes by aggregating the representation of attribute nodes, and then use the attention mechanism to aggregate neighbor nodes on multiple meta-paths to get ultimate applicant node embedding. We conduct experiments over the real-life data of a large financial platform. The results demonstrate that S3GNN can outperform the state-of-the-art methods, including the method of pilot platform.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {jan},
articleno = {13},
numpages = {24},
keywords = {online credit loan services, weak supervision, graph neural networks, Fraud prediction}
}

@inproceedings{10.1145/3341105.3373855,
author = {Koch, Simon and Sauer, Tim and Johns, Martin and Pellegrino, Giancarlo},
title = {Raccoon: automated verification of guarded race conditions in web applications},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373855},
doi = {10.1145/3341105.3373855},
abstract = {Web applications are distributed, asynchronous applications that can span multiple concurrent processes. They are intended to be used by a large amount of users at the same time. As concurrent applications, web applications have to account for race conditions that may occur when database access happens concurrently. Unlike vulnerability classes, such as XSS or SQL Injection, dbms based race condition flaws have received little attention even though their impact is potentially severe. In this paper, we present Raccoon, an automated approach to detect and verify race condition vulnerabilities in web application. Raccoon identifies potential race conditions through interleaving execution of user traces while tightly monitoring the resulting database activity. Based on our methodology we create a proof of concept implementation. We test four different web applications and ten use cases and discover six race conditions with security implications. Raccoon requires neither security expertise nor knowledge about implementation or database layout, while only reporting vulnerabilities, in which the tool was able to successfully replicate a practical attack. Thus, Raccoon complements previous approaches that did not verify detected possible vulnerabilities.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1678–1687},
numpages = {10},
keywords = {web application security testing, race conditions},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3355166.3355170,
author = {Nabbosa, Veronica L. and Iftikhar, Rehan},
title = {Digital Retail Challenges within the EU: Fulfillment of Holistic Customer Journey Post GDPR},
year = {2019},
isbn = {9781450372565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3355166.3355170},
doi = {10.1145/3355166.3355170},
abstract = {Retail customers are demanding better shopping experience whether shopping online or in-store. To provide this experience, retailers use digital technologies such as Artificial Intelligence, Big Data, to name a few. They also collect personal data from customers, process it and integrate it in their business models. Use of the digital technologies and customers' data poses legal challenges with the introduction of GDPR in EU. This paper analyses the challenges faced by digital retailers as they strive to provide fulfilling customer experiences. The authors address in this study, the influence of GDPR on business and technological aspects of digital retail.},
booktitle = {Proceedings of the 2019 3rd International Conference on E-Education, E-Business and E-Technology},
pages = {51–58},
numpages = {8},
keywords = {Retail Challenges, GDPR, EU, Digital Retail, Customer Journey},
location = {Madrid, Spain},
series = {ICEBT '19}
}

@inproceedings{10.1145/3488560.3498459,
author = {Song, Yu and Sun, Shuai and Lian, Jianxun and Huang, Hong and Li, Yu and Jin, Hai and Xie, Xing},
title = {Show Me the Whole World: Towards Entire Item Space Exploration for Interactive Personalized Recommendations},
year = {2022},
isbn = {9781450391320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488560.3498459},
doi = {10.1145/3488560.3498459},
abstract = {User interest exploration is an important and challenging topic in recommender systems, which alleviates the closed-loop effects between recommendation models and user-item interactions.Contextual bandit (CB) algorithms strive to make a good trade-off between exploration and exploitation so that users' potential interests have chances to expose. However, classical CB algorithms can only be applied to a small, sampled item set (usually hundreds), which forces the typical applications in recommender systems limited to candidate post-ranking, homepage top item ranking, ad creative selection, or online model selection (A/B test). In this paper, we introduce two simple but effective hierarchical CB algorithms to make a classical CB model (such as LinUCB and Thompson Sampling) capable to explore users' interest in the entire item space without limiting to a small item set. We first construct a hierarchy item tree via a bottom-up clustering algorithm to organize items in a coarse-to-fine manner. Then we propose ahierarchical CB (HCB) algorithm to explore users' interest on the hierarchy tree. HCB takes the exploration problem as a series of decision-making processes, where the goal is to find a path from the root to a leaf node, and the feedback will be back-propagated to all the nodes in the path. We further propose aprogressive hierarchical CB (pHCB) algorithm, which progressively extends visible nodes which reach a confidence level for exploration, to avoid misleading actions on upper-level nodes in the sequential decision-making process. Extensive experiments on two public recommendation datasets demonstrate the effectiveness and flexibility of our methods.},
booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
pages = {947–956},
numpages = {10},
keywords = {recommender system, interest exploration, contextual bandit},
location = {Virtual Event, AZ, USA},
series = {WSDM '22}
}

@inproceedings{10.1145/3233027.3233049,
author = {Horcas, Jose-Miguel and Corti\~{n}as, Alejandro and Fuentes, Lidia and Luaces, Miguel R.},
title = {Integrating the common variability language with multilanguage annotations for web engineering},
year = {2018},
isbn = {9781450364645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3233027.3233049},
doi = {10.1145/3233027.3233049},
abstract = {Web applications development involves managing a high diversity of files and resources like code, pages or style sheets, implemented in different languages. To deal with the automatic generation of custom-made configurations of web applications, industry usually adopts annotation-based approaches even though the majority of studies encourage the use of composition-based approaches to implement Software Product Lines. Recent work tries to combine both approaches to get the complementary benefits. However, technological companies are reticent to adopt new development paradigms such as feature-oriented programming or aspect-oriented programming. Moreover, it is extremely difficult, or even impossible, to apply these programming models to web applications, mainly because of their multilingual nature, since their development involves multiple types of source code (Java, Groovy, JavaScript), templates (HTML, Markdown, XML), style sheet files (CSS and its variants, such as SCSS), and other files (JSON, YML, shell scripts). We propose to use the Common Variability Language as a composition-based approach and integrate annotations to manage fine grained variability of a Software Product Line for web applications. In this paper, we (i) show that existing composition and annotation-based approaches, including some well-known combinations, are not appropriate to model and implement the variability of web applications; and (ii) present a combined approach that effectively integrates annotations into a composition-based approach for web applications. We implement our approach and show its applicability with an industrial real-world system.},
booktitle = {Proceedings of the 22nd International Systems and Software Product Line Conference - Volume 1},
pages = {196–207},
numpages = {12},
keywords = {web engineering, variability, composition, automation, annotations, SPL, CVL},
location = {Gothenburg, Sweden},
series = {SPLC '18}
}

@article{10.5555/3648699.3648863,
author = {Holzm\"{u}ller, David and Zaverkin, Viktor and K\"{a}stner, Johannes and Steinwart, Ingo},
title = {A framework and benchmark for deep batch active learning for regression},
year = {2024},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {The acquisition of labels for supervised learning can be expensive. To improve the sample efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations, and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width neural tangent kernels and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or training code. We provide open-source code that includes efficient implementations of all kernels, kernel transformations, and selection methods, and can be used for reproducing our results.},
journal = {J. Mach. Learn. Res.},
month = {mar},
articleno = {164},
numpages = {81},
keywords = {batch mode deep active learning, regression, tabular data, neural network, Benchmark}
}

@inproceedings{10.1145/3234664.3234665,
author = {Feng, Tao and He, Weiyou},
title = {Research on Privacy Preserving of Searchable Encryption},
year = {2018},
isbn = {9781450364850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234664.3234665},
doi = {10.1145/3234664.3234665},
abstract = {In the cloud computing applications, the researchers proposed a new cryptographic primitive searchable encryption (SE) in order to ensure data security. Searchable encryption can make full use of cloud server computing capacity to search the ciphertext. The privacy of the searchable encryption on this paper is discussed: First of all, security threat model and security definition of searchable encryption is discussed. Secondly, the privacy preserving definition of searchable encryption is established from two aspects of data privacy and identity privacy. Once again the existing searchable encryption schemes are analyzed and evaluated based on data privacy preserving (index privacy preserving, search pattern privacy preserving, access pattern privacy preserving) by treat model and privacy preserving definition. Fourthly, searchable encryption schemes of different application models are introduced based on identity privacy preserving, and anonymous searchable encryption schemes are analyzed and evaluated based on anonymity definitions of different application models. Finally, the design principle and method of safety analysis are provided for privacy preserving scheme of searchable encryption.},
booktitle = {Proceedings of the 2018 2nd High Performance Computing and Cluster Technologies Conference},
pages = {58–68},
numpages = {11},
keywords = {privacy preserving, identity privacy, data privacy, anonymity, Searchable encryption},
location = {Beijing, China},
series = {HPCCT '18}
}

