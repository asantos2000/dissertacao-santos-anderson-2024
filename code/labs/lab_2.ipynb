{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 - Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import pandas as pd\n",
    "\n",
    "# \\u00a7 275.0-2 expressions\n",
    "true_values = [\n",
    "    {\"doc_id\": \"ยง 275.0-2_P1\", \"id\": 1, \"expression\": \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\"},\n",
    "    {\"doc_id\": \"ยง 275.0-2_P1\", \"id\": 2, \"A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\",\n",
    "    \"If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\",\n",
    "    \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"Managing agent means any person, including a trustee, who directs or manages, or who participates in directing or managing, the affairs of any unincorporated organization or association other than a partnership.\",\n",
    "    \"Non-resident means an individual who resides in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a corporation that is incorporated in or that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a partnership or other unincorporated organization or association that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Principal office and place of business has the same meaning as in \\u00a7 275.203A-3(c) of this chapter.\"\n",
    "]\n",
    "\n",
    "# List of suspect domains to check for potential impersonation\n",
    "pred_values = [\n",
    "    \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\",\n",
    "    \"A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\",\n",
    "    \"If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\",\n",
    "    \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"Managing agent means any person, including a trustee, who directs or manages, or who participates in directing or managing, the affairs of any unincorporated organization or association other than a partnership.\",\n",
    "    \"Non-resident means an individual who resides in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a corporation that is incorporated in or that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Non-resident means a partnership or other unincorporated organization or association that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\",\n",
    "    \"Principal office and place of business has the same meaning as in \\u00a7 275.203A-3(c) of this chapter.\",\n",
    "]\n",
    "\n",
    "# Function to check the similarity between true and pred expression\n",
    "def check_for_expressions_mililarity(true_list, pred_list, threshold=0.7):\n",
    "    results = []\n",
    "    for pred in pred_list:\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for true_item in true_list:\n",
    "            # Calculate the similarity score using the Levenshtein distance\n",
    "            score = jellyfish.levenshtein_distance(pred, true_item)\n",
    "            similarity_score = 1 - (score / max(len(pred), len(true_item)))  # Normalizing to a similarity score\n",
    "            \n",
    "            if similarity_score > best_score:\n",
    "                best_score = similarity_score\n",
    "                best_match = true_item\n",
    "        results.append((pred, best_match, best_score))\n",
    "    return results\n",
    "\n",
    "# Check for potential domain impersonations\n",
    "similarity_results = check_for_expressions_mililarity(true_values, pred_values)\n",
    "\n",
    "# Building dataframe\n",
    "df_results = pd.DataFrame(similarity_results, columns=[\"pred_expression\", \"true_expression\", \"similarity_score\"])\n",
    "\n",
    "# Adding Color Coding to \"Similarity Score\" Column\n",
    "def highlight_similarity(val):\n",
    "    color = 'green' if val >= 0.9 else 'red'  \n",
    "    return f'background-color: {color}'\n",
    "styled_df = df_results.style.applymap(highlight_similarity, subset=[\"similarity_score\"])\n",
    "styled_df.set_table_attributes('style=\"width: 100%; border: 1px solid black;\"')\n",
    "styled_df.set_properties(**{'border': '1px solid black'})\n",
    "\n",
    "\n",
    "# Display the final DataFrame\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the id fields from both pred_list and true_list, we can enhance your code to analyze how often the pred_id matches the true_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to group expressions by doc_id\n",
    "def group_expressions_by_doc_id(expressions_list, is_pred=False):\n",
    "    doc_id_map = defaultdict(list)\n",
    "    for item in expressions_list:\n",
    "        doc_id = item['doc_id']\n",
    "        if is_pred:\n",
    "            # Include filename, id, and classification for pred_list items\n",
    "            expression_info = {\n",
    "                'id': item['id'],\n",
    "                'expression': item['expression'],\n",
    "                'classification_pred': item.get('classification', None),\n",
    "                'filename_pred': item['filename']\n",
    "            }\n",
    "        else:\n",
    "            # Include id and classification for true_list items\n",
    "            expression_info = {\n",
    "                'id': item['id'],\n",
    "                'expression': item['expression'],\n",
    "                'classification_true': item.get('classification', None)\n",
    "            }\n",
    "        doc_id_map[doc_id].append(expression_info)\n",
    "    return doc_id_map\n",
    "\n",
    "# Function to check the similarity between true and pred expressions grouped by doc_id\n",
    "def check_for_expressions_similarity(true_list, pred_list, threshold=0.7):\n",
    "    # Build mappings from doc_id to list of expressions\n",
    "    true_expressions_by_doc_id = group_expressions_by_doc_id(true_list)\n",
    "    pred_expressions_by_doc_id = group_expressions_by_doc_id(pred_list, is_pred=True)\n",
    "\n",
    "    results = []\n",
    "    all_doc_ids = set(true_expressions_by_doc_id.keys()).union(pred_expressions_by_doc_id.keys())\n",
    "\n",
    "    for doc_id in all_doc_ids:\n",
    "        true_expressions = true_expressions_by_doc_id.get(doc_id, [])\n",
    "        pred_expressions = pred_expressions_by_doc_id.get(doc_id, [])\n",
    "\n",
    "        for pred_item in pred_expressions:\n",
    "            pred_expr = pred_item['expression']\n",
    "            pred_id = pred_item['id']\n",
    "            classification_pred = pred_item.get('classification_pred', None)\n",
    "            filename_pred = pred_item['filename_pred']\n",
    "            best_match = None\n",
    "            best_score = 0\n",
    "            best_true_id = None\n",
    "            classification_true = None\n",
    "            for true_item in true_expressions:\n",
    "                true_expr = true_item['expression']\n",
    "                true_id = true_item['id']\n",
    "                # Calculate the similarity score using the Levenshtein distance\n",
    "                score = jellyfish.levenshtein_distance(pred_expr, true_expr)\n",
    "                similarity_score = 1 - (score / max(len(pred_expr), len(true_expr)))  # Normalize to a similarity score\n",
    "\n",
    "                if similarity_score > best_score:\n",
    "                    best_score = similarity_score\n",
    "                    best_match = true_expr\n",
    "                    best_true_id = true_id\n",
    "                    classification_true = true_item.get('classification_true', None)\n",
    "            results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"pred_id\": pred_id,\n",
    "                \"true_id\": best_true_id,\n",
    "                \"classification_pred\": classification_pred,\n",
    "                \"classification_true\": classification_true,\n",
    "                \"filename_pred\": filename_pred,\n",
    "                \"pred_expression\": pred_expr,\n",
    "                \"true_expression\": best_match,\n",
    "                \"similarity_score\": best_score\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Use the function with your data\n",
    "similarity_results = check_for_expressions_similarity(true_elements, pred_elements)\n",
    "\n",
    "# Build the dataframe\n",
    "df_results = pd.DataFrame(similarity_results)\n",
    "\n",
    "# Add a column to indicate whether the pred_id matches the true_id\n",
    "df_results['id_match'] = df_results['pred_id'] == df_results['true_id']\n",
    "\n",
    "# Calculate the number and percentage of matches\n",
    "total_matches = df_results['id_match'].sum()\n",
    "total_comparisons = len(df_results)\n",
    "match_percentage = (total_matches / total_comparisons) * 100\n",
    "\n",
    "print(f\"Total Matches: {total_matches}\")\n",
    "print(f\"Total Comparisons: {total_comparisons}\")\n",
    "print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "\n",
    "# Create a confusion matrix for ID matching\n",
    "# We'll label matches as 'match' and mismatches as 'mismatch'\n",
    "df_results['id_match_label'] = df_results['id_match'].map({True: 'match', False: 'mismatch'})\n",
    "\n",
    "# Generate confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# Prepare the data\n",
    "y_true = df_results['id_match_label']  # Since we're comparing IDs, y_true and y_pred are the same\n",
    "y_pred = df_results['id_match_label']\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = ['match', 'mismatch']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title('ID Match Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, labels=labels, digits=4)\n",
    "print(\"Classification Report for ID Matching:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity search\n",
    "\n",
    "```sparql\n",
    "PREFIX llm: <http://franz.com/ns/allegrograph/8.0.0/llm/> \n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX fro-cfr: <http://cfr2sbvr.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "select ?uri ?score (xsd:decimal(?score)*100 as ?score_percent) ?originalText ?definition\n",
    "FROM fibo:FIBO_Graph\n",
    "{\n",
    "  (?uri ?score ?originalText) llm:nearestNeighbor (\"employee\" \"test1-fibo\" 5 0.9) .\n",
    "\n",
    "  ?term a owl:Class ;\n",
    "    skos:definition ?definition ;\n",
    "    ?o ?originalText .\n",
    "}\n",
    "ORDER BY DESC(?score)\n",
    "```\n",
    "\n",
    "fibo-terms-definition\n",
    "\n",
    "```sparql\n",
    "# This PREFIX causes the default graph of the dataset to include\n",
    "# only triples that are not in a named graph.\n",
    "# Otherwise, the default graph will include every triple.\n",
    "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
    "PREFIX fro-cfr: <http://cfr2sbvr.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "\n",
    "# View quads\n",
    "SELECT ?term ?definition\n",
    "#FROM fro-cfr:Code_Federal_Regulations_Graph\n",
    "FROM fibo:FIBO_Graph\n",
    "WHERE { \n",
    "  ?term a owl:Class ;\n",
    "  skos:definition ?definition .\n",
    "}\n",
    "```\n",
    "\n",
    "Qde embeddings\n",
    "\n",
    "```sparkl\n",
    "# Definition\n",
    "select (COUNT(?s) AS ?qty_emb)\n",
    "where {\n",
    "  ?s <http://franz.com/vdb/gen/embedding> ?o . \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AllegroGraph Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the src (modules) directory to the path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import configuration.main as configuration  # noqa: E402configuration.main as configuration\n",
    "\n",
    "config = configuration.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import os\n",
    "\n",
    "# Ensure the ../logs directory exists\n",
    "# log_directory = os.path.join(os.getcwd(), config[\"DEFAULT_LOG_DIR\"])\n",
    "# os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "# # Path for the log file\n",
    "# log_file_path = os.path.join(log_directory, 'application.log')\n",
    "\n",
    "# # Set up TimedRotatingFileHandler to rotate logs every day\n",
    "# file_handler = TimedRotatingFileHandler(\n",
    "#     log_file_path, when=\"midnight\", interval=1, backupCount=0  # Rotate every midnight, keep all backups\n",
    "# )\n",
    "\n",
    "# # Set the file handler's log format\n",
    "# file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=config[\"LOG_LEVEL\"],  # Set to the desired log level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Console log format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',  # Custom date format\n",
    "    handlers=[\n",
    "        #file_handler,  # Log to the rotating file in ../logs\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Log a test message to verify\n",
    "#logger.info(\"Logging is set up with daily rotation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'https://{config[\"ALLEGROGRAPH\"][\"HOST\"]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "REPO= \"actors\"\n",
    "CATALOG= \"root\"\n",
    "HOST= \"ag1eawvuu0p3zv35.allegrograph.cloud\" # for AllegroGraph cloud\n",
    "PORT= 443 # for AllegroGraph cloud\n",
    "USER= \"admin\" # for AllegroGraph cloud\n",
    "PASSWORD= \"\"  # Replace with your password\n",
    "HOME_DIR= \"/home/adsantos/agraph-8.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ag_connect(repo=REPO, catalog=config[\"ALLEGROGRAPH\"][\"CATALOG\"],\n",
    "                host=config[\"ALLEGROGRAPH\"][\"HOST\"], port=config[\"ALLEGROGRAPH\"][\"PORT\"],\n",
    "                protocol=\"http\",\n",
    "                user=config[\"ALLEGROGRAPH\"][\"USER\"], password=config[\"ALLEGROGRAPH\"][\"PASSWORD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\"\"\")\n",
    "query_string = \"SELECT ?s ?p ?o { ?s ?p ?o . } LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "result = tuple_query.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with result:\n",
    "   for binding_set in result:\n",
    "        s = binding_set.getValue(\"s\")\n",
    "        p = binding_set.getValue(\"p\")\n",
    "        o = binding_set.getValue(\"o\")\n",
    "        print(\"%s %s %s\" % (s, p, o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.repository.repository import Repository\n",
    "\n",
    "server = AllegroGraphServer(host=config[\"ALLEGROGRAPH\"][\"HOST\"], port=config[\"ALLEGROGRAPH\"][\"PORT\"],\n",
    "                            user=config[\"ALLEGROGRAPH\"][\"USER\"], password=config[\"ALLEGROGRAPH\"][\"PASSWORD\"],\n",
    "                            repo=config[\"ALLEGROGRAPH\"][\"REPO\"])\n",
    "\n",
    "print(f\"Available catalogs: {server.listCatalogs()}\")\n",
    "\n",
    "catalog = server.openCatalog('root')\n",
    "\n",
    "print(f\"Available repositories: {catalog.listRepositories()}\")\n",
    "\n",
    "myRepository = catalog.getRepository(\"actors\", Repository.ACCESS)\n",
    "\n",
    "print(f\"Available databases: {myRepository.getDatabaseName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround SSL problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stunnel for SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agraph_stunnel.conf\n",
    "\n",
    "[allegrograph_proxy]\n",
    "client = yes\n",
    "accept = 127.0.0.1:8443\n",
    "connect = ag1eawvuu0p3zv35.allegrograph.cloud:443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S stunnel agraph_stunnel.conf\" #can be any command but don't forget -S as it enables input from stdin\n",
    "os.system('echo %s | %s' % (password, command)) # Start stunnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ag_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_cloud = ag_connect(repo=REPO, catalog=CATALOG,\n",
    "                host=\"localhost\", port=8443,\n",
    "                protocol=\"http\",\n",
    "                user=USER, password=PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_query = conn_cloud.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "result = tuple_query.evaluate()\n",
    "\n",
    "with result:\n",
    "   for binding_set in result:\n",
    "        s = binding_set.getValue(\"s\")\n",
    "        p = binding_set.getValue(\"p\")\n",
    "        o = binding_set.getValue(\"o\")\n",
    "        print(\"%s %s %s\" % (s, p, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.repository.repository import Repository\n",
    "\n",
    "server = AllegroGraphServer(host=\"localhost\", port=8443,\n",
    "                            user=USER, password=PASSWORD, \n",
    "                            protocol=\"http\")\n",
    "\n",
    "print(f\"Available catalogs: {server.listCatalogs()}\")\n",
    "\n",
    "catalog = server.openCatalog('root')\n",
    "\n",
    "print(f\"Available repositories: {catalog.listRepositories()}\")\n",
    "\n",
    "myRepository = catalog.getRepository(\"actors\", Repository.ACCESS)\n",
    "\n",
    "print(f\"Available databases: {myRepository.getDatabaseName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_cloud.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop\n",
    "password = getpass.getpass()\n",
    "command = \"sudo -S kill $(ps aux | grep 'stunnel agraph_stunnel.conf' | awk '{print $2}')\" \n",
    "os.system('echo %s | %s' % (password, command)) # Start stunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_num = \"ยง 275.0-7\"\n",
    "# logger.info(get_section_from_kg(conn, section_num=section_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
