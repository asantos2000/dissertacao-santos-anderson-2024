{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lwF6l0TKfK0"
   },
   "source": [
    "# Semantic Annotation - rules classification\n",
    "\n",
    "Lab 4 - Initial version.\n",
    "\n",
    "Chapter 6. Ferramentas de suporte\n",
    "- Section 6.2 Implementação dos principais componentes\n",
    "  - Section 6.2.3 Anotações semânticas\n",
    "    - Section Algoritmo “taxonomy classification and templates”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for labs\n",
    "import sys\n",
    "sys.path.append(r'../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Third-party libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pydantic import BaseModel, Field\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from typing import List, Dict, Optional, Any, Tuple, Set\n",
    "\n",
    "# Local application/library-specific imports\n",
    "import checkpoint.main as checkpoint\n",
    "from checkpoint.main import restore_checkpoint, save_checkpoint, Document, DocumentProcessor, get_all_checkpoints\n",
    "import configuration.main as configuration\n",
    "import logging_setup.main as logging_setup\n",
    "import token_estimator.main as token_estimator\n",
    "from token_estimator.main import estimate_tokens\n",
    "import rules_taxonomy_provider.main as rules_taxonomy_provider\n",
    "from rules_taxonomy_provider.main import RuleInformationProvider, RulesTemplateProvider\n",
    "import llm_query.main as llm_query\n",
    "from llm_query.main import query_instruct_llm\n",
    "\n",
    "DEV_MODE = True\n",
    "\n",
    "if DEV_MODE:\n",
    "    # Development mode\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(configuration)\n",
    "    importlib.reload(logging_setup)\n",
    "    importlib.reload(checkpoint)\n",
    "    importlib.reload(token_estimator)\n",
    "    importlib.reload(rules_taxonomy_provider)\n",
    "    importlib.reload(llm_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Default settings, check them before run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "DEFAULT_CONFIG_FILE = \"../config.yaml\"\n",
    "config = configuration.load_config(DEFAULT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated files for analysis in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/checkpoints/documents-2024-11-05-2.json ../outputs/extraction_report-2024-11-05-1.html ../outputs/compare_items_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(config[\"DEFAULT_CHECKPOINT_FILE\"],\n",
    "config[\"DEFAULT_EXTRACTION_REPORT_FILE\"],\n",
    "config[\"DEFAULT_EXCEL_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:42 - INFO - Logging is set up with daily rotation.\n"
     ]
    }
   ],
   "source": [
    "logger = logging_setup.setting_logging(config[\"DEFAULT_LOG_DIR\"], config[\"LOG_LEVEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "Documents, annoted datasets, statistics and metrics about the execution of the notebook are stored by checkpoint module.\n",
    "\n",
    "Checkpoints are stored / retrieved at the directory `DEFAULT_CHECKPOINT_FILE` in the configuration file.\n",
    "\n",
    "During the execution, it will restore the checkpoint at the beginning of the section and saved at the end. We can run and restore the checkpoint several times. If the run fails, check the closest checkpoint and restore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:42 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-11-01-3.json.\n"
     ]
    }
   ],
   "source": [
    "# Restore the checkpoint\n",
    "\n",
    "# For development only\n",
    "config[\"DEFAULT_CHECKPOINT_FILE\"] = \"../data/checkpoints/documents-2024-11-01-3.json\"\n",
    "\n",
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Datasets used in the notebook. They are divided into sections and true tables. The sections are the documents from CFR and true tables are annoted  or \"golden\" datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions and data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True tables\n",
    "\n",
    "True tables are annotated or \"golden\" datasets in which entities have been manually identified and labeled within the original source data.\n",
    "\n",
    "True tables for sectiona 275.0-2, 275.0-5 and 275.0-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load true table for P1 - Taxonomy Classification - top level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config['DEFAULT_DATA_DIR']}/classification_p1_true_table.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-2_P1|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-5_P1|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-7_P1|true_table\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load true table for P2 - Taxonomy Classification - sub levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config['DEFAULT_DATA_DIR']}/classification_p2_true_table.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-2_P2|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-5_P2|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"§ 275.0-7_P2|true_table\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:42 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract / classify elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions and data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model for P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    type: str = Field(..., description=\"Type of the rule (e.g., Party, Data, Activity)\")\n",
    "    confidence: float = Field(..., ge=0, le=1, description=\"Confidence level of the classification\")\n",
    "    explanation: str = Field(..., description=\"Explanation of why the classification was made\")\n",
    "\n",
    "\n",
    "class StatementClassification(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'\")\n",
    "    statement_text: str = Field(..., description=\"The statement to be classified\")\n",
    "    statement_source: str = Field(..., description=\"Source of the statement\")\n",
    "    classification: List[Classification] = Field(..., description=\"List of classifications with explanations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model for P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubClassification(BaseModel):\n",
    "    subtype: str = Field(..., description=\"Subtype of the rule. The title of the section/subsection.\")\n",
    "    templates_ids: List[str] = Field(..., description=\"List of template IDs that matched the statement.\")\n",
    "    confidence: float = Field(..., ge=0, le=1, description=\"Confidence level of the classification\")\n",
    "    explanation: str = Field(..., description=\"Explanation of why the classification was made\")\n",
    "\n",
    "\n",
    "class StatementSubClassification(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'\")\n",
    "    statement_text: str = Field(..., description=\"The statement to be classified\")\n",
    "    statement_source: str = Field(..., description=\"Source of the statement\")\n",
    "    classification: List[SubClassification] = Field(..., description=\"List of classifications with explanations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "\n",
    "def classify_and_add_prompts(element_type, rule_type, rules_to_classify, manager):\n",
    "    user_prompt_classify = []\n",
    "    system_prompt_classify = []\n",
    "\n",
    "    # Helper to split list into batches with up to 15 items each\n",
    "    def batch(iterable, max_batch_size):\n",
    "        iterator = iter(iterable)\n",
    "        while True:\n",
    "            batch_list = list(islice(iterator, max_batch_size))\n",
    "            if not batch_list:\n",
    "                break\n",
    "            yield batch_list\n",
    "\n",
    "    # Process rules in batches of up to 15 items\n",
    "    for batch_num, batch_rules in enumerate(batch(rules_to_classify, 15)):\n",
    "        logger.info(f\"Processing batch {batch_num + 1} with {len(batch_rules)} items\")\n",
    "        \n",
    "        # Group by 'statement_type' within each batch\n",
    "        grouped_data = defaultdict(list)\n",
    "        for item in batch_rules:\n",
    "            grouped_data[item[\"statement_type\"]].append(item)\n",
    "\n",
    "        # Process each statement type within the batch\n",
    "        for statement_type, items in grouped_data.items():\n",
    "            system_prompt = get_system_prompt_classify_p2(len(batch_rules), element_type, rule_type, statement_type)\n",
    "            system_prompt_classify.append(system_prompt)\n",
    "            user_prompt = get_user_prompt_classify(items)\n",
    "            user_prompt_classify.append(user_prompt)\n",
    "            \n",
    "            # Log token counts for the current batch and statement type\n",
    "            logger.info(f\"Batch {batch_num + 1} - token count system prompt {statement_type}: {token_estimator.estimate_tokens(system_prompt)}\")\n",
    "            logger.info(f\"Batch {batch_num + 1} - token count user prompt {statement_type}: {token_estimator.estimate_tokens(user_prompt)}\")\n",
    "\n",
    "            # Add documents to the manager with batch and statement type info\n",
    "            manager.add_document(\n",
    "                Document(\n",
    "                    id=f\"prompt-classify_P2_{element_type.replace(' ', '_')}_batch{batch_num + 1}_{statement_type}\",\n",
    "                    type=\"prompt\",\n",
    "                    content=system_prompt\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return user_prompt_classify, system_prompt_classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_get_templates(\n",
    "    element_name, part, user_prompt_classify, system_prompt_classify, manager\n",
    "):\n",
    "    # Log the start of the process\n",
    "    logger.info(\n",
    "        f\"{part}. processing {len(system_prompt_classify)} prompts...\"\n",
    "    )\n",
    "    logger.info(f\"{part}. Classifying and getting templates for rules...\")\n",
    "\n",
    "    # Initialize an empty list to accumulate all responses\n",
    "    all_responses_classify = []\n",
    "\n",
    "    # Loop through each pair of user and system prompts with a counter\n",
    "    for index, (user_prompt, system_prompt) in enumerate(zip(user_prompt_classify, system_prompt_classify), start=1):\n",
    "        logger.info(f\"Processing classification and templates prompt {index} ...\")\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "        # Query the language model\n",
    "        response_classify = query_instruct_llm(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            document_model=List[StatementSubClassification],\n",
    "            llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "            temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "            max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    "        )\n",
    "\n",
    "        logger.debug(response_classify)\n",
    "\n",
    "        # Accumulate the responses in the list\n",
    "        all_responses_classify.extend(response_classify)\n",
    "\n",
    "        logger.info(f\"Finished processing classification and templates prompt {index}.\")\n",
    "\n",
    "    # After the loop, create a single Document with all the accumulated responses\n",
    "    doc = Document(\n",
    "        id=f\"classify_{part}_{element_name.replace(' ', '_')}\",\n",
    "        type=\"llm_response_classification\",\n",
    "        content=all_responses_classify,\n",
    "    )\n",
    "    manager.add_document(doc)\n",
    "\n",
    "    return all_responses_classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomy classification and templates for definitional and operative rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for classify rules using the top level of Witt (2012) taxonomy.\n",
    "\n",
    "In examining the classification of terms, names, fact types, and rules within business systems, key distinctions arise between definitional and operative rules, as well as in the structuring of term definitions. Terms, names, and fact types are foundational elements in the taxonomy of definitional rules, though they are not rules themselves. Instead, they serve as the core vocabulary for creating precise definitions and facilitating the rule-making process within an organization. Terms represent general concepts or classes, names uniquely identify specific instances or entities, and fact types capture relationships between terms. Together, these elements enable the consistent and unambiguous use of language across rule statements, models, and documentation, ensuring that definitional and operative rules function cohesively.\n",
    "\n",
    "Definitional rules aim to provide precise structures for organizational concepts, establishing clear, logical statements that support consistent interpretation and application of business language. These rules formalize term definitions, establish categorization schemes, and delineate relationships using fact types, which are classified by their structure as unary, binary, or higher-order and allow organizations to express relationships from simple Boolean properties to complex multi-term associations. When structured through definitional rule templates, fact types enhance clarity, facilitate shared understanding, and ensure accurate application within organizational rules, while supporting a conceptual backbone for business definitions.\n",
    "\n",
    "Names function as unique identifiers for specific instances or entities, adding precision to rule statements that require exact identification. Embedded within definitional rules, names provide specific references crucial for rules that depend on individual entities, distinguishing them from broader terms and reducing ambiguity in complex business contexts. Through structured templates within the definitional rule taxonomy, organizations can integrate names with uniformity and clarity, allowing for reliable reference to distinct entities within rule statements and models. \n",
    "\n",
    "Operative rules, on the other hand, govern actionable requirements, setting conditions under which actions must or must not occur. These include data, activity, and party rules, each ensuring compliance, standardization, and procedural integrity across business processes. Operative rules provide the necessary conditions for maintaining organizational consistency, detailing what actions are authorized in particular circumstances or specifying roles within defined tasks, thereby aligning processes with business objectives.\n",
    "\n",
    "To formalize term definitions, statements must adhere to specific templates within the definitional rule taxonomy, which clearly articulate each term's scope, meaning, and responsibilities. For instance, the term \"Commission\" can be formally defined within Template T7, part of the definitional rule taxonomy, to clarify its procedural functions as the entity that receives and forwards legal documents. By using templates for definitional rules, organizations achieve consistent, unambiguous documentation of terms, fact types, and names, which minimizes ambiguity and ensures standardized interpretation across all business contexts. This structured approach supports precise rule governance and enhances communication within organizational processes, reinforcing the integrity and reliability of rule-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt (Instructions) for classify operative rules using the top level of Witt (2012) taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_classify_p1():\n",
    "    return \"\"\"\n",
    "You are an expert in SBVR (Semantics of Business Vocabulary and Business Rules).\n",
    "\n",
    "You will be provided with a list of statements formatted as JSON.\n",
    "\n",
    "Your task is to classify each statement into one or more Operative Rules types according to the given definitions.\n",
    "\n",
    "You also need to record a confidence level for each classification and provide an explanation for why the classification was made.\n",
    "\n",
    "# Classifications\n",
    "The **Operative rules** Govern actions or constraints that must or must not happen under certain conditions, such as Data Rules, Activity Rules, and Party Rules. types to classify are:\n",
    "- **Party rules**: A type of operative rule that restrict what parties can perform processes, activities, or play roles. They are operative rules.\n",
    "- **Data rules**: A type of operative rule that constrain the data included in a transaction (e.g., forms or messages) or a persistent dataset.\n",
    "- **Activity rules**: A type of operative rule that constrain the operation of one or more business processes or activities.\n",
    "\n",
    "# Input JSON Format\n",
    "The statements are provided in the following JSON format:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"doc_id\": \"some doc id\",\n",
    "        \"statement_id\": \"some id\",\n",
    "        \"statement_source\": \"some source\",\n",
    "        \"statement_text\": \"some text\",\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "# Task Requirements\n",
    "\n",
    "1. Classify each \"statement\" into one or more of the provided rule types (Party, Data, Activity).\n",
    "2. Assess a **confidence level** for each classification between 0 and 1.\n",
    "3. Provide a **clear explanation** for the classification decision.\n",
    "\n",
    "# Output Format\n",
    "Your output must also be in JSON format. It should contain, for each statement:\n",
    "- The `doc_id`\n",
    "- The `statement_id`\n",
    "- The original `statement_text`\n",
    "- The `statement_source` of the statement\n",
    "- A list of classifications (`classification`), each containing:\n",
    "  - The `type` of the rule.\n",
    "  - The `confidence` in your classification.\n",
    "  - An `explanation` detailing why you made the classification decision.\n",
    "\n",
    "Here is an example of the expected output:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"doc_id\": \"some doc id\",\n",
    "        \"statement_id\": \"some id\",\n",
    "        \"statement_text\": \"some text\",\n",
    "        \"statement_source\": \"some source\",\n",
    "        \"classification\": [\n",
    "            {\n",
    "                \"type\": \"Data\",\n",
    "                \"confidence\": 0.9,\n",
    "                \"explanation\": \"This statement defines a constaint that mandates the presence of data.\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Party\",\n",
    "                \"confidence\": 0.2,\n",
    "                \"explanation\": \"There is little reference to any restriction on participants or parties, which means this may not be a valid classification.\"\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": ...,\n",
    "        \"statement_id\": ...,\n",
    "        \"statement_text\": ...,\n",
    "        \"statement_source\": ...,\n",
    "        \"classification\": ...\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "# Notes\n",
    "- **Detail the Reasoning**: Make sure to provide explanations that justify why a particular rule type was chosen.\n",
    "- **Confidence Values**: The confidence value should genuinely represent how strongly you believe the classification is correct, with 1 being an absolute match and 0 meaning unlikely.\n",
    "\n",
    "Make sure that every statement is analyzed thoroughly, and the final justification for each classification is straightforward and adequately supports both the type choice and confidence level.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt including the list of statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_classify(rules_to_classify):\n",
    "    return f\"\"\"\n",
    "# Here's the list of elements you'll need to classify\n",
    "\n",
    "{json.dumps(rules_to_classify, indent=2)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt (Instructions) for classify definitional and operative rules using the sub levels of Witt (2012) taxonomy.\n",
    "\n",
    "- element_type: term, name, fact, operative rule\n",
    "- rule_type: Definitional, Activity, Data, Party\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_classify_p2(element_count, element_type, rule_type, classification):\n",
    "    rule_information_provider = RuleInformationProvider(\"../data\")\n",
    "\n",
    "    subclassification_text = rule_information_provider.get_classification_and_templates(f\"{classification} rules\")        \n",
    "\n",
    "    return f\"\"\"\n",
    "Classify {element_count} {element_type}(s) from the list of elements into one or more {rule_type} Rule subtypes, provide an explanation for each classification, and assign a confidence score between 0 and 1.\n",
    "\n",
    "Use the {rule_type} Rule subtype definitions, templates, and guidelines provided to perform a thorough analysis of each statement.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Identify {rule_type} Rule Subtype(s)**: For each `statement_text` provided, classify the rule type according to the given {rule_type} Rules subtypes and templates.\n",
    "    - Use provided templates, definitions, and details on each subtype to determine the correct classification.\n",
    "    - Cross-reference with template examples to accurately determine the appropriate rule subtype.\n",
    "\n",
    "2. **Assign Confidence Level**: Assess the suitability of each classification by assigning a confidence level between 0 and 1. \n",
    "    - 1 indicates a very strong match, while lower numbers indicate weaker matches.\n",
    "\n",
    "3. **Provide Explanation**: Provide a detailed, but concise, explanation justifying why a given subtype was assigned to the statement.\n",
    "    - Include reasoning related to the template structure, terminology used, or specific conditions the rule mentions.\n",
    "\n",
    "# {rule_type} Rule subtypes\n",
    "\n",
    "{subclassification_text}\n",
    "\n",
    "## Definitions\n",
    "- **attribute term**: A term that signifies a non-Boolean property of an entity class (or object class).\n",
    "- **role term**: A term that signifies the role played by one of the participating parties or objects in a relationship: for example, employer and employee are role terms (with respect to the relationship whereby an organization employs a person), whereas organization and person are not role terms.\n",
    "- **category attribute term**: A term is usually admin-defined, with some external inputs. They have unique labels (e.g., 'Cash') and may use internal codes. Boolean attributes indicate \"Yes\" or \"No\" responses, shown as checkboxes or \"Y/N\" fields.\n",
    "- **quantitative attribute**: An attribute on which some arithmetic can be performed (e.g., addition, subtraction) and on which comparisons other than \"=\" and \"<>\" can be performed.\n",
    "- **qualifying clause**: refines a rule's scope or specificity by limiting the subject or other terms to particular subsets or conditions (e.g., “for a return journey” or “that is current”).\n",
    "\n",
    "# Output Format\n",
    "\n",
    "The output must be provided in JSON format. Each element of the statement list must contain:\n",
    "- `doc_id`: The Document ID from the input.\n",
    "- `statement_id`: The original statement.\n",
    "- `statement_text`: The original statement_text.\n",
    "- `statement_source`: The original statement_source.\n",
    "- `classification`: A list that may contain multiple entries, each of which should have:\n",
    "    - `subtype`: Assigned rule subtype, use the title of the section/subsection (e.g., \"Activity time limit rules\").\n",
    "    - `templates_ids`: A list of template IDs that matched the statement.\n",
    "    - `confidence`: A float indicating confidence in classification.\n",
    "    - `explanation`: A textual explanation detailing why the classification was appropriate.\n",
    "\n",
    "The output JSON should look like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    {{\n",
    "        \"doc_id\": \"some doc id\",\n",
    "        \"statement_id\": \"some id\",\n",
    "        \"statement_text\": \"some text\",\n",
    "        \"statement_source\": \"some source\",\n",
    "        \"classification\": [\n",
    "            {{\n",
    "                \"subtype\": \"Some Subtype Title\",\n",
    "                \"templates_ids\": [\"T123\", \"T456\"],\n",
    "                \"confidence\": 0.9,\n",
    "                \"explanation\": \"This statement restricts the occurrence of an activity during a specified time. The use of 'must not occur' clearly indicates an Activity time limit rule.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"subtype\": \"Another Subtype Title\",\n",
    "                \"templates_ids\": [\"T789\"],\n",
    "                \"confidence\": 0.4,\n",
    "                \"explanation\": \"There are elements of a participation restriction, but since it isn't clearly specified, the match is weak.\"\n",
    "            }}\n",
    "        ]\n",
    "    }},\n",
    "    {{\n",
    "        \"doc_id\": \"another doc id\",\n",
    "        \"statement_id\": \"another id\",\n",
    "        \"statement_text\": \"another text\",\n",
    "        \"statement_source\": \"another source\",\n",
    "        \"classification\": [\n",
    "            {{\n",
    "                \"subtype\": \"Subtype Title\",\n",
    "                \"templates_ids\": [\"T123\"],\n",
    "                \"confidence\": 0.7,\n",
    "                \"explanation\": \"The clause dictates who is allowed to perform the task, indicating a party restriction context.\"\n",
    "            }}\n",
    "        ]\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "# Notes\n",
    "- **Detail the Reasoning**: Ensure the explanations refer to template structure, specific terminology used, or matching requirements for the rule subtype.\n",
    "- **Confidence Assessment**: Be honest about the degree of certainty in your classification, and provide meaningful values for confidence (e.g., if templates do not match perfectly but there are similarities, confidence should be moderate to low).\n",
    "- **Multiple Classifications**: In cases where one statement seems to fit multiple rule subtypes, include multiple classifications with appropriate confidence ratings and explanations for each.\n",
    "\n",
    "This output will be used to not only understand classifications but also inform next steps regarding validation and business rule structuring.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operative Rules classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing P1 - Classify Operative Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt (Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "rules_to_classify_p1 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_source\": item[\"source\"],\n",
    "        \"statement_text\": item[\"statement\"]\n",
    "    }\n",
    "    for item in processor.get_rules()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:42 - INFO - P1. Classifing Operative Rules...\n",
      "2024-11-05 22:07:48 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-05 22:07:48 - INFO - Execution time for query_instruct_llm: 5.90 seconds\n",
      "2024-11-05 22:07:48 - INFO - Saving checkpoint...\n",
      "2024-11-05 22:07:48 - INFO - Checkpoint saved.\n",
      "2024-11-05 22:07:48 - INFO - Finished processing classification.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Classify Operative Rules\n",
    "user_prompt = get_user_prompt_classify(rules_to_classify_p1)\n",
    "system_prompt = get_system_prompt_classify_p1()\n",
    "\n",
    "logger.info(\"P1. Classifing Operative Rules...\")\n",
    "logger.debug(system_prompt)\n",
    "logger.debug(user_prompt)\n",
    "\n",
    "response_classify_p1 = query_instruct_llm(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    document_model=List[StatementClassification],\n",
    "    llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "    temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "    max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    ")\n",
    "\n",
    "logger.debug(response_classify_p1)\n",
    "\n",
    "doc_1 = Document(id=\"classify_P1\", type=\"llm_response_classification\", content=response_classify_p1)\n",
    "manager.add_document(doc_1)\n",
    "\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)\n",
    "\n",
    "logger.info(\"Finished processing classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing P2 - Classify and get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt (Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System and user prompt data\n",
    "\n",
    "Create a prompt for each of the type of rule (Activity, Data, Party) from P1 with the statements for that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = manager.retrieve_document(\"classify_P1\", doc_type=\"llm_response_classification\")\n",
    "\n",
    "rules_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item.doc_id,\n",
    "        \"statement_id\": item.statement_id,\n",
    "        \"statement_source\": item.statement_source,\n",
    "        \"statement_text\": item.statement_text,\n",
    "        \"statement_type\": max(item.classification, key=lambda x: x.confidence).type  # Get type with highest confidence\n",
    "    }\n",
    "    for item in document.content\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt for each of the type of rule (Activity, Data, Party) from P1 with the statements for that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token count system prompt Party: 3113\n",
      "token count user prompt Party: 231\n",
      "token count system prompt Activity: 5254\n",
      "token count user prompt Activity: 377\n"
     ]
    }
   ],
   "source": [
    "user_prompt_classify_p2o, system_prompt_classify_p2o = classify_and_add_prompts(\"operative rule\", \"Operative\", rules_to_classify_p2,  manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:49 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P2. User Prompt to classify Operative Rules and get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing P2 - Subclassify Operative Rules\n",
    "\n",
    "For each type of rule get response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:07:49 - INFO - P2_Operative. processing 2 statements and 2 prompts...\n",
      "2024-11-05 22:07:49 - INFO - P2_Operative. Classifying and getting templates for rules...\n",
      "2024-11-05 22:07:49 - INFO - Processing classification and templates...\n",
      "2024-11-05 22:07:59 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-05 22:07:59 - INFO - Execution time for query_instruct_llm: 9.59 seconds\n",
      "2024-11-05 22:07:59 - INFO - Finished processing classification and templates.\n",
      "2024-11-05 22:07:59 - INFO - Processing classification and templates...\n",
      "2024-11-05 22:08:14 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-05 22:08:14 - INFO - Execution time for query_instruct_llm: 11.46 seconds\n",
      "2024-11-05 22:08:14 - INFO - Finished processing classification and templates.\n"
     ]
    }
   ],
   "source": [
    "all_responses_classify_p2o = classify_and_get_templates(\n",
    "    \"rules\", \"P2_Operative\", user_prompt_classify_p2o, system_prompt_classify_p2o, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 22:08:14 - INFO - Saving checkpoint...\n",
      "2024-11-05 22:08:14 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the checkpoint after adding the combined document\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitional rules classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Terms\n",
    "\n",
    "Terms without definition will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "terms_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"signifier\"],\n",
    "        \"statement_source\": item[\"source\"],\n",
    "        \"statement_text\": item[\"definition\"],\n",
    "        \"statement_type\": \"Definitional\"\n",
    "    }\n",
    "    for item in processor.get_terms(\"non_null\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms_to_classify_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:42:36 - INFO - Processing batch 1 with 15 items\n",
      "2024-11-06 00:42:36 - INFO - Batch 1 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:36 - INFO - Batch 1 - token count user prompt Definitional: 1143\n",
      "2024-11-06 00:42:36 - INFO - Processing batch 2 with 15 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 2 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 2 - token count user prompt Definitional: 1119\n",
      "2024-11-06 00:42:37 - INFO - Processing batch 3 with 15 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 3 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 3 - token count user prompt Definitional: 1233\n",
      "2024-11-06 00:42:37 - INFO - Processing batch 4 with 15 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 4 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 4 - token count user prompt Definitional: 1158\n",
      "2024-11-06 00:42:37 - INFO - Processing batch 5 with 15 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 5 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 5 - token count user prompt Definitional: 1088\n",
      "2024-11-06 00:42:37 - INFO - Processing batch 6 with 15 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 6 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 6 - token count user prompt Definitional: 1564\n",
      "2024-11-06 00:42:37 - INFO - Processing batch 7 with 1 items\n",
      "2024-11-06 00:42:37 - INFO - Batch 7 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:42:37 - INFO - Batch 7 - token count user prompt Definitional: 183\n"
     ]
    }
   ],
   "source": [
    "user_prompt_classify_p2_terms, system_prompt_classify_p2_terms = classify_and_add_prompts(\"term\", \"Definitional\", terms_to_classify_p2, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(system_prompt_classify_p2_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:45:33 - INFO - P2_Definitional. processing 7 prompts...\n",
      "2024-11-06 00:45:33 - INFO - P2_Definitional. Classifying and getting templates for rules...\n",
      "2024-11-06 00:45:33 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:46:27 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:46:27 - INFO - Execution time for query_instruct_llm: 46.78 seconds\n",
      "2024-11-06 00:46:27 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:46:27 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:47:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:47:16 - INFO - Execution time for query_instruct_llm: 45.82 seconds\n",
      "2024-11-06 00:47:16 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:47:16 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:47:57 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:47:57 - INFO - Execution time for query_instruct_llm: 37.66 seconds\n",
      "2024-11-06 00:47:57 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:47:57 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:48:34 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:48:34 - INFO - Execution time for query_instruct_llm: 33.38 seconds\n",
      "2024-11-06 00:48:34 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:48:34 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:49:08 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:49:08 - INFO - Execution time for query_instruct_llm: 29.82 seconds\n",
      "2024-11-06 00:49:08 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:49:08 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:50:08 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:50:08 - INFO - Execution time for query_instruct_llm: 52.52 seconds\n",
      "2024-11-06 00:50:08 - INFO - Finished processing classification and templates.\n",
      "2024-11-06 00:50:08 - INFO - Processing classification and templates...\n",
      "2024-11-06 00:50:13 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:50:13 - INFO - Execution time for query_instruct_llm: 5.00 seconds\n",
      "2024-11-06 00:50:13 - INFO - Finished processing classification and templates.\n"
     ]
    }
   ],
   "source": [
    "all_responses_classify_terms = classify_and_get_templates(\n",
    "    \"terms\", \"P2_Definitional\", user_prompt_classify_p2_terms, system_prompt_classify_p2_terms, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avarage 45s per prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_responses_classify_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:50:42 - INFO - Saving checkpoint...\n",
      "2024-11-06 00:50:42 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the checkpoint after adding the combined document\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"signifier\"],\n",
    "        \"statement_source\": item[\"source\"],\n",
    "        \"statement_text\": item[\"definition\"],\n",
    "        \"statement_type\": \"Definitional\"\n",
    "    }\n",
    "    for item in processor.get_names(\"non_null\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_to_classify_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:51:57 - INFO - Processing batch 1 with 15 items\n",
      "2024-11-06 00:51:57 - INFO - Batch 1 - token count system prompt Definitional: 6008\n",
      "2024-11-06 00:51:57 - INFO - Batch 1 - token count user prompt Definitional: 1147\n"
     ]
    }
   ],
   "source": [
    "user_prompt_classify_p2_names, system_prompt_classify_p2_names = classify_and_add_prompts(\"name\", \"Definitional\", names_to_classify_p2, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:52:03 - INFO - P2_Definitional. processing 1 prompts...\n",
      "2024-11-06 00:52:03 - INFO - P2_Definitional. Classifying and getting templates for rules...\n",
      "2024-11-06 00:52:03 - INFO - Processing classification and templates prompt 1 ...\n",
      "2024-11-06 00:52:31 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:52:31 - INFO - Execution time for query_instruct_llm: 23.77 seconds\n",
      "2024-11-06 00:52:31 - INFO - Finished processing classification and templates prompt 1.\n"
     ]
    }
   ],
   "source": [
    "all_responses_classify_p2_names = classify_and_get_templates(\n",
    "    \"names\", \"P2_Definitional\", user_prompt_classify_p2_names, system_prompt_classify_p2_names, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_responses_classify_p2_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:52:38 - INFO - Saving checkpoint...\n",
      "2024-11-06 00:52:38 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the checkpoint after adding the combined document\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fact / Fact Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "facts_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_source\": item[\"source\"],\n",
    "        \"statement_text\": item[\"statement\"],\n",
    "        \"statement_type\": \"Definitional\"\n",
    "    }\n",
    "    for item in processor.get_facts()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(facts_to_classify_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:52:45 - INFO - Processing batch 1 with 15 items\n",
      "2024-11-06 00:52:45 - INFO - Batch 1 - token count system prompt Definitional: 6009\n",
      "2024-11-06 00:52:45 - INFO - Batch 1 - token count user prompt Definitional: 1354\n",
      "2024-11-06 00:52:45 - INFO - Processing batch 2 with 2 items\n",
      "2024-11-06 00:52:46 - INFO - Batch 2 - token count system prompt Definitional: 6009\n",
      "2024-11-06 00:52:46 - INFO - Batch 2 - token count user prompt Definitional: 179\n"
     ]
    }
   ],
   "source": [
    "user_prompt_classify_p2_facts, system_prompt_classify_p2_facts = classify_and_add_prompts(\"fact type\", \"Definitional\", facts_to_classify_p2, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:52:58 - INFO - P2_Definitional. processing 2 prompts...\n",
      "2024-11-06 00:52:58 - INFO - P2_Definitional. Classifying and getting templates for rules...\n",
      "2024-11-06 00:52:58 - INFO - Processing classification and templates prompt 1 ...\n",
      "2024-11-06 00:53:20 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:53:51 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:53:51 - INFO - Execution time for query_instruct_llm: 49.33 seconds\n",
      "2024-11-06 00:53:51 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-11-06 00:53:51 - INFO - Processing classification and templates prompt 2 ...\n",
      "2024-11-06 00:54:01 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-06 00:54:01 - INFO - Execution time for query_instruct_llm: 10.14 seconds\n",
      "2024-11-06 00:54:01 - INFO - Finished processing classification and templates prompt 2.\n"
     ]
    }
   ],
   "source": [
    "all_responses_classify_p2_facts = classify_and_get_templates(\n",
    "    \"facts\", \"P2_Definitional\", user_prompt_classify_p2_facts, system_prompt_classify_p2_facts, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avarage 45s per prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_responses_classify_p2_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:54:29 - INFO - Saving checkpoint...\n",
      "2024-11-06 00:54:29 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the checkpoint after adding the combined document\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "For the the first parte (prompt_classify_p1), the assigned confidence levels reflect a calibrated approach to statements involving multiple classifications where a dominant rule type is not explicitly evident. For instance, when an statement primarily constrains data (Data rule) but also includes specific parties (Party rule), a high confidence level is attributed to Data while a moderate confidence level is applied to Party, acknowledging its secondary relevance. Similarly, statements referencing roles such as “Secretary” or “interested person” without explicit party restrictions are assigned moderate confidence for Party classification due to interpretive ambiguity. Procedural elements that impact data handling, such as document forwarding, receive high confidence for Data rules; however, a moderate confidence level is assigned for Activity rules when procedural references are indirect. This methodology prioritizes primary rule types while accounting for the interpretive limits of secondary classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Stop here\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
