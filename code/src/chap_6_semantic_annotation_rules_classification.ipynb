{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/asantos2000/master-degree-santos-anderson/blob/main/code/src/chap_6_semantic_annotation_rules_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lwF6l0TKfK0"
   },
   "source": [
    "# Semantic Annotation - rules classification\n",
    "\n",
    "Classify elements according to the taxonomy and get templates for transformation.\n",
    "\n",
    "Chapter 6. Ferramentas de suporte\n",
    "- Section 6.2 Implementação dos principais componentes\n",
    "  - Section 6.2.3 Anotações semânticas\n",
    "    - Section Algoritmo \"taxonomy classification and templates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  !rm -rf cfr2sbvr configuration checkpoint\n",
    "  !git clone https://github.com/asantos2000/master-degree-santos-anderson.git cfr2sbvr\n",
    "  %pip install -r cfr2sbvr/code/requirements.txt\n",
    "  !cp -r cfr2sbvr/code/src/configuration .\n",
    "  !cp -r cfr2sbvr/code/src/checkpoint .\n",
    "  !cp -r cfr2sbvr/code/config.colab.yaml config.yaml\n",
    "  DEFAULT_CONFIG_FILE=\"config.yaml\"\n",
    "else:\n",
    "  DEFAULT_CONFIG_FILE=\"../config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from itertools import islice\n",
    "\n",
    "# Third-party libraries\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Local application/library-specific imports\n",
    "import checkpoint.main as checkpoint\n",
    "from checkpoint.main import (\n",
    "    restore_checkpoint,\n",
    "    save_checkpoint,\n",
    "    Document,\n",
    "    DocumentProcessor,\n",
    ")\n",
    "import configuration.main as configuration\n",
    "import logging_setup.main as logging_setup\n",
    "import token_estimator.main as token_estimator\n",
    "from token_estimator.main import estimate_tokens\n",
    "import rules_taxonomy_provider.main as rules_taxonomy_provider\n",
    "from rules_taxonomy_provider.main import RuleInformationProvider\n",
    "import llm_query.main as llm_query\n",
    "from llm_query.main import query_instruct_llm\n",
    "\n",
    "DEV_MODE = True\n",
    "\n",
    "if DEV_MODE:\n",
    "    # Development mode\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(configuration)\n",
    "    importlib.reload(logging_setup)\n",
    "    importlib.reload(checkpoint)\n",
    "    importlib.reload(token_estimator)\n",
    "    importlib.reload(rules_taxonomy_provider)\n",
    "    importlib.reload(llm_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Default settings, check them before run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = configuration.load_config(DEFAULT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging_setup.setting_logging(config[\"DEFAULT_LOG_DIR\"], config[\"LOG_LEVEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "Documents, annoted datasets, statistics and metrics about the execution of the notebook are stored by checkpoint module.\n",
    "\n",
    "Checkpoints are stored / retrieved at the directory `DEFAULT_CHECKPOINT_FILE` in the configuration file.\n",
    "\n",
    "During the execution, it will restore the checkpoint at the beginning of the section and saved at the end. We can run and restore the checkpoint several times. If the run fails, check the closest checkpoint and restore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run after extraction\n",
    "last_checkpoint = configuration.get_last_filename(config[\"DEFAULT_CHECKPOINT_DIR\"], \"documents\", \"json\")\n",
    "\n",
    "logger.info(f\"{last_checkpoint=}\")\n",
    "\n",
    "config[\"DEFAULT_CHECKPOINT_FILE\"] = last_checkpoint\n",
    "\n",
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions and data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model for P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(BaseModel):\n",
    "    type: str = Field(..., description=\"Type of the rule (e.g., Party, Data, Activity)\")\n",
    "    confidence: float = Field(..., ge=0, le=1, description=\"Confidence level of the classification\")\n",
    "    explanation: str = Field(..., description=\"Explanation of why the classification was made\")\n",
    "\n",
    "\n",
    "class StatementClassification(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'\")\n",
    "    statement_title: str = Field(..., description=\"The title of the statement\")\n",
    "    statement_text: str = Field(..., description=\"The statement to be classified\")\n",
    "    statement_sources: List[str] = Field(..., description=\"List of statement's source\")\n",
    "    classification: List[Classification] = Field(..., description=\"List of classifications with explanations\")\n",
    "\n",
    "class StatementClassifications(BaseModel):\n",
    "    StatementClassifications: List[StatementClassification]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model for P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubClassification(BaseModel):\n",
    "    subtype: str = Field(..., description=\"Subtype of the rule. The title of the section/subsection.\")\n",
    "    templates_ids: List[str] = Field(..., description=\"List of template IDs that matched the statement.\")\n",
    "    confidence: float = Field(..., ge=0, le=1, description=\"Confidence level of the classification\")\n",
    "    explanation: str = Field(..., description=\"Explanation of why the classification was made\")\n",
    "\n",
    "\n",
    "class StatementSubClassification(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'\")\n",
    "    statement_title: str = Field(..., description=\"The title of the statement\")\n",
    "    statement_text: str = Field(..., description=\"The statement to be classified\")\n",
    "    statement_sources: List[str] = Field(..., description=\"List of statement's source\")\n",
    "    classification: List[SubClassification] = Field(..., description=\"List of classifications with explanations\")\n",
    "\n",
    "class StatementSubClassifications(BaseModel):\n",
    "    StatementSubClassifications: List[StatementSubClassification]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_add_prompts(element_type, rule_type, rules_to_classify, manager):\n",
    "    user_prompt_classify = []\n",
    "    system_prompt_classify = []\n",
    "\n",
    "    # Helper to split list into batches with up to 15 items each\n",
    "    def batch(iterable, max_batch_size):\n",
    "        iterator = iter(iterable)\n",
    "        while True:\n",
    "            batch_list = list(islice(iterator, max_batch_size))\n",
    "            if not batch_list:\n",
    "                break\n",
    "            yield batch_list\n",
    "\n",
    "    # Process rules in batches of up to 15 items\n",
    "    for batch_num, batch_rules in enumerate(batch(rules_to_classify, 5)):\n",
    "        logger.info(f\"Processing batch {batch_num + 1} with {len(batch_rules)} items\")\n",
    "        \n",
    "        # Group by 'statement_type' within each batch\n",
    "        grouped_data = defaultdict(list)\n",
    "        for item in batch_rules:\n",
    "            grouped_data[item[\"statement_type\"]].append(item)\n",
    "\n",
    "        # Process each statement type within the batch\n",
    "        for statement_type, items in grouped_data.items():\n",
    "            # print(10 * \"cap \")\n",
    "            # print(len(batch_rules), element_type, rule_type, statement_type)\n",
    "            # print(10 * \"cap \")\n",
    "            system_prompt = get_system_prompt_classify_p2(len(batch_rules), element_type, rule_type, statement_type)\n",
    "            system_prompt_classify.append(system_prompt)\n",
    "            user_prompt = get_user_prompt_classify(items)\n",
    "            user_prompt_classify.append(user_prompt)\n",
    "            \n",
    "            # Log token counts for the current batch and statement type\n",
    "            logger.info(f\"Batch {batch_num + 1} - token count system prompt {statement_type}: {estimate_tokens(system_prompt)}\")\n",
    "            logger.info(f\"Batch {batch_num + 1} - token count user prompt {statement_type}: {estimate_tokens(user_prompt)}\")\n",
    "\n",
    "            # Add documents to the manager with batch and statement type info\n",
    "            manager.add_document(\n",
    "                Document(\n",
    "                    id=f\"prompt-classify_P2_{element_type.replace(' ', '_')}_batch{batch_num + 1}_{statement_type}\",\n",
    "                    type=\"prompt\",\n",
    "                    content=system_prompt\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return user_prompt_classify, system_prompt_classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_get_templates(\n",
    "    element_name, part, user_prompt_classify, system_prompt_classify, manager\n",
    "):\n",
    "    # Log the start of the process\n",
    "    logger.info(\n",
    "        f\"{part}. processing {len(system_prompt_classify)} prompts...\"\n",
    "    )\n",
    "    logger.info(f\"{part}. Classifying and getting templates for rules...\")\n",
    "\n",
    "    # Initialize an empty list to accumulate all responses\n",
    "    all_responses_classify = []\n",
    "\n",
    "    # Loop through each pair of user and system prompts with a counter\n",
    "    for index, (user_prompt, system_prompt) in enumerate(zip(user_prompt_classify, system_prompt_classify), start=1):\n",
    "        logger.info(f\"Processing classification and templates prompt {index} ...\")\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "        # Query the language model\n",
    "        response_classify, completion, elapse_time = query_instruct_llm(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            document_model=StatementSubClassifications,\n",
    "            llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "            temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "            max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    "        )\n",
    "\n",
    "        logger.info(response_classify.StatementSubClassifications)\n",
    "        logger.info(f\"{len(response_classify.StatementSubClassifications)} rules classified and templates obtained.\")\n",
    "\n",
    "        # Accumulate the responses in the list\n",
    "        all_responses_classify.extend(response_classify.StatementSubClassifications)\n",
    "\n",
    "        logger.info(f\"Finished processing classification and templates prompt {index}.\")\n",
    "\n",
    "    # After the loop, create a single Document with all the accumulated responses\n",
    "    if all_responses_classify:\n",
    "        doc = Document(\n",
    "            id=f\"classify_{part}_{element_name.replace(' ', '_')}\",\n",
    "            type=\"llm_response_classification\",\n",
    "            content=all_responses_classify,\n",
    "            elapsed_times=[elapse_time],\n",
    "            completions=[completion.dict()],\n",
    "        )\n",
    "        manager.add_document(doc)\n",
    "\n",
    "    return all_responses_classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_keys(elements: List[Dict[str, Any]], keys: List[str], dataset_name: str) -> None:\n",
    "    \"\"\"Check for missing keys in a list of dictionaries and print status for a dataset.\"\"\"\n",
    "    missing_found = False  # Flag to track if any key is missing\n",
    "    for element in elements:\n",
    "        for key in keys:\n",
    "            if not element.get(key):\n",
    "                logger.info(f\"Dataset '{dataset_name}' - Missing key: '{key}' in element: {element}\")\n",
    "                missing_found = True\n",
    "\n",
    "    # Print message based on whether keys are missing or not\n",
    "    if not missing_found:\n",
    "        logger.info(f\"Dataset '{dataset_name}' - All elements have the required keys.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Datasets used in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True tables\n",
    "\n",
    "True tables are annotated or \"golden\" datasets in which entities have been manually identified and labeled within the original source data.\n",
    "\n",
    "True tables for sectiona 275.0-2, 275.0-5 and 275.0-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load true table for P1 - Taxonomy Classification - top level and P2 - Taxonomy Classification - sub levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config['DEFAULT_DATA_DIR']}/documents_true_table.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"classify_P1|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"classify_P2_Operative_rules|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"classify_P2_Definitional_terms|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"classify_P2_Definitional_names|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"classify_P2_Definitional_facts|true_table\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomy classification and templates for definitional and operative rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for classify rules using the top level of Witt (2012) taxonomy.\n",
    "\n",
    "In examining the classification of terms, names, fact types, and rules within business systems, key distinctions arise between definitional and operative rules, as well as in the structuring of term definitions. Terms, names, and fact types are foundational elements in the taxonomy of definitional rules, though they are not rules themselves. Instead, they serve as the core vocabulary for creating precise definitions and facilitating the rule-making process within an organization. Terms represent general concepts or classes, names uniquely identify specific instances or entities, and fact types capture relationships between terms. Together, these elements enable the consistent and unambiguous use of language across rule statements, models, and documentation, ensuring that definitional and operative rules function cohesively.\n",
    "\n",
    "Definitional rules aim to provide precise structures for organizational concepts, establishing clear, logical statements that support consistent interpretation and application of business language. These rules formalize term definitions, establish categorization schemes, and delineate relationships using fact types, which are classified by their structure as unary, binary, or higher-order and allow organizations to express relationships from simple Boolean properties to complex multi-term associations. When structured through definitional rule templates, fact types enhance clarity, facilitate shared understanding, and ensure accurate application within organizational rules, while supporting a conceptual backbone for business definitions.\n",
    "\n",
    "Names function as unique identifiers for specific instances or entities, adding precision to rule statements that require exact identification. Embedded within definitional rules, names provide specific references crucial for rules that depend on individual entities, distinguishing them from broader terms and reducing ambiguity in complex business contexts. Through structured templates within the definitional rule taxonomy, organizations can integrate names with uniformity and clarity, allowing for reliable reference to distinct entities within rule statements and models. \n",
    "\n",
    "Operative rules, on the other hand, govern actionable requirements, setting conditions under which actions must or must not occur. These include data, activity, and party rules, each ensuring compliance, standardization, and procedural integrity across business processes. Operative rules provide the necessary conditions for maintaining organizational consistency, detailing what actions are authorized in particular circumstances or specifying roles within defined tasks, thereby aligning processes with business objectives.\n",
    "\n",
    "To formalize term definitions, statements must adhere to specific templates within the definitional rule taxonomy, which clearly articulate each term's scope, meaning, and responsibilities. For instance, the term \"Commission\" can be formally defined within Template T7, part of the definitional rule taxonomy, to clarify its procedural functions as the entity that receives and forwards legal documents. By using templates for definitional rules, organizations achieve consistent, unambiguous documentation of terms, fact types, and names, which minimizes ambiguity and ensures standardized interpretation across all business contexts. This structured approach supports precise rule governance and enhances communication within organizational processes, reinforcing the integrity and reliability of rule-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt (Instructions) for classify operative rules using the top level of Witt (2012) taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_classify_p1():\n",
    "    return \"\"\"\n",
    "You are an expert in SBVR (Semantics of Business Vocabulary and Business Rules).\n",
    "\n",
    "You are working for regulatory bodies, auditors, or process managers.\n",
    "\n",
    "You will be provided with a list of statements formatted as JSON.\n",
    "\n",
    "Your task is to classify each statement into one or more Operative Rules types according to the given definitions.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Summarize statement**: Summarize the given statement to understand its structure and content.\n",
    "\n",
    "2. **Classify statement**: Classify each Operative Rule statement into one or more of the provided rule types. The **Operative rules** govern actions or constraints that must or must not happen under certain conditions, such as Data Rules, Activity Rules, and Party Rules. types to classify are:\n",
    "\n",
    "- **Party rules**: A \"Party rule\" is a type of operative rule that establishes distinctions or constraints involving parties or the roles they perform. To identify a party rule, it is important to recognize its defining characteristics, as these rules often specify who can carry out certain activities, access particular information, or hold specific responsibilities. Party rules may include restrictions on who is permitted to perform specific roles or processes. For example, a rule might state that a person can serve as the pilot in command only if they hold a current command endorsement. Additionally, these rules may enforce role separation to prevent conflicts of interest, such as a requirement that the cabin crew member verifying an aircraft door's disarmed status cannot be the same individual who initially disarmed it. In other cases, party rules may require role binding, ensuring continuity by stipulating that the consultant who signs a quality review report must be the one who conducted the review. Party rules can also govern information access, specifying who is authorized to view, create, or modify certain data. For instance, a rule might state that an employee’s leave record can only be accessed by the employee, their supervisor, or a human resources officer. Furthermore, responsibility rules fall under this category by defining accountability for specific actions or obligations, such as requiring the receiving parties in a property transfer to pay the associated stamp duty. These rules can be identified by linking actions or processes (predicates) to subjects, like roles or data, while applying conditions that qualify or limit their application. \n",
    "- **Data rules**: A \"Data rule\" imposes constraints or requirements on the data used in transactions, records, or systems. Identifying a data rule involves analyzing its structure, purpose, and type, which include cardinality, content, and update rules. Data cardinality rules govern the presence and multiplicity of data items. These may include mandatory rules requiring data items, such as specifying at least one passenger name in a flight booking confirmation. They can also restrict data, such as ensuring a one-way flight booking does not include a return date, or enforce limits on the number of data instances in a transaction. Data content rules regulate the values within data items. Examples include value set rules, which require a data item to match one of a specified set of valid values, and range rules that constrain a data item's value to within a specific range. Equality rules ensure consistency between related data items, such as requiring that an origin city matches the corresponding booking request. Additionally, uniqueness constraints ensure that a data item's value does not duplicate within a dataset, and consistency rules maintain logical relationships between multiple data points. Lastly, data update rules constrain modifications to existing data. These rules may prohibit updates entirely, restrict the scope of permissible changes (such as maintaining valid state transitions), or enforce monotonic trends like numeric values that can only increase or decrease. To identify a data rule, it is essential to examine the specific constraints or requirements applied to data items, their interrelationships, and their contexts within a given system or transaction. Templates and formalized structures, can aid in distinguishing these rules effectively.\n",
    "- **Activity rules**: An \"Activity rule\" is an operative rule designed to constrain the operation of business processes or activities. Identifying an activity rule involves understanding its subcategories, which define how activities are regulated or mandated. The primary types of activity rules are activity restriction rules, activity obligation rules, and process decision rules. Activity restriction rules are used to place limitations on when or under what conditions an activity can occur. For example, time-based restrictions may stipulate that online check-in for a flight can only occur within a specific time window, such as the 24 hours before departure. Similarly, exclusion period rules prohibit activities during certain times, such as a restriction on operating machinery during nighttime hours. Activity pre-condition rules ensure that an event must occur before another activity can take place, such as requiring passengers to complete a security screening before boarding. Activity obligation rules, on the other hand, specify activities that must be performed either within a maximum time after a triggering event or as soon as practical. For instance, acknowledging an order may be mandated to occur within 24 hours of receipt. These rules enforce timely action and compliance with operational requirements. Process decision rules determine actions in response to specific situations. These rules guide devices or processes, such as ensuring that a ticket barrier retains invalid tickets to prevent misuse. To identify an activity rule, it is essential to look for statements that define constraints, obligations, or decision-making criteria for activities. Such rules are often structured using specific templates that articulate the conditions, timeframes, or triggers associated with the activity. Recognizing these elements helps in categorizing activity rules effectively.\n",
    "\n",
    "2. Assess a **confidence level** for each classification between 0 and 1. Assign confidence scores to each class for the given statement, ensuring that no two classes receive the same score. If one class is assigned a score (e.g., 0.6), the others must have distinct values that are either higher or lower. The scores should reflect the likelihood of each class while avoiding ties.\n",
    "\n",
    "3. **Explain classification**: You also need to record a confidence level for each classification and provide an explanation for why the classification was made.\n",
    "\n",
    "4. **Repeat for each statement**: Repeat the process for each statement in the list.\n",
    "\n",
    "5. **Output format**: Your output must also be in JSON format. It should contain, for each statement:\n",
    "\n",
    "- The `doc_id`\n",
    "- The `statement_id`\n",
    "- The `statement_title`\n",
    "- The original `statement_text`\n",
    "- The `statement_sources` of the statement\n",
    "- A list of classifications (`classification`), each containing:\n",
    "  - The `type` of the rule.\n",
    "  - The `confidence` in your classification.\n",
    "  - An `explanation` detailing why you made the classification decision.\n",
    "\n",
    "Here is an example of the expected output:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"doc_id\": \"some doc id\",\n",
    "        \"statement_id\": \"some id\",\n",
    "        \"statement_title\": \"some title\",\n",
    "        \"statement_text\": \"some text\",\n",
    "        \"statement_sources\": [\"some source\"],\n",
    "        \"classification\": [\n",
    "            {\n",
    "                \"type\": \"Activity rules\",\n",
    "                \"confidence\": 0.9,\n",
    "                \"explanation\": \"This statement defines ...\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"Party rules\",\n",
    "                \"confidence\": 0.2,\n",
    "                \"explanation\": \"There is little reference ...\"\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"doc_id\": ...,\n",
    "        \"statement_id\": ...,\n",
    "        \"statement_title\": ...,\n",
    "        \"statement_text\": ...,\n",
    "        \"statement_sources\": ...,\n",
    "        \"classification\": ...\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "# Notes\n",
    "- **Detail the Reasoning**: Make sure to provide explanations that justify why a particular rule type was chosen.\n",
    "- **Confidence Values**: The confidence value should genuinely represent how strongly you believe the classification is correct, with 1 being an absolute match and 0 meaning unlikely.\n",
    "\n",
    "Make sure that every statement is analyzed thoroughly, and the final justification for each classification is straightforward and adequately supports both the type choice and confidence level.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt including the list of statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_classify(rules_to_classify):\n",
    "    return f\"\"\"\n",
    "# Classification Task:\n",
    "\n",
    "Analyze the following statements based on the above guidelines:\n",
    "\n",
    "{json.dumps(rules_to_classify, indent=2)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt (Instructions) for classify definitional and operative rules using the sub levels of Witt (2012) taxonomy.\n",
    "\n",
    "- element_type: term, name, fact, operative rule\n",
    "- rule_type: Definitional, Activity, Data, Party\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_classify_p2(element_count, element_type, rule_type, statement_type):\n",
    "    rule_information_provider = RuleInformationProvider(config[\"DEFAULT_DATA_DIR\"])\n",
    "\n",
    "    subclassification_text = rule_information_provider.get_classification_and_templates(f\"{statement_type}\")\n",
    "\n",
    "    return f\"\"\"\n",
    "You are an expert in **SBVR (Semantics of Business Vocabulary and Business Rules)**, working for regulatory bodies, auditors, or process managers.\n",
    "\n",
    "Your task is to classify {element_count} {element_type}(s) from a provided list into one or more **{rule_type} Rule subtypes**, explain each classification in detail, and assign a confidence score ranging from 0 to 1.\n",
    "\n",
    "# Approach:\n",
    "Use the **{rule_type} Rule subtype definitions**, associated templates, and guidelines to analyze each statement thoroughly, ensuring accurate classification.\n",
    "\n",
    "---\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Classify the Statement**:\n",
    "   - For each `statement_text`, determine its rule subtype according to the provided **{rule_type} Rule subtypes** and their corresponding templates.\n",
    "   - Use the provided templates, definitions, and examples to match the statement to the correct subtype.\n",
    "   - If the statement does not align with a high-level type, analyze the sublevels.\n",
    "   - The subtype to be used starts with \"subtype: <subtype name>\".\n",
    "   - You should assign a subtype and a template ID, make your best guess, justify your choice, and lower the confidence level if necessary.\n",
    "   - Templates and examples help identify subtypes.\n",
    "\n",
    "2. **Assign Confidence Level**:\n",
    "   - Assign a confidence score between **0 and 1** for each classification:\n",
    "     - **1** indicates a strong and clear match.\n",
    "     - Lower scores reflect weaker matches due to ambiguities or partial alignment.\n",
    "   - Consider both template alignment and the clarity of the statement's intent when assigning scores.\n",
    "   - Assign confidence scores to each class for the given statement, ensuring that no two classes receive the same score. If one class is assigned a score (e.g., 0.6), the others must have distinct values that are either higher or lower. The scores should reflect the likelihood of each class while avoiding ties.\n",
    "\n",
    "3. **Provide an Explanation**:\n",
    "   - Provide a concise yet detailed explanation for the assigned classification.\n",
    "   - Justify the classification by referencing:\n",
    "     - Template structure.\n",
    "     - Terminology used in the statement.\n",
    "     - Specific conditions or context highlighted by the statement.\n",
    "   - Explicitly map the elements of the statement (e.g., terms, qualifying clauses, verb phrases, conditional clauses, etc.) to template components.\n",
    "\n",
    "---\n",
    "\n",
    "# {rule_type} Rule subtypes\n",
    "\n",
    "{subclassification_text}\n",
    "\n",
    "---\n",
    "\n",
    "# Definitions\n",
    "- **attribute term**: A term that signifies a non-Boolean property of an entity class (or object class).\n",
    "- **role term**: A term that signifies the role played by one of the participating parties or objects in a relationship: for example, employer and employee are role terms (with respect to the relationship whereby an organization employs a person), whereas organization and person are not role terms.\n",
    "- **category attribute term**: A term is usually admin-defined, with some external inputs. They have unique labels (e.g., 'Cash') and may use internal codes. Boolean attributes indicate \"Yes\" or \"No\" responses, shown as checkboxes or \"Y/N\" fields.\n",
    "- **quantitative attribute**: An attribute on which some arithmetic can be performed (e.g., addition, subtraction) and on which comparisons other than \"=\" and \"<>\" can be performed.\n",
    "- **qualifying clause**: refines a rule's scope or specificity by limiting the subject or other terms to particular subsets or conditions (e.g., “for a return journey” or “that is current”).\n",
    "\n",
    "# Output Format:\n",
    "\n",
    "Each analyzed statement must be provided in JSON format. The structure for each statement is as follows:\n",
    "\n",
    "```json\n",
    "{{\n",
    "    \"doc_id\": \"The Document ID from the input\",\n",
    "    \"statement_id\": \"The original statement ID\",\n",
    "    \"statement_title\": \"The original statement_title\",\n",
    "    \"statement_text\": \"The original statement_text\",\n",
    "    \"statement_sources\": \"The original statement_sources\",\n",
    "    \"classification\": [\n",
    "        {{\n",
    "            \"subtype\": \"Assigned rule subtype, use the title of the section/subsection (e.g., Activity time limit rules)\",\n",
    "            \"templates_ids\": [\"Template ID that matched the statement.\"],\n",
    "            \"confidence\": Confidence Score (0-1),\n",
    "            \"explanation\": \"Detailed explanation of why this classification was assigned.\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "```\n",
    "\n",
    "---\n",
    "    \n",
    "## Example Output:\n",
    "\n",
    "```\n",
    "[\n",
    "    {{\n",
    "        \"doc_id\": \"some doc id\",\n",
    "        \"statement_id\": \"some id\",\n",
    "        \"statement_title\": \"some title\",\n",
    "        \"statement_text\": \"some text\",\n",
    "        \"statement_sources\": [\"some source\"],\n",
    "        \"classification\": [\n",
    "            {{\n",
    "                \"subtype\": \"Some Subtype Title\",\n",
    "                \"templates_ids\": [\"T123\", \"T456\"],\n",
    "                \"confidence\": 0.9,\n",
    "                \"explanation\": \"This statement ...\"\n",
    "            }},\n",
    "            {{\n",
    "                \"subtype\": \"Another Subtype Title\",\n",
    "                \"templates_ids\": [\"T789\"],\n",
    "                \"confidence\": 0.4,\n",
    "                \"explanation\": \"There are elements ...\"\n",
    "            }}\n",
    "        ]\n",
    "    }},\n",
    "    {{\n",
    "        \"doc_id\": \"another doc id\",\n",
    "        \"statement_id\": \"another id\",\n",
    "        \"statement_title\": \"another title\",\n",
    "        \"statement_text\": \"another text\",\n",
    "        \"statement_sources\": [\"another source\"],\n",
    "        \"classification\": [\n",
    "            {{\n",
    "                \"subtype\": \"Subtype Title\",\n",
    "                \"templates_ids\": [\"T123\"],\n",
    "                \"confidence\": 0.7,\n",
    "                \"explanation\": \"The clause dictates ...\"\n",
    "            }}\n",
    "        ]\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Additional Notes:\n",
    "- **Multiple Classifications**:\n",
    "   - A statement can have multiple classifications if it aligns with different subtypes. Justify each with appropriate confidence levels.\n",
    "- **Cross-References**:\n",
    "   - When a statement refers to another section (e.g., \"(a)(1)\"), incorporate the referenced section if it is provided or available. If unavailable, indicate this in the explanation and lower the confidence score.\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operative Rules classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing P1 - Classify Operative Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt (Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "rules_to_classify_p1 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_title\": item[\"statement_title\"],\n",
    "        \"statement_sources\": item[\"sources\"],\n",
    "        \"statement_text\": item[\"statement\"]\n",
    "    }\n",
    "    for item in processor.get_rules()\n",
    "]\n",
    "\n",
    "logger.info(f\"Total rules to classify: {len(rules_to_classify_p1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Classify Operative Rules\n",
    "user_prompt = get_user_prompt_classify(rules_to_classify_p1)\n",
    "system_prompt = get_system_prompt_classify_p1()\n",
    "\n",
    "logger.info(\"P1. Classifing Operative Rules...\")\n",
    "logger.debug(system_prompt)\n",
    "logger.debug(user_prompt)\n",
    "#raise Exception(\"Stop here\")\n",
    "\n",
    "response_classify_p1, completion_1, elapse_time_1 = query_instruct_llm(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    document_model=StatementClassifications,\n",
    "    llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "    temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "    max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    ")\n",
    "\n",
    "logger.debug(response_classify_p1)\n",
    "\n",
    "doc_1 = Document(\n",
    "    id=\"classify_P1\",\n",
    "    type=\"llm_response_classification\",\n",
    "    content=response_classify_p1.StatementClassifications,\n",
    "    elapsed_times=[elapse_time_1],\n",
    "    completions=[completion_1.dict()],\n",
    ")\n",
    "manager.add_document(doc_1)\n",
    "\n",
    "logger.info(\"Saving checkpoint...\")\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)\n",
    "\n",
    "logger.info(\"Finished processing classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average 35s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing P2 - Classify and get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User prompt (Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System and user prompt data\n",
    "\n",
    "Create a prompt for each of the type of rule (Activity, Data, Party) from P1 with the statements for that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])\n",
    "\n",
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "rules_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_title\": item[\"statement_title\"],\n",
    "        \"statement_sources\": item[\"sources\"],\n",
    "        \"statement_text\": item[\"statement\"],\n",
    "        \"statement_type\": item[\"type\"]\n",
    "    }\n",
    "    for item in processor.get_rules()\n",
    "]\n",
    "\n",
    "logger.info(f\"Total rules to classify: {len(rules_to_classify_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prompt for each of the type of rule (Activity, Data, Party) from P1 with the statements for that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_classify_p2_op_rules, system_prompt_classify_p2_op_rules = (\n",
    "    classify_and_add_prompts(\n",
    "        \"operative rule\", \"Operative\", rules_to_classify_p2, manager\n",
    "    )\n",
    ")\n",
    "\n",
    "logger.info(f\"Prompts to run {len(user_prompt_classify_p2_op_rules)}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P2. User Prompt to classify Operative Rules and get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing P2 - Subclassify Operative Rules\n",
    "\n",
    "Running classification. For each type of rule get response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses_classify_p2_op_rules = classify_and_get_templates(\n",
    "    \"rules\",\n",
    "    \"P2_Operative\",\n",
    "    user_prompt_classify_p2_op_rules,\n",
    "    system_prompt_classify_p2_op_rules,\n",
    "    manager,\n",
    ")\n",
    "\n",
    "logger.info(f\"Total responses: {len(all_responses_classify_p2_op_rules)}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, resp in enumerate(all_responses_classify_p2_op_rules):\n",
    "    print(i, resp.classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average 15s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating miss classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_first_attempt_p1 = {\n",
    "    \"doc_id\": \"\\u00a7 275.0-2\",\n",
    "    \"statement_id\": \"4\",\n",
    "    \"statement_text\": \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"statement_source\": \"(a)(3)\",\n",
    "    \"classification\": [\n",
    "        {\n",
    "            \"type\": \"Data\",\n",
    "            \"confidence\": 0.6,\n",
    "            \"explanation\": \"The statement involves certification, which is a form of data that serves as evidence of service.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Activity\",\n",
    "            \"confidence\": 0.4,\n",
    "            \"explanation\": \"The statement describes the activity of certifying and forwarding documents, which are part of the process.\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_first_attempt_p2 = {\n",
    "    \"doc_id\": \"\\u00a7 275.0-2\",\n",
    "    \"statement_id\": \"4\",\n",
    "    \"statement_text\": \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"statement_source\": \"(a)(3)\",\n",
    "    \"classification\": [\n",
    "        {\n",
    "            \"subtype\": \"Data content rules\",\n",
    "            \"templates_ids\": [],\n",
    "            \"confidence\": 0.6,\n",
    "            \"explanation\": \"The statement describes a condition under which a certification constitutes evidence of service. It involves the presence of certain documents and their forwarding, which relates to data content. However, it does not fit neatly into a specific template, leading to a moderate confidence level.\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_second_attempt_p1 = {\n",
    "    \"doc_id\": \"\\u00a7 275.0-2\",\n",
    "    \"statement_id\": \"4\",\n",
    "    \"statement_text\": \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"statement_source\": \"(a)(3)\",\n",
    "    \"classification\": [\n",
    "        {\n",
    "            \"type\": \"Party\",\n",
    "            \"confidence\": 0.7,\n",
    "            \"explanation\": \"The statement involves the certification of service to a named party, indicating a role for the Secretary and the parties involved. This aligns with Party rules as it specifies actions related to parties.\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Activity\",\n",
    "            \"confidence\": 0.3,\n",
    "            \"explanation\": \"The statement describes the certification process as part of a business activity, which aligns with Activity rules as it governs the operation of certifying service.\",\n",
    "        },\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_second_attempt_p2 = {\n",
    "    \"doc_id\": \"\\u00a7 275.0-2\",\n",
    "    \"statement_id\": \"4\",\n",
    "    \"statement_text\": \"If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\",\n",
    "    \"statement_source\": \"(a)(3)\",\n",
    "    \"classification\": [\n",
    "        {\n",
    "            \"subtype\": \"Responsibility rules\",\n",
    "            \"templates_ids\": [\"T56\"],\n",
    "            \"confidence\": 0.7,\n",
    "            \"explanation\": \"This statement involves the certification process by the Secretary, which serves as evidence of service. It defines a responsibility related to the certification of document forwarding, fitting the responsibility rule subtype.\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "The classification of the given statement initially had a lower confidence level because it could be interpreted from two distinct perspectives: a **party rule** or a **data consistency rule**. A **party rule** focuses on procedural governance and accountability, emphasizing the roles, responsibilities, and authority of individuals—in this case, the Secretary, whose certification serves as evidence of service. This perspective is crucial when considering formal roles, defining valid actions, and ensuring compliance, which makes it more fitting for scenarios involving regulatory oversight, accountability, and process management.\n",
    "\n",
    "The **data consistency rule** perspective, on the other hand, considers the relationship between different data elements—here, the certification and document forwarding—and aims to ensure logical consistency between these elements. This classification fits more technical or data-centric contexts, such as ensuring the integrity of records. However, with the prompt specifying a focus on regulatory bodies, auditors, or process managers, the interpretation naturally shifts toward the **party rule** classification. Consequently, the confidence in this classification increases, as it directly aligns with the needs of those focused on governance, responsibility, and ensuring procedural correctness.\n",
    "\n",
    "According to Opsahl-Ong et al. (2024) small changes in the prompt affect the outcome because language models are highly sensitive to the structure and context of the instructions. Minimal alterations in word choice, sentence order, or tone can lead the model to interpret the task differently, as it relies on statistical correlations and previously observed patterns. In multi-stage pipelines, this is even more critical, as a change in one module can create a cascading effect, impacting the results of subsequent stages. This sensitivity makes precise prompt adjustments essential to achieve the desired performance in specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitional rules classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms\n",
    "\n",
    "Selecting terms to classify. Terms without definition will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])\n",
    "\n",
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "terms_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_sources\": item[\"sources\"],\n",
    "        \"statement_text\": item[\"definition\"],\n",
    "        \"statement_type\": \"Definitional rules\"\n",
    "    }\n",
    "    for item in processor.get_terms(definition_filter=\"non_null\")\n",
    "]\n",
    "\n",
    "logger.info(f\"Number of terms to classify: {len(terms_to_classify_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_classify_p2_terms, system_prompt_classify_p2_terms = (\n",
    "    classify_and_add_prompts(\"term\", \"Definitional\", terms_to_classify_p2, manager)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses_classify_terms = classify_and_get_templates(\n",
    "    \"terms\",\n",
    "    \"P2_Definitional\",\n",
    "    user_prompt_classify_p2_terms,\n",
    "    system_prompt_classify_p2_terms,\n",
    "    manager,\n",
    ")\n",
    "\n",
    "logger.info(f\"Total responses: {len(all_responses_classify_terms)}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, resp in enumerate(all_responses_classify_terms):\n",
    "    print(i, resp.classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avarage 45s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection names to classify. Names without definition will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])\n",
    "\n",
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "names_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_sources\": item[\"sources\"],\n",
    "        \"statement_text\": item[\"definition\"],\n",
    "        \"statement_type\": \"Definitional rules\"\n",
    "    }\n",
    "    for item in processor.get_names(definition_filter=\"non_null\")\n",
    "]\n",
    "\n",
    "logger.info(f\"Number of names to classify: {len(names_to_classify_p2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_classify_p2_names, system_prompt_classify_p2_names = (\n",
    "    classify_and_add_prompts(\"name\", \"Definitional\", names_to_classify_p2, manager)\n",
    ")\n",
    "\n",
    "logger.info(f\"Prompts to run {len(user_prompt_classify_p2_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses_classify_p2_names = classify_and_get_templates(\n",
    "    \"names\",\n",
    "    \"P2_Definitional\",\n",
    "    user_prompt_classify_p2_names,\n",
    "    system_prompt_classify_p2_names,\n",
    "    manager,\n",
    ")\n",
    "\n",
    "logger.info(f\"Total responses: {len(all_responses_classify_p2_names)}\")\n",
    "\n",
    "# Save the checkpoint after adding the combined document\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average time 40s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact / Fact Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting facts to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])\n",
    "\n",
    "processor = DocumentProcessor(manager)\n",
    "\n",
    "facts_to_classify_p2 = [\n",
    "    {\n",
    "        \"doc_id\": item[\"doc_id\"],\n",
    "        \"statement_id\": item[\"statement_id\"],\n",
    "        \"statement_title\": item[\"statement_title\"],\n",
    "        \"statement_sources\": item[\"sources\"],\n",
    "        \"statement_text\": item[\"statement\"],\n",
    "        \"statement_type\": \"Definitional rules\"\n",
    "    }\n",
    "    for item in processor.get_facts()\n",
    "]\n",
    "\n",
    "logger.info(f\"Number of facts to classify: {len(facts_to_classify_p2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_classify_p2_facts, system_prompt_classify_p2_facts = (\n",
    "    classify_and_add_prompts(\"fact type\", \"Definitional\", facts_to_classify_p2, manager)\n",
    ")\n",
    "\n",
    "logger.info(f\"Prompts to run {len(user_prompt_classify_p2_facts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses_classify_p2_facts = classify_and_get_templates(\n",
    "    \"facts\", \"P2_Definitional\", user_prompt_classify_p2_facts, system_prompt_classify_p2_facts, manager\n",
    ")\n",
    "\n",
    "logger.info(f\"Total responses: {len(all_responses_classify_p2_facts)}\")\n",
    "\n",
    "# Save the checkpoint after adding the combined document\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avarage 30s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])\n",
    "\n",
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "pred_operative_rules = processor.get_rules()\n",
    "pred_facts = processor.get_facts()\n",
    "pred_terms = processor.get_terms()\n",
    "pred_names = processor.get_names()\n",
    "pred_terms_with_definitions = processor.get_terms(definition_filter=\"non_null\")\n",
    "pred_names_with_definitions = processor.get_names(definition_filter=\"non_null\")\n",
    "\n",
    "logger.debug(f\"Rules: {pred_operative_rules}\")\n",
    "logger.debug(f\"Facts: {pred_facts}\")\n",
    "logger.debug(f\"Terms: {pred_terms}\")\n",
    "logger.debug(f\"Names: {pred_names}\")\n",
    "logger.info(f\"Rules to evaluate: {len(pred_operative_rules)}\")\n",
    "logger.info(f\"Facts to evaluate: {len(pred_facts)}\")\n",
    "logger.info(f\"Terms to evaluate: {len(pred_terms)}\")\n",
    "logger.info(f\"Names to evaluate: {len(pred_names)}\")\n",
    "logger.info(f\"Terms with definitions: {len(pred_terms_with_definitions)}\")\n",
    "logger.info(f\"Names with definitions: {len(pred_names_with_definitions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if all elements has templates_ids and subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common keys to check\n",
    "keys = [\"templates_ids\", \"subtype\"]\n",
    "\n",
    "# List of datasets to check with their names\n",
    "datasets = [\n",
    "    (\"pred_operative_rules\", pred_operative_rules),\n",
    "    (\"pred_facts\", pred_facts),\n",
    "    (\"pred_terms_with_definitions\", pred_terms_with_definitions),\n",
    "    (\"pred_names_with_definitions\", pred_names_with_definitions),\n",
    "]\n",
    "\n",
    "# Call the function for each dataset\n",
    "for dataset_name, dataset in datasets:\n",
    "    check_missing_keys(dataset, keys, dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "In the first prompt (prompt_classify_p1), the confidence levels assigned reflect the absence of a dominant classification. For example, when a statement primarily restricts data (data rule) but also includes specific roles (party rule), a high level of confidence is assigned to the data while a moderate level of confidence is applied to the party, recognizing its secondary relevance. Similarly, statements that reference roles such as \"Secretary\" or \"interested person\" without explicit party restrictions receive moderate confidence for party classification due to ambiguity in interpretation. Procedural elements that impact data handling, such as document routing, receive high confidence for data rules; however, a moderate level of confidence is assigned to activity rules when procedural references are indirect.\n",
    "\n",
    "An example of this behavior was the classification of the sentence: “If the Secretary certifies that the Commission has received proceedings, petitions, or other documents under paragraph (a)(1) of this section and forwarded those documents to a party designated by paragraph (a)(2) of this section, such certification constitutes evidence of service to that party.” The first classification (classify_P1) had low confidence because the sentence admits two interpretations: party rule or data consistency rule. The role rule focuses on governance and accountability, highlighting the roles of individuals, such as the Secretary, whose certification serves as evidence of service. The data consistency perspective considers the relationship between data elements, evolving the logical consistency between them, such as certification and forwarding of documents.\n",
    "\n",
    "Initially, the prompt did not specify the focus, which led to the choice of the technical perspective (data) and caused problems in the second classification, where the LLM could not find an appropriate category (sublevel) in the taxonomy. With the addition of the sentence “You are working for regulators, auditors, or process managers.” interpretation has shifted to part rule classification, increasing confidence, consistency in classification, and locating a classification in the taxonomy sublevel (classify_P2_operative_rule) - Responsibility rules."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
