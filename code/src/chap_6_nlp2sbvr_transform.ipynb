{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/asantos2000/master-degree-santos-anderson/blob/main/code/src/chap_6_nlp2sbvr_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lwF6l0TKfK0"
   },
   "source": [
    "# nlp2sbvr - Transformação para SBVR\n",
    "\n",
    "Chapter 6. Ferramentas de suporte\n",
    "- Section 6.2 Implementação dos principais componentes\n",
    "  - Section 6.2.4 nlp2sbvr\n",
    "    - Section Algoritmo \"Transformação para SBVR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  !rm -rf cfr2sbvr configuration checkpoint\n",
    "  !git clone https://github.com/asantos2000/master-degree-santos-anderson.git cfr2sbvr\n",
    "  %pip install -r cfr2sbvr/code/requirements.txt\n",
    "  !cp -r cfr2sbvr/code/src/configuration .\n",
    "  !cp -r cfr2sbvr/code/src/checkpoint .\n",
    "  !cp -r cfr2sbvr/code/config.colab.yaml config.yaml\n",
    "  DEFAULT_CONFIG_FILE=\"config.yaml\"\n",
    "else:\n",
    "  DEFAULT_CONFIG_FILE=\"../config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "\n",
    "# Third-party libraries\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Any\n",
    "\n",
    "# Local application/library-specific imports\n",
    "import checkpoint.main as checkpoint\n",
    "from checkpoint.main import (\n",
    "    save_checkpoint,\n",
    "    restore_checkpoint,\n",
    "    DocumentProcessor,\n",
    "    Document,\n",
    ")\n",
    "import configuration.main as configuration\n",
    "import logging_setup.main as logging_setup\n",
    "import rules_taxonomy_provider.main as rules_taxonomy_provider\n",
    "from rules_taxonomy_provider.main import RulesTemplateProvider\n",
    "import llm_query.main as llm_query\n",
    "from llm_query.main import query_instruct_llm\n",
    "\n",
    "DEV_MODE = True\n",
    "\n",
    "if DEV_MODE:\n",
    "    # Development mode\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(configuration)\n",
    "    importlib.reload(logging_setup)\n",
    "    importlib.reload(checkpoint)\n",
    "    importlib.reload(rules_taxonomy_provider)\n",
    "    importlib.reload(llm_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Default settings, check them before run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = configuration.load_config(DEFAULT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated files for analysis in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/checkpoints/documents-2024-12-08-11.json ../outputs/extraction_report-2024-12-08-1.html ../outputs/compare_items_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(config[\"DEFAULT_CHECKPOINT_FILE\"],\n",
    "config[\"DEFAULT_EXTRACTION_REPORT_FILE\"],\n",
    "config[\"DEFAULT_EXCEL_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:50 - INFO - Logging is set up with daily rotation.\n"
     ]
    }
   ],
   "source": [
    "logger = logging_setup.setting_logging(config[\"DEFAULT_LOG_DIR\"], config[\"LOG_LEVEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "Documents, annoted datasets, statistics and metrics about the execution of the notebook are stored by checkpoint module.\n",
    "\n",
    "Checkpoints are stored / retrieved at the directory `DEFAULT_CHECKPOINT_FILE` in the configuration file.\n",
    "\n",
    "During the execution, it will restore the checkpoint at the beginning of the section and saved at the end. We can run and restore the checkpoint several times. If the run fails, check the closest checkpoint and restore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:50 - INFO - last_checkpoint='../data/checkpoints/documents-2024-12-08-10.json'\n",
      "2024-12-08 23:02:50 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:02:50 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-08-10.json.\n"
     ]
    }
   ],
   "source": [
    "# To run after classification\n",
    "last_checkpoint = configuration.get_last_filename(config[\"DEFAULT_CHECKPOINT_DIR\"], \"documents\", \"json\")\n",
    "\n",
    "logger.info(f\"{last_checkpoint=}\")\n",
    "\n",
    "config[\"DEFAULT_CHECKPOINT_FILE\"] = last_checkpoint\n",
    "\n",
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts_samples(system_prompts, user_prompts, element_name, manager):\n",
    "    manager.add_document(\n",
    "        Document(\n",
    "            id=f\"prompt-system-transform_rules_{element_name.replace(' ', '_')}\",\n",
    "            type=\"prompt\",\n",
    "            content=system_prompts[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document(\n",
    "            id=f\"prompt-user-transform_rules_{element_name.replace(' ', '_')}\",\n",
    "            type=\"prompt\",\n",
    "            content=user_prompts[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.info(f\"System prompts for {element_name}s: {len(system_prompts)}\")\n",
    "    logger.info(f\"User prompts for {element_name}s: {len(user_prompts)}\")\n",
    "\n",
    "    save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedStatement(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement.\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'.\")\n",
    "    statement_title: str = Field(..., description=\"Title of the statement.\") \n",
    "    statement: str = Field(..., description=\"The statement to be transformed.\")\n",
    "    statement_sources: List[str] = Field(..., description=\"Sources of the statement.\")\n",
    "    templates_ids: List[str] = Field(..., description=\"List of template IDs.\")\n",
    "    transformed: str = Field(..., description=\"The transformed statement.\")\n",
    "    confidence: float = Field(..., description=\"Confidence of the transformation.\")\n",
    "    reason: str = Field(..., description=\"Reason for confidence score of the transformation.\")\n",
    "\n",
    "class TransformedStatements(BaseModel):\n",
    "    TransformedStatements: List[TransformedStatement] = Field(..., description=\"List of transformed statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_statement(element_name, user_prompts, system_prompts, manager):\n",
    "    # Initialize an empty list to accumulate all responses\n",
    "    all_responses = []\n",
    "    elapse_times = []\n",
    "    completions = []\n",
    "\n",
    "    # Loop through each pair of user and system prompts with a counter\n",
    "    for index, (user_prompt, system_prompt) in enumerate(\n",
    "        zip(user_prompts, system_prompts), start=1\n",
    "    ):\n",
    "        logger.info(f\"Processing transformation prompt {index} for {element_name}.\")\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "        # Query the language model\n",
    "        response, completion, elapse_time = query_instruct_llm(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            document_model=TransformedStatements,\n",
    "            llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "            temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "            max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    "        )\n",
    "\n",
    "        logger.debug(response)\n",
    "\n",
    "        # Accumulate the responses in the list\n",
    "        all_responses.extend(response.TransformedStatements)\n",
    "        elapse_times.append(elapse_time)\n",
    "        completions.append(completion.dict())\n",
    "\n",
    "        logger.info(f\"Finished processing classification and templates prompt {index}.\")\n",
    "\n",
    "    # After the loop, create a single Document with all the accumulated responses\n",
    "    doc = Document(\n",
    "        id=f\"transform_{element_name.replace(' ', '_')}s\",\n",
    "        type=\"llm_response_transform\",\n",
    "        content=all_responses,\n",
    "        elapsed_times=elapse_times,\n",
    "        completions=completions,\n",
    "    )\n",
    "    manager.add_document(doc)\n",
    "\n",
    "    logger.info(f\"{element_name}s: {len(all_responses)}\")\n",
    "\n",
    "    return all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prompts_for_rule(rules, rule_template_formulation, data_dir):\n",
    "    rule_template_provider = RulesTemplateProvider(data_dir)\n",
    "\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for rule in rules:\n",
    "        element_name = rule.get(\"element_name\")\n",
    "\n",
    "        if element_name == [\"Term\", \"Name\"]:\n",
    "            statement_key = \"definition\"\n",
    "            statement_id_key = \"signifier\"\n",
    "        else:\n",
    "            statement_key = \"statement\"\n",
    "            statement_id_key = \"statement_id\"\n",
    "\n",
    "        # # Return templates and examples for fact types or all\n",
    "        # if element_name == \"Fact Type\":\n",
    "        #     return_forms = \"fact_type\"\n",
    "        # else:\n",
    "        #     return_forms = \"rule\"\n",
    "        # logger.info(f\"Processing {element_name} with return forms {return_forms}.\")\n",
    "\n",
    "        input_rule = {\n",
    "            \"doc_id\": rule[\"doc_id\"],\n",
    "            f\"{statement_id_key}\": rule[\"statement_id\"],\n",
    "            \"sources\": rule[\"sources\"],\n",
    "            f\"{statement_key}\": rule.get(\"statement\", rule.get(\"definition\")),\n",
    "            \"templates_ids\": rule[\"templates_ids\"],\n",
    "        }\n",
    "        user_prompt = get_user_prompt_transform(element_name, input_rule)\n",
    "        user_prompts.append(user_prompt)\n",
    "        rule_templates_subtemplates = rule_template_provider.get_rules_template(rule[\"templates_ids\"])\n",
    "        system_prompt = get_system_prompt_transform(element_name,rule_template_formulation, rule_templates_subtemplates)\n",
    "        system_prompts.append(system_prompt)\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "    logger.info(f\"System prompts for {element_name}s: {len(system_prompts)}\")\n",
    "    logger.info(f\"User prompts for {element_name}s: {len(user_prompts)}\")\n",
    "\n",
    "    return system_prompts, user_prompts, element_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Datasets used in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True tables\n",
    "\n",
    "There are no true tables to evaluate the transformation, the evaluation depends on the algorithms SEMSCORE and \"LLM as a Judge\", see `chap_7_validation_rules_transformation.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elements to transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get expressions to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:50 - WARNING - Document 'transform_Fact_Types' of type 'llm_response_transform' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Document 'transform_Terms' of type 'llm_response_transform' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Document 'transform_Names' of type 'llm_response_transform' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Document 'transform_Operative_Rules' of type 'llm_response_transform' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Validation document 'validation_judge_Operative_Rules' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Validation document 'validation_judge_Fact_Types' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Validation document 'validation_judge_Terms' not found or empty.\n",
      "2024-12-08 23:02:50 - WARNING - Validation document 'validation_judge_Names' not found or empty.\n",
      "2024-12-08 23:02:50 - INFO - Rules to evaluate: 6\n",
      "2024-12-08 23:02:50 - INFO - Facts to evaluate: 16\n",
      "2024-12-08 23:02:50 - INFO - Terms to evaluate: 28\n",
      "2024-12-08 23:02:50 - INFO - Names to evaluate: 5\n"
     ]
    }
   ],
   "source": [
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "pred_operative_rules = processor.get_rules()\n",
    "pred_facts = processor.get_facts()\n",
    "pred_terms = processor.get_terms(definition_filter=\"non_null\")\n",
    "pred_names = processor.get_names(definition_filter=\"non_null\")\n",
    "\n",
    "logger.debug(f\"Rules: {pred_operative_rules}\")\n",
    "logger.debug(f\"Facts: {pred_facts}\")\n",
    "logger.debug(f\"Terms: {pred_terms}\")\n",
    "logger.debug(f\"Names: {pred_names}\")\n",
    "logger.info(f\"Rules to evaluate: {len(pred_operative_rules)}\")\n",
    "logger.info(f\"Facts to evaluate: {len(pred_facts)}\")\n",
    "logger.info(f\"Terms to evaluate: {len(pred_terms)}\")\n",
    "logger.info(f\"Names to evaluate: {len(pred_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System prompt\n",
    "\n",
    "Formulation is expressed using a template (WITT, 2012, p. 162)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_template_formulation = \"\"\"\n",
    "# How to interpret the templates and subtemplates\n",
    "\n",
    "Each formulation is expressed using a template, in which the various symbols have the following meanings:\n",
    "\n",
    "1. Each item enclosed in \"angle brackets\" (\"<\" and \">\") is a placeholder, in place of which any suitable text may be substituted. For example, any of the following may be substituted in place of <operative rule statement subject> (subtemplate):\n",
    "    a. a term: for example, \"flight booking request\",\n",
    "    b. a term followed by a qualifying clause: for example, \"flight booking request for a one-way journey\",\n",
    "    c. a reference to a combination of items: for example, \"combination of enrollment date and graduation date\", with or without a qualifying clause,\n",
    "    d. a reference to a set of items: for example, \"set of passengers\", with or without a qualifying clause.\n",
    "2. Each pair of braces (\"{\" and \"}\") encloses a set of options (separated from each other by the bar symbol: \"|\"), one of which is included in the rule statement. For example,\n",
    "3. If a pair of braces includes a bar symbol immediately before the closing brace, the null option is allowed: that is, you can, if necessary, include none of the options at that point in the rule statement.\n",
    "4. Sets of options may be nested. For example, in each of the templates above\n",
    "    a. a conditional clause may be included or omitted,\n",
    "    b. if included, the conditional clause should be preceded by either \"if\" or \"unless\".\n",
    "5. A further notation, introduced later in this section, uses square brackets to indicate that a syntactic element may be repeated indefinitely.\n",
    "6. Any text not enclosed in either \"angle brackets\" or braces (i.e., \"must\", \"not\", \"may\", and \"only\") is included in every rule statement conforming to the relevant template.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_transform(element_name, rule_template_formulation, rule_templates_subtemplates):\n",
    "    statement_name = \"definition\" if element_name in [\"Term\", \"Name\"] else \"statement\"\n",
    "    return f\"\"\"\n",
    "Transform each given {element_name} {statement_name} into a structured format by matching it to the specified templates and subtemplates.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Summarize {statement_name}**: Summarize the given {element_name} {statement_name} to understand its structure and content.\n",
    "\n",
    "2. **Use Template**:\n",
    "   - For given expression, use the templates and subtemplates ({\"Fact Type Form\" if element_name in [\"Fact Type\", \"Fact\"] else \"Rule Form\"}) provided for transformation.\n",
    "   - Determine the appropriate template or subtemplate based on the structure of the expression.\n",
    "   \n",
    "3. **Replace Placeholders**:\n",
    "   - Substitute placeholders, such as `<term>`, `<verb phrase>`, `<conditional clause>`, etc., with suitable values as per the expression.\n",
    "   - For terms and names, the statement_id is the term defined by the statement.\n",
    "   \n",
    "4. **Include Qualifying Details**:\n",
    "   - Where placeholders, such as `<qualifying clause>`, require additional details (e.g., attributes or qualifiers to distinguish meaning), ensure that these are included appropriately as per the respective subtemplate.\n",
    "\n",
    "5. **Transform into Structured Format**:\n",
    "   - Once the transformation is complete, ensure it's in the correct template format.\n",
    "\n",
    "6. **Output as Structured JSON**:\n",
    "   - For every transformed expression generate a JSON object as per the specified output format.\n",
    "\n",
    "7. **Review and Validate**:\n",
    "   - Ensure accuracy in grammar and compliance with logical constructs when performing substitutions.\n",
    "   - Ensure the generated JSON is in the correct template format.\n",
    "\n",
    "8. **Assess the Transformation**:\n",
    "   - Record the confidence level and reason for the confidence score in the JSON object.\n",
    "\n",
    "{rule_template_formulation}\n",
    "\n",
    "# Provided templates and subtemplates for transformation\n",
    "\n",
    "{rule_templates_subtemplates}\n",
    "\n",
    "# Output Format\n",
    "\n",
    "[\n",
    "    {{\n",
    "      \"doc_id\": <doc_id>,\n",
    "      \"statement_id\": <statement_id or signifier>,\n",
    "      \"statement_title\": <statement_title>,\n",
    "      \"sources\": [<source>],\n",
    "      \"statement\": <statement or definition>,\n",
    "      \"templates_ids\": [<templates_id>],\n",
    "      \"transformed\": <transformed_statement>,\n",
    "      \"confidence\": <confidence_level>,\n",
    "      \"reason\": <reason_for_confidence>\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\n",
    "- **`doc_id`**: A original identifier of the given document.\n",
    "- **`statement_id or signifier`**: The original identifier of the given {statement_name}. e.g., '1', 'Person'\".\n",
    "- **`statement_title`**: The title of the given {statement_name}.\n",
    "- **`sources`**: The original sources of the given {statement_name}.\n",
    "- **`statement or definition`**: The original text of the given {statement_name}.\n",
    "- **`templates_ids`**: The template(s) used for the transformation (e.g., T1, T2, etc.)\n",
    "- **`transformed`**: The transformed statement according to template.\n",
    "- **`confidence`**: The confidence level of the transformation range from 0 to 1.\n",
    "- **`reason`**: The reason for the confidence score.\n",
    "\n",
    "# Notes\n",
    "- Use only the provided templates and subtemplates for transformation.\n",
    "- If a placeholder within an expression is not applicable or optional, consider whether it should be omitted or replaced by a suitable value.\n",
    "- Each expression may involve nested levels of substitution as indicated by the subtemplate hierarchy (e.g., a qualifying clause that contains sub-elements).\n",
    "- Ensure accuracy in grammar and compliance with logical constructs when performing substitutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_transform(element_name, rule):\n",
    "\n",
    "    return f\"\"\"\n",
    "# Here's the {element_name} {\"definition\" if element_name in [\"Term\", \"Name\"] else \"statement\"} you need to transform using template {rule.get(\"templates_ids\")}.\n",
    "\n",
    "{json.dumps(rule, indent=2)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:50 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:02:50 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:51 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:02:51 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-08-10.json.\n"
     ]
    }
   ],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operative rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for operative rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:51 - INFO - System prompts for Operative Rules: 6\n",
      "2024-12-08 23:02:51 - INFO - User prompts for Operative Rules: 6\n"
     ]
    }
   ],
   "source": [
    "system_prompts_operative_rules, user_prompts_operative_rules, element_name = (\n",
    "    get_prompts_for_rule(\n",
    "        rules=pred_operative_rules,\n",
    "        rule_template_formulation=rule_template_formulation,\n",
    "        data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:51 - INFO - System prompts for Operative Rules: 6\n",
      "2024-12-08 23:02:51 - INFO - User prompts for Operative Rules: 6\n",
      "2024-12-08 23:02:51 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:02:51 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_operative_rules, user_prompts_operative_rules, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform operative rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:02:51 - INFO - Processing transformation prompt 1 for Operative Rule.\n",
      "2024-12-08 23:02:53 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:02:53 - INFO - Tokes used: CompletionUsage(completion_tokens=189, prompt_tokens=5022, total_tokens=5211, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:02:53 - INFO - Execution time for query_instruct_llm: 2.00 seconds\n",
      "2024-12-08 23:02:53 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-08 23:02:53 - INFO - Processing transformation prompt 2 for Operative Rule.\n",
      "2024-12-08 23:02:56 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:02:56 - INFO - Tokes used: CompletionUsage(completion_tokens=222, prompt_tokens=5049, total_tokens=5271, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:02:56 - INFO - Execution time for query_instruct_llm: 3.10 seconds\n",
      "2024-12-08 23:02:56 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-08 23:02:56 - INFO - Processing transformation prompt 3 for Operative Rule.\n",
      "2024-12-08 23:03:03 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:03 - INFO - Tokes used: CompletionUsage(completion_tokens=192, prompt_tokens=5400, total_tokens=5592, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:03 - INFO - Execution time for query_instruct_llm: 3.08 seconds\n",
      "2024-12-08 23:03:03 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-08 23:03:03 - INFO - Processing transformation prompt 4 for Operative Rule.\n",
      "2024-12-08 23:03:05 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:05 - INFO - Tokes used: CompletionUsage(completion_tokens=201, prompt_tokens=5162, total_tokens=5363, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:05 - INFO - Execution time for query_instruct_llm: 2.22 seconds\n",
      "2024-12-08 23:03:05 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-08 23:03:05 - INFO - Processing transformation prompt 5 for Operative Rule.\n",
      "2024-12-08 23:03:07 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:07 - INFO - Tokes used: CompletionUsage(completion_tokens=197, prompt_tokens=5456, total_tokens=5653, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:07 - INFO - Execution time for query_instruct_llm: 2.05 seconds\n",
      "2024-12-08 23:03:07 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-08 23:03:07 - INFO - Processing transformation prompt 6 for Operative Rule.\n",
      "2024-12-08 23:03:10 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:10 - INFO - Tokes used: CompletionUsage(completion_tokens=235, prompt_tokens=5335, total_tokens=5570, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:10 - INFO - Execution time for query_instruct_llm: 3.01 seconds\n",
      "2024-12-08 23:03:10 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-08 23:03:10 - INFO - Operative Rules: 6\n",
      "2024-12-08 23:03:10 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:03:10 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_operative_rules = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_operative_rules,\n",
    "    system_prompts=system_prompts_operative_rules,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_operative_rules=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:10 - INFO - System prompts for Fact Types: 16\n",
      "2024-12-08 23:03:10 - INFO - User prompts for Fact Types: 16\n"
     ]
    }
   ],
   "source": [
    "system_prompts_facts, user_prompts_facts, element_name = get_prompts_for_rule(\n",
    "    rules=pred_facts,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:10 - INFO - System prompts for Fact Types: 16\n",
      "2024-12-08 23:03:10 - INFO - User prompts for Fact Types: 16\n",
      "2024-12-08 23:03:10 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:03:10 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_facts, user_prompts_facts, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:10 - INFO - Processing transformation prompt 1 for Fact Type.\n",
      "2024-12-08 23:03:14 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:14 - INFO - Tokes used: CompletionUsage(completion_tokens=206, prompt_tokens=1940, total_tokens=2146, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:14 - INFO - Execution time for query_instruct_llm: 3.23 seconds\n",
      "2024-12-08 23:03:14 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-08 23:03:14 - INFO - Processing transformation prompt 2 for Fact Type.\n",
      "2024-12-08 23:03:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:16 - INFO - Tokes used: CompletionUsage(completion_tokens=235, prompt_tokens=1949, total_tokens=2184, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:16 - INFO - Execution time for query_instruct_llm: 2.89 seconds\n",
      "2024-12-08 23:03:16 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-08 23:03:16 - INFO - Processing transformation prompt 3 for Fact Type.\n",
      "2024-12-08 23:03:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:19 - INFO - Tokes used: CompletionUsage(completion_tokens=179, prompt_tokens=5085, total_tokens=5264, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:19 - INFO - Execution time for query_instruct_llm: 2.16 seconds\n",
      "2024-12-08 23:03:19 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-08 23:03:19 - INFO - Processing transformation prompt 4 for Fact Type.\n",
      "2024-12-08 23:03:22 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:22 - INFO - Tokes used: CompletionUsage(completion_tokens=280, prompt_tokens=1875, total_tokens=2155, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:22 - INFO - Execution time for query_instruct_llm: 3.66 seconds\n",
      "2024-12-08 23:03:22 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-08 23:03:22 - INFO - Processing transformation prompt 5 for Fact Type.\n",
      "2024-12-08 23:03:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:24 - INFO - Tokes used: CompletionUsage(completion_tokens=176, prompt_tokens=5076, total_tokens=5252, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:24 - INFO - Execution time for query_instruct_llm: 2.04 seconds\n",
      "2024-12-08 23:03:24 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-08 23:03:24 - INFO - Processing transformation prompt 6 for Fact Type.\n",
      "2024-12-08 23:03:27 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:27 - INFO - Tokes used: CompletionUsage(completion_tokens=147, prompt_tokens=1820, total_tokens=1967, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:27 - INFO - Execution time for query_instruct_llm: 2.36 seconds\n",
      "2024-12-08 23:03:27 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-08 23:03:27 - INFO - Processing transformation prompt 7 for Fact Type.\n",
      "2024-12-08 23:03:29 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:29 - INFO - Tokes used: CompletionUsage(completion_tokens=177, prompt_tokens=5093, total_tokens=5270, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:29 - INFO - Execution time for query_instruct_llm: 2.00 seconds\n",
      "2024-12-08 23:03:29 - INFO - Finished processing classification and templates prompt 7.\n",
      "2024-12-08 23:03:29 - INFO - Processing transformation prompt 8 for Fact Type.\n",
      "2024-12-08 23:03:31 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:31 - INFO - Tokes used: CompletionUsage(completion_tokens=184, prompt_tokens=1907, total_tokens=2091, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:31 - INFO - Execution time for query_instruct_llm: 1.95 seconds\n",
      "2024-12-08 23:03:31 - INFO - Finished processing classification and templates prompt 8.\n",
      "2024-12-08 23:03:31 - INFO - Processing transformation prompt 9 for Fact Type.\n",
      "2024-12-08 23:03:32 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:32 - INFO - Tokes used: CompletionUsage(completion_tokens=164, prompt_tokens=1879, total_tokens=2043, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:32 - INFO - Execution time for query_instruct_llm: 1.87 seconds\n",
      "2024-12-08 23:03:32 - INFO - Finished processing classification and templates prompt 9.\n",
      "2024-12-08 23:03:32 - INFO - Processing transformation prompt 10 for Fact Type.\n",
      "2024-12-08 23:03:39 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:39 - INFO - Tokes used: CompletionUsage(completion_tokens=229, prompt_tokens=1959, total_tokens=2188, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:39 - INFO - Execution time for query_instruct_llm: 2.98 seconds\n",
      "2024-12-08 23:03:39 - INFO - Finished processing classification and templates prompt 10.\n",
      "2024-12-08 23:03:39 - INFO - Processing transformation prompt 11 for Fact Type.\n",
      "2024-12-08 23:03:42 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:42 - INFO - Tokes used: CompletionUsage(completion_tokens=194, prompt_tokens=5077, total_tokens=5271, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:42 - INFO - Execution time for query_instruct_llm: 2.60 seconds\n",
      "2024-12-08 23:03:42 - INFO - Finished processing classification and templates prompt 11.\n",
      "2024-12-08 23:03:42 - INFO - Processing transformation prompt 12 for Fact Type.\n",
      "2024-12-08 23:03:44 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:44 - INFO - Tokes used: CompletionUsage(completion_tokens=201, prompt_tokens=5084, total_tokens=5285, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:44 - INFO - Execution time for query_instruct_llm: 2.07 seconds\n",
      "2024-12-08 23:03:44 - INFO - Finished processing classification and templates prompt 12.\n",
      "2024-12-08 23:03:44 - INFO - Processing transformation prompt 13 for Fact Type.\n",
      "2024-12-08 23:03:46 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:46 - INFO - Tokes used: CompletionUsage(completion_tokens=182, prompt_tokens=5083, total_tokens=5265, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:46 - INFO - Execution time for query_instruct_llm: 2.07 seconds\n",
      "2024-12-08 23:03:46 - INFO - Finished processing classification and templates prompt 13.\n",
      "2024-12-08 23:03:46 - INFO - Processing transformation prompt 14 for Fact Type.\n",
      "2024-12-08 23:03:48 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:48 - INFO - Tokes used: CompletionUsage(completion_tokens=248, prompt_tokens=5121, total_tokens=5369, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:48 - INFO - Execution time for query_instruct_llm: 2.54 seconds\n",
      "2024-12-08 23:03:48 - INFO - Finished processing classification and templates prompt 14.\n",
      "2024-12-08 23:03:48 - INFO - Processing transformation prompt 15 for Fact Type.\n",
      "2024-12-08 23:03:51 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:51 - INFO - Tokes used: CompletionUsage(completion_tokens=192, prompt_tokens=5069, total_tokens=5261, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:51 - INFO - Execution time for query_instruct_llm: 2.28 seconds\n",
      "2024-12-08 23:03:51 - INFO - Finished processing classification and templates prompt 15.\n",
      "2024-12-08 23:03:51 - INFO - Processing transformation prompt 16 for Fact Type.\n",
      "2024-12-08 23:03:53 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:53 - INFO - Tokes used: CompletionUsage(completion_tokens=202, prompt_tokens=1844, total_tokens=2046, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:53 - INFO - Execution time for query_instruct_llm: 2.59 seconds\n",
      "2024-12-08 23:03:53 - INFO - Finished processing classification and templates prompt 16.\n",
      "2024-12-08 23:03:53 - INFO - Fact Types: 16\n",
      "2024-12-08 23:03:53 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:03:53 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_facts = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_facts,\n",
    "    system_prompts=system_prompts_facts,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_facts=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:53 - INFO - System prompts for Terms: 28\n",
      "2024-12-08 23:03:53 - INFO - User prompts for Terms: 28\n"
     ]
    }
   ],
   "source": [
    "system_prompts_terms, user_prompts_terms, element_name = get_prompts_for_rule(\n",
    "    rules=pred_terms,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:53 - INFO - System prompts for Terms: 28\n",
      "2024-12-08 23:03:53 - INFO - User prompts for Terms: 28\n",
      "2024-12-08 23:03:53 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:03:53 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_terms, user_prompts_terms, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:03:54 - INFO - Processing transformation prompt 1 for Term.\n",
      "2024-12-08 23:03:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:55 - INFO - Tokes used: CompletionUsage(completion_tokens=141, prompt_tokens=1809, total_tokens=1950, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:55 - INFO - Execution time for query_instruct_llm: 1.57 seconds\n",
      "2024-12-08 23:03:55 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-08 23:03:55 - INFO - Processing transformation prompt 2 for Term.\n",
      "2024-12-08 23:03:57 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:57 - INFO - Tokes used: CompletionUsage(completion_tokens=178, prompt_tokens=1817, total_tokens=1995, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:57 - INFO - Execution time for query_instruct_llm: 2.23 seconds\n",
      "2024-12-08 23:03:57 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-08 23:03:57 - INFO - Processing transformation prompt 3 for Term.\n",
      "2024-12-08 23:03:59 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:03:59 - INFO - Tokes used: CompletionUsage(completion_tokens=171, prompt_tokens=5079, total_tokens=5250, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:03:59 - INFO - Execution time for query_instruct_llm: 2.05 seconds\n",
      "2024-12-08 23:03:59 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-08 23:03:59 - INFO - Processing transformation prompt 4 for Term.\n",
      "2024-12-08 23:04:02 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:02 - INFO - Tokes used: CompletionUsage(completion_tokens=186, prompt_tokens=5084, total_tokens=5270, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:02 - INFO - Execution time for query_instruct_llm: 2.69 seconds\n",
      "2024-12-08 23:04:02 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-08 23:04:02 - INFO - Processing transformation prompt 5 for Term.\n",
      "2024-12-08 23:04:04 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:04 - INFO - Tokes used: CompletionUsage(completion_tokens=170, prompt_tokens=5066, total_tokens=5236, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:04 - INFO - Execution time for query_instruct_llm: 2.31 seconds\n",
      "2024-12-08 23:04:04 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-08 23:04:04 - INFO - Processing transformation prompt 6 for Term.\n",
      "2024-12-08 23:04:06 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:06 - INFO - Tokes used: CompletionUsage(completion_tokens=163, prompt_tokens=5060, total_tokens=5223, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:06 - INFO - Execution time for query_instruct_llm: 1.66 seconds\n",
      "2024-12-08 23:04:06 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-08 23:04:06 - INFO - Processing transformation prompt 7 for Term.\n",
      "2024-12-08 23:04:08 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:08 - INFO - Tokes used: CompletionUsage(completion_tokens=173, prompt_tokens=5073, total_tokens=5246, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:08 - INFO - Execution time for query_instruct_llm: 1.94 seconds\n",
      "2024-12-08 23:04:08 - INFO - Finished processing classification and templates prompt 7.\n",
      "2024-12-08 23:04:08 - INFO - Processing transformation prompt 8 for Term.\n",
      "2024-12-08 23:04:10 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:10 - INFO - Tokes used: CompletionUsage(completion_tokens=141, prompt_tokens=5059, total_tokens=5200, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:10 - INFO - Execution time for query_instruct_llm: 1.88 seconds\n",
      "2024-12-08 23:04:10 - INFO - Finished processing classification and templates prompt 8.\n",
      "2024-12-08 23:04:10 - INFO - Processing transformation prompt 9 for Term.\n",
      "2024-12-08 23:04:15 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:15 - INFO - Tokes used: CompletionUsage(completion_tokens=161, prompt_tokens=5066, total_tokens=5227, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:15 - INFO - Execution time for query_instruct_llm: 1.80 seconds\n",
      "2024-12-08 23:04:15 - INFO - Finished processing classification and templates prompt 9.\n",
      "2024-12-08 23:04:15 - INFO - Processing transformation prompt 10 for Term.\n",
      "2024-12-08 23:04:18 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:18 - INFO - Tokes used: CompletionUsage(completion_tokens=138, prompt_tokens=5059, total_tokens=5197, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:18 - INFO - Execution time for query_instruct_llm: 2.23 seconds\n",
      "2024-12-08 23:04:18 - INFO - Finished processing classification and templates prompt 10.\n",
      "2024-12-08 23:04:18 - INFO - Processing transformation prompt 11 for Term.\n",
      "2024-12-08 23:04:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:19 - INFO - Tokes used: CompletionUsage(completion_tokens=150, prompt_tokens=1872, total_tokens=2022, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:19 - INFO - Execution time for query_instruct_llm: 1.63 seconds\n",
      "2024-12-08 23:04:19 - INFO - Finished processing classification and templates prompt 11.\n",
      "2024-12-08 23:04:19 - INFO - Processing transformation prompt 12 for Term.\n",
      "2024-12-08 23:04:21 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:21 - INFO - Tokes used: CompletionUsage(completion_tokens=151, prompt_tokens=5057, total_tokens=5208, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:21 - INFO - Execution time for query_instruct_llm: 1.99 seconds\n",
      "2024-12-08 23:04:21 - INFO - Finished processing classification and templates prompt 12.\n",
      "2024-12-08 23:04:21 - INFO - Processing transformation prompt 13 for Term.\n",
      "2024-12-08 23:04:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:24 - INFO - Tokes used: CompletionUsage(completion_tokens=185, prompt_tokens=5070, total_tokens=5255, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:24 - INFO - Execution time for query_instruct_llm: 2.90 seconds\n",
      "2024-12-08 23:04:24 - INFO - Finished processing classification and templates prompt 13.\n",
      "2024-12-08 23:04:24 - INFO - Processing transformation prompt 14 for Term.\n",
      "2024-12-08 23:04:26 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:26 - INFO - Tokes used: CompletionUsage(completion_tokens=135, prompt_tokens=5052, total_tokens=5187, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:26 - INFO - Execution time for query_instruct_llm: 2.11 seconds\n",
      "2024-12-08 23:04:26 - INFO - Finished processing classification and templates prompt 14.\n",
      "2024-12-08 23:04:26 - INFO - Processing transformation prompt 15 for Term.\n",
      "2024-12-08 23:04:28 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:28 - INFO - Tokes used: CompletionUsage(completion_tokens=160, prompt_tokens=5062, total_tokens=5222, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:28 - INFO - Execution time for query_instruct_llm: 1.81 seconds\n",
      "2024-12-08 23:04:28 - INFO - Finished processing classification and templates prompt 15.\n",
      "2024-12-08 23:04:28 - INFO - Processing transformation prompt 16 for Term.\n",
      "2024-12-08 23:04:30 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:30 - INFO - Tokes used: CompletionUsage(completion_tokens=138, prompt_tokens=5051, total_tokens=5189, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:30 - INFO - Execution time for query_instruct_llm: 1.70 seconds\n",
      "2024-12-08 23:04:30 - INFO - Finished processing classification and templates prompt 16.\n",
      "2024-12-08 23:04:30 - INFO - Processing transformation prompt 17 for Term.\n",
      "2024-12-08 23:04:31 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:31 - INFO - Tokes used: CompletionUsage(completion_tokens=146, prompt_tokens=5054, total_tokens=5200, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:31 - INFO - Execution time for query_instruct_llm: 1.70 seconds\n",
      "2024-12-08 23:04:31 - INFO - Finished processing classification and templates prompt 17.\n",
      "2024-12-08 23:04:31 - INFO - Processing transformation prompt 18 for Term.\n",
      "2024-12-08 23:04:33 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:33 - INFO - Tokes used: CompletionUsage(completion_tokens=140, prompt_tokens=5055, total_tokens=5195, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:33 - INFO - Execution time for query_instruct_llm: 1.66 seconds\n",
      "2024-12-08 23:04:33 - INFO - Finished processing classification and templates prompt 18.\n",
      "2024-12-08 23:04:33 - INFO - Processing transformation prompt 19 for Term.\n",
      "2024-12-08 23:04:35 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:35 - INFO - Tokes used: CompletionUsage(completion_tokens=135, prompt_tokens=5053, total_tokens=5188, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:35 - INFO - Execution time for query_instruct_llm: 1.59 seconds\n",
      "2024-12-08 23:04:35 - INFO - Finished processing classification and templates prompt 19.\n",
      "2024-12-08 23:04:35 - INFO - Processing transformation prompt 20 for Term.\n",
      "2024-12-08 23:04:37 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:37 - INFO - Tokes used: CompletionUsage(completion_tokens=161, prompt_tokens=5061, total_tokens=5222, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:37 - INFO - Execution time for query_instruct_llm: 2.10 seconds\n",
      "2024-12-08 23:04:37 - INFO - Finished processing classification and templates prompt 20.\n",
      "2024-12-08 23:04:37 - INFO - Processing transformation prompt 21 for Term.\n",
      "2024-12-08 23:04:38 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:38 - INFO - Tokes used: CompletionUsage(completion_tokens=160, prompt_tokens=1879, total_tokens=2039, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:38 - INFO - Execution time for query_instruct_llm: 1.77 seconds\n",
      "2024-12-08 23:04:38 - INFO - Finished processing classification and templates prompt 21.\n",
      "2024-12-08 23:04:38 - INFO - Processing transformation prompt 22 for Term.\n",
      "2024-12-08 23:04:42 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:42 - INFO - Tokes used: CompletionUsage(completion_tokens=159, prompt_tokens=1879, total_tokens=2038, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:42 - INFO - Execution time for query_instruct_llm: 3.08 seconds\n",
      "2024-12-08 23:04:42 - INFO - Finished processing classification and templates prompt 22.\n",
      "2024-12-08 23:04:42 - INFO - Processing transformation prompt 23 for Term.\n",
      "2024-12-08 23:04:44 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:44 - INFO - Tokes used: CompletionUsage(completion_tokens=199, prompt_tokens=4933, total_tokens=5132, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:44 - INFO - Execution time for query_instruct_llm: 2.28 seconds\n",
      "2024-12-08 23:04:44 - INFO - Finished processing classification and templates prompt 23.\n",
      "2024-12-08 23:04:44 - INFO - Processing transformation prompt 24 for Term.\n",
      "2024-12-08 23:04:50 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:50 - INFO - Tokes used: CompletionUsage(completion_tokens=162, prompt_tokens=5077, total_tokens=5239, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:50 - INFO - Execution time for query_instruct_llm: 2.24 seconds\n",
      "2024-12-08 23:04:50 - INFO - Finished processing classification and templates prompt 24.\n",
      "2024-12-08 23:04:50 - INFO - Processing transformation prompt 25 for Term.\n",
      "2024-12-08 23:04:59 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:04:59 - INFO - Tokes used: CompletionUsage(completion_tokens=197, prompt_tokens=5090, total_tokens=5287, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:04:59 - INFO - Execution time for query_instruct_llm: 8.83 seconds\n",
      "2024-12-08 23:04:59 - INFO - Finished processing classification and templates prompt 25.\n",
      "2024-12-08 23:04:59 - INFO - Processing transformation prompt 26 for Term.\n",
      "2024-12-08 23:05:02 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:02 - INFO - Tokes used: CompletionUsage(completion_tokens=170, prompt_tokens=5080, total_tokens=5250, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:02 - INFO - Execution time for query_instruct_llm: 3.23 seconds\n",
      "2024-12-08 23:05:02 - INFO - Finished processing classification and templates prompt 26.\n",
      "2024-12-08 23:05:02 - INFO - Processing transformation prompt 27 for Term.\n",
      "2024-12-08 23:05:05 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:05 - INFO - Tokes used: CompletionUsage(completion_tokens=274, prompt_tokens=5122, total_tokens=5396, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:05 - INFO - Execution time for query_instruct_llm: 2.91 seconds\n",
      "2024-12-08 23:05:05 - INFO - Finished processing classification and templates prompt 27.\n",
      "2024-12-08 23:05:05 - INFO - Processing transformation prompt 28 for Term.\n",
      "2024-12-08 23:05:08 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:08 - INFO - Tokes used: CompletionUsage(completion_tokens=164, prompt_tokens=5065, total_tokens=5229, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:08 - INFO - Execution time for query_instruct_llm: 3.14 seconds\n",
      "2024-12-08 23:05:08 - INFO - Finished processing classification and templates prompt 28.\n",
      "2024-12-08 23:05:08 - INFO - Terms: 28\n",
      "2024-12-08 23:05:08 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:05:08 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_terms = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_terms,\n",
    "    system_prompts=system_prompts_terms,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_terms=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 4s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:05:08 - INFO - System prompts for Names: 5\n",
      "2024-12-08 23:05:08 - INFO - User prompts for Names: 5\n"
     ]
    }
   ],
   "source": [
    "system_prompts_names, user_prompts_names, element_name = get_prompts_for_rule(\n",
    "    rules=pred_names,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:05:08 - INFO - System prompts for Names: 5\n",
      "2024-12-08 23:05:08 - INFO - User prompts for Names: 5\n",
      "2024-12-08 23:05:08 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:05:08 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_names, user_prompts_names, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:05:08 - INFO - Processing transformation prompt 1 for Name.\n",
      "2024-12-08 23:05:10 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:10 - INFO - Tokes used: CompletionUsage(completion_tokens=170, prompt_tokens=5074, total_tokens=5244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:10 - INFO - Execution time for query_instruct_llm: 1.89 seconds\n",
      "2024-12-08 23:05:10 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-08 23:05:10 - INFO - Processing transformation prompt 2 for Name.\n",
      "2024-12-08 23:05:12 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:12 - INFO - Tokes used: CompletionUsage(completion_tokens=161, prompt_tokens=5071, total_tokens=5232, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:12 - INFO - Execution time for query_instruct_llm: 2.00 seconds\n",
      "2024-12-08 23:05:12 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-08 23:05:12 - INFO - Processing transformation prompt 3 for Name.\n",
      "2024-12-08 23:05:14 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:14 - INFO - Tokes used: CompletionUsage(completion_tokens=139, prompt_tokens=5055, total_tokens=5194, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:14 - INFO - Execution time for query_instruct_llm: 1.77 seconds\n",
      "2024-12-08 23:05:14 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-08 23:05:14 - INFO - Processing transformation prompt 4 for Name.\n",
      "2024-12-08 23:05:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:16 - INFO - Tokes used: CompletionUsage(completion_tokens=159, prompt_tokens=5063, total_tokens=5222, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:16 - INFO - Execution time for query_instruct_llm: 1.95 seconds\n",
      "2024-12-08 23:05:16 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-08 23:05:16 - INFO - Processing transformation prompt 5 for Name.\n",
      "2024-12-08 23:05:17 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-08 23:05:17 - INFO - Tokes used: CompletionUsage(completion_tokens=146, prompt_tokens=5052, total_tokens=5198, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-08 23:05:17 - INFO - Execution time for query_instruct_llm: 1.62 seconds\n",
      "2024-12-08 23:05:17 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-08 23:05:17 - INFO - Names: 5\n",
      "2024-12-08 23:05:17 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:05:17 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_names = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_names,\n",
    "    system_prompts=system_prompts_names,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_names=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:05:18 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-08-10.json\n",
      "2024-12-08 23:05:18 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-08-10.json.\n"
     ]
    }
   ],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate elements for missing transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 23:05:18 - WARNING - Validation document 'validation_judge_Operative_Rules' not found or empty.\n",
      "2024-12-08 23:05:18 - WARNING - Validation document 'validation_judge_Fact_Types' not found or empty.\n",
      "2024-12-08 23:05:18 - WARNING - Validation document 'validation_judge_Terms' not found or empty.\n",
      "2024-12-08 23:05:18 - WARNING - Validation document 'validation_judge_Names' not found or empty.\n",
      "2024-12-08 23:05:18 - INFO - Empty transformed pred_facts: 0/16\n",
      "2024-12-08 23:05:18 - INFO - Empty transformed pred_terms: 0/28\n",
      "2024-12-08 23:05:18 - INFO - Empty transformed pred_names: 0/5\n",
      "2024-12-08 23:05:18 - INFO - Empty transformed pred_operative_rules: 0/6\n"
     ]
    }
   ],
   "source": [
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "pred_operative_rules = processor.get_rules()\n",
    "pred_facts = processor.get_facts()\n",
    "pred_terms = processor.get_terms(definition_filter=\"non_null\")\n",
    "pred_names = processor.get_names(definition_filter=\"non_null\")\n",
    "\n",
    "logger.debug(f\"Rules: {pred_operative_rules}\")\n",
    "logger.debug(f\"Facts: {pred_facts}\")\n",
    "logger.debug(f\"Terms: {pred_terms}\")\n",
    "logger.debug(f\"Names: {pred_names}\")\n",
    "\n",
    "data = [pred_facts, pred_terms, pred_names, pred_operative_rules]\n",
    "data_names = [\"pred_facts\", \"pred_terms\", \"pred_names\", \"pred_operative_rules\"]\n",
    "\n",
    "for element_list, element_name in zip(data, data_names):\n",
    "    empty_transformed_elements = []\n",
    "    for element in element_list:\n",
    "        if not element.get(\"transformed\"):\n",
    "            logger.debug(f\"{element_name} - {element.get('statement_id')}: {element.get('transformed')}\")\n",
    "            empty_transformed_elements.append(element)\n",
    "\n",
    "    logger.info(f\"Empty transformed {element_name}: {len(empty_transformed_elements)}/{len(element_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "For the the first parte (prompt_classify_p1), the assigned confidence levels reflect a calibrated approach to expressions involving multiple classifications where a dominant rule type is not explicitly evident. For instance, when an expression primarily constrains data (Data rule) but also includes specific parties (Party rule), a high confidence level is attributed to Data while a moderate confidence level is applied to Party, acknowledging its secondary relevance.\n",
    "\n",
    "Similarly, expressions referencing roles such as “Secretary” or “interested person” without explicit party restrictions are assigned moderate confidence for Party classification due to interpretive ambiguity. Procedural elements that impact data handling, such as document forwarding, receive high confidence for Data rules; however, a moderate confidence level is assigned for Activity rules when procedural references are indirect. This methodology prioritizes primary rule types while accounting for the interpretive limits of secondary classifications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
