{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/asantos2000/master-degree-santos-anderson/blob/main/code/src/chap_6_nlp2sbvr_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lwF6l0TKfK0"
   },
   "source": [
    "# nlp2sbvr - Transformação para SBVR\n",
    "\n",
    "Chapter 6. Ferramentas de suporte\n",
    "- Section 6.2 Implementação dos principais componentes\n",
    "  - Section 6.2.4 nlp2sbvr\n",
    "    - Section Algoritmo \"Transformação para SBVR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  !rm -rf cfr2sbvr configuration checkpoint\n",
    "  !git clone https://github.com/asantos2000/master-degree-santos-anderson.git cfr2sbvr\n",
    "  %pip install -r cfr2sbvr/code/requirements.txt\n",
    "  !cp -r cfr2sbvr/code/src/configuration .\n",
    "  !cp -r cfr2sbvr/code/src/checkpoint .\n",
    "  !cp -r cfr2sbvr/code/config.colab.yaml config.yaml\n",
    "  DEFAULT_CONFIG_FILE=\"config.yaml\"\n",
    "else:\n",
    "  DEFAULT_CONFIG_FILE=\"../config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "\n",
    "# Third-party libraries\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Any\n",
    "\n",
    "# Local application/library-specific imports\n",
    "import checkpoint.main as checkpoint\n",
    "from checkpoint.main import (\n",
    "    save_checkpoint,\n",
    "    restore_checkpoint,\n",
    "    DocumentProcessor,\n",
    "    Document,\n",
    ")\n",
    "import configuration.main as configuration\n",
    "import logging_setup.main as logging_setup\n",
    "import rules_taxonomy_provider.main as rules_taxonomy_provider\n",
    "from rules_taxonomy_provider.main import RulesTemplateProvider\n",
    "import llm_query.main as llm_query\n",
    "from llm_query.main import query_instruct_llm\n",
    "\n",
    "DEV_MODE = True\n",
    "\n",
    "if DEV_MODE:\n",
    "    # Development mode\n",
    "    import importlib\n",
    "\n",
    "    importlib.reload(configuration)\n",
    "    importlib.reload(logging_setup)\n",
    "    importlib.reload(checkpoint)\n",
    "    importlib.reload(rules_taxonomy_provider)\n",
    "    importlib.reload(llm_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Default settings, check them before run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = configuration.load_config(DEFAULT_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated files for analysis in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/checkpoints/documents-2024-12-08-2.json ../outputs/extraction_report-2024-12-08-1.html ../outputs/compare_items_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(config[\"DEFAULT_CHECKPOINT_FILE\"],\n",
    "config[\"DEFAULT_EXTRACTION_REPORT_FILE\"],\n",
    "config[\"DEFAULT_EXCEL_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 20:30:17 - INFO - Logging is set up with daily rotation.\n"
     ]
    }
   ],
   "source": [
    "logger = logging_setup.setting_logging(config[\"DEFAULT_LOG_DIR\"], config[\"LOG_LEVEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints\n",
    "\n",
    "Documents, annoted datasets, statistics and metrics about the execution of the notebook are stored by checkpoint module.\n",
    "\n",
    "Checkpoints are stored / retrieved at the directory `DEFAULT_CHECKPOINT_FILE` in the configuration file.\n",
    "\n",
    "During the execution, it will restore the checkpoint at the beginning of the section and saved at the end. We can run and restore the checkpoint several times. If the run fails, check the closest checkpoint and restore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 20:30:19 - INFO - last_checkpoint='../data/checkpoints/documents-2024-12-08-1.json'\n",
      "2024-12-08 20:30:19 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-08-1.json\n",
      "2024-12-08 20:30:19 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-08-1.json.\n"
     ]
    }
   ],
   "source": [
    "# To run after classification\n",
    "last_checkpoint = configuration.get_last_filename(config[\"DEFAULT_CHECKPOINT_DIR\"], \"documents\", \"json\")\n",
    "\n",
    "logger.info(f\"{last_checkpoint=}\")\n",
    "\n",
    "config[\"DEFAULT_CHECKPOINT_FILE\"] = last_checkpoint\n",
    "\n",
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions and data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts_samples(system_prompts, user_prompts, element_name, manager):\n",
    "    manager.add_document(\n",
    "        Document(\n",
    "            id=f\"prompt-system-transform_rules_{element_name.replace(' ', '_')}\",\n",
    "            type=\"prompt\",\n",
    "            content=system_prompts[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document(\n",
    "            id=f\"prompt-user-transform_rules_{element_name.replace(' ', '_')}\",\n",
    "            type=\"prompt\",\n",
    "            content=user_prompts[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    logger.info(f\"System prompts for {element_name}s: {len(system_prompts)}\")\n",
    "    logger.info(f\"User prompts for {element_name}s: {len(user_prompts)}\")\n",
    "\n",
    "    save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM response model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedStatement(BaseModel):\n",
    "    doc_id: str = Field(..., description=\"Document ID associated with the statement.\")\n",
    "    statement_id: str = Field(..., description=\"A provided string that identifies the statement. e.g., '1', 'Person'.\")\n",
    "    statement_title: str = Field(..., description=\"Title of the statement.\") \n",
    "    statement: str = Field(..., description=\"The statement to be transformed.\")\n",
    "    statement_sources: List[str] = Field(..., description=\"Sources of the statement.\")\n",
    "    templates_ids: List[str] = Field(..., description=\"List of template IDs.\")\n",
    "    transformed: str = Field(..., description=\"The transformed statement.\")\n",
    "    confidence: float = Field(..., description=\"Confidence of the transformation.\")\n",
    "    reason: str = Field(..., description=\"Reason for confidence score of the transformation.\")\n",
    "\n",
    "class TransformedStatements(BaseModel):\n",
    "    TransformedStatements: List[TransformedStatement] = Field(..., description=\"List of transformed statements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_statement(element_name, user_prompts, system_prompts, manager):\n",
    "    # Initialize an empty list to accumulate all responses\n",
    "    all_responses = []\n",
    "    elapse_times = []\n",
    "    completions = []\n",
    "\n",
    "    # Loop through each pair of user and system prompts with a counter\n",
    "    for index, (user_prompt, system_prompt) in enumerate(\n",
    "        zip(user_prompts, system_prompts), start=1\n",
    "    ):\n",
    "        logger.info(f\"Processing transformation prompt {index} for {element_name}.\")\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "        # Query the language model\n",
    "        response, completion, elapse_time = query_instruct_llm(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=user_prompt,\n",
    "            document_model=TransformedStatements,\n",
    "            llm_model=config[\"LLM\"][\"MODEL\"],\n",
    "            temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
    "            max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
    "        )\n",
    "\n",
    "        logger.debug(response)\n",
    "\n",
    "        # Accumulate the responses in the list\n",
    "        all_responses.extend(response.TransformedStatements)\n",
    "        elapse_times.append(elapse_time)\n",
    "        completions.append(completion.dict())\n",
    "\n",
    "        logger.info(f\"Finished processing classification and templates prompt {index}.\")\n",
    "\n",
    "    # After the loop, create a single Document with all the accumulated responses\n",
    "    doc = Document(\n",
    "        id=f\"transform_{element_name.replace(' ', '_')}s\",\n",
    "        type=\"llm_response_transform\",\n",
    "        content=all_responses,\n",
    "        elapsed_times=elapse_times,\n",
    "        completions=completions,\n",
    "    )\n",
    "    manager.add_document(doc)\n",
    "\n",
    "    logger.info(f\"{element_name}s: {len(all_responses)}\")\n",
    "\n",
    "    return all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prompts_for_rule(rules, rule_template_formulation, data_dir):\n",
    "    rule_template_provider = RulesTemplateProvider(data_dir)\n",
    "\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for rule in rules:\n",
    "        element_name = rule.get(\"element_name\")\n",
    "\n",
    "        if element_name == [\"Term\", \"Name\"]:\n",
    "            statement_key = \"definition\"\n",
    "            statement_id_key = \"signifier\"\n",
    "        else:\n",
    "            statement_key = \"statement\"\n",
    "            statement_id_key = \"statement_id\"\n",
    "\n",
    "        # # Return templates and examples for fact types or all\n",
    "        # if element_name == \"Fact Type\":\n",
    "        #     return_forms = \"fact_type\"\n",
    "        # else:\n",
    "        #     return_forms = \"rule\"\n",
    "        # logger.info(f\"Processing {element_name} with return forms {return_forms}.\")\n",
    "\n",
    "        input_rule = {\n",
    "            \"doc_id\": rule[\"doc_id\"],\n",
    "            f\"{statement_id_key}\": rule[\"statement_id\"],\n",
    "            \"sources\": rule[\"sources\"],\n",
    "            f\"{statement_key}\": rule.get(\"statement\", rule.get(\"definition\")),\n",
    "            \"templates_ids\": rule[\"templates_ids\"],\n",
    "        }\n",
    "        user_prompt = get_user_prompt_transform(element_name, input_rule)\n",
    "        user_prompts.append(user_prompt)\n",
    "        rule_templates_subtemplates = rule_template_provider.get_rules_template(rule[\"templates_ids\"])\n",
    "        system_prompt = get_system_prompt_transform(element_name,rule_template_formulation, rule_templates_subtemplates)\n",
    "        system_prompts.append(system_prompt)\n",
    "        logger.debug(system_prompt)\n",
    "        logger.debug(user_prompt)\n",
    "\n",
    "    logger.info(f\"System prompts for {element_name}s: {len(system_prompts)}\")\n",
    "    logger.info(f\"User prompts for {element_name}s: {len(user_prompts)}\")\n",
    "\n",
    "    return system_prompts, user_prompts, element_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Datasets used in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True tables\n",
    "\n",
    "True tables are annotated or \"golden\" datasets in which entities have been manually identified and labeled within the original source data.\n",
    "\n",
    "True tables for sectiona 275.0-2, 275.0-5 and 275.0-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load true table for P1 - Taxonomy Classification - top level and P2 - Taxonomy Classification - sub levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{config['DEFAULT_DATA_DIR']}/documents_true_table.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"transform_Operative_Rules|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"transform_Fact_Types|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"transform_Terms|true_table\"])\n",
    "    )\n",
    "\n",
    "    manager.add_document(\n",
    "        Document.model_validate(data[\"transform_Names|true_table\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:23:53 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elements to transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get expressions to transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 17:06:52 - INFO - Rules to evaluate: 6\n",
      "2024-12-01 17:06:52 - INFO - Facts to evaluate: 16\n",
      "2024-12-01 17:06:52 - INFO - Terms to evaluate: 40\n",
      "2024-12-01 17:06:52 - INFO - Names to evaluate: 3\n"
     ]
    }
   ],
   "source": [
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "pred_operative_rules = processor.get_rules()\n",
    "pred_facts = processor.get_facts()\n",
    "pred_terms = processor.get_terms(definition_filter=\"non_null\")\n",
    "pred_names = processor.get_names(definition_filter=\"non_null\")\n",
    "\n",
    "logger.debug(f\"Rules: {pred_operative_rules}\")\n",
    "logger.debug(f\"Facts: {pred_facts}\")\n",
    "logger.debug(f\"Terms: {pred_terms}\")\n",
    "logger.debug(f\"Names: {pred_names}\")\n",
    "logger.info(f\"Rules to evaluate: {len(pred_operative_rules)}\")\n",
    "logger.info(f\"Facts to evaluate: {len(pred_facts)}\")\n",
    "logger.info(f\"Terms to evaluate: {len(pred_terms)}\")\n",
    "logger.info(f\"Names to evaluate: {len(pred_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': '§ 275.0-2',\n",
       "  'statement_id': 3,\n",
       "  'statement_title': 'Forwarding documents by the Secretary',\n",
       "  'statement': \"If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\",\n",
       "  'sources': ['(a)(2)'],\n",
       "  'terms': [{'term': 'Process, pleadings, or other papers',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to legal documents involved in the service process.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the object.'},\n",
       "   {'term': 'Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term refers to a specific governmental body.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the recipient.'},\n",
       "   {'term': 'Secretary of the Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term refers to a specific official within the Commission.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the subject.'},\n",
       "   {'term': 'Named party',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the entities involved in the legal process.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is implied as the recipient of the documents.'},\n",
       "   {'term': 'Registered or certified mail',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the method of delivery for the documents.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the method.'},\n",
       "   {'term': 'Last address filed with the Commission',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the location where documents are sent.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is implied as the destination.'}],\n",
       "  'verb_symbols': ['are served', 'will forward', 'by'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'The Secretary of the Commission must forward a copy to each named party if process, pleadings, or other papers are served on the Commission as described in this section.',\n",
       "  'semscore': 0.8808862811693581,\n",
       "  'similarity_score': 0.9,\n",
       "  'similarity_score_confidence': 0.85,\n",
       "  'transformation_accuracy': 0.9,\n",
       "  'grammar_syntax_accuracy': 0.95,\n",
       "  'findings': ['The transformed sentence maintains the core meaning of the original statement.',\n",
       "   'The transformation accurately reflects the responsibility of the Secretary to forward documents.',\n",
       "   'The conditional clause is preserved, ensuring the context of the action is clear.',\n",
       "   'The grammar and syntax of the transformed sentence are correct.'],\n",
       "  'type': 'Party rules',\n",
       "  'type_confidence': 0.9,\n",
       "  'type_explanation': 'This statement specifies the role of the Secretary in forwarding documents to named parties, indicating a responsibility and action linked to a specific role, which is characteristic of a party rule.',\n",
       "  'subtype': 'Responsibility rules',\n",
       "  'subtype_confidence': 0.8,\n",
       "  'subtype_explanation': 'The statement assigns a responsibility to the Secretary of the Commission to forward documents to each named party. The rule specifies the process (forwarding documents) and the responsible party (Secretary), aligning with the responsibility rule template.',\n",
       "  'templates_ids': ['T56']},\n",
       " {'doc_id': '§ 275.0-2',\n",
       "  'statement_id': 4,\n",
       "  'statement_title': 'Certification of service by the Secretary',\n",
       "  'statement': 'If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.',\n",
       "  'sources': ['(a)(3)'],\n",
       "  'terms': [{'term': 'Secretary',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term refers to a specific official within the Commission.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the subject.'},\n",
       "   {'term': 'Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term refers to a specific governmental body.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the recipient.'},\n",
       "   {'term': 'Process, pleadings, or other papers',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to legal documents involved in the service process.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the object.'},\n",
       "   {'term': 'Named party',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the entities involved in the legal process.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is implied as the recipient of the documents.'},\n",
       "   {'term': 'Certification',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the official confirmation of service.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the result.'},\n",
       "   {'term': 'Evidence of service',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term refers to the proof of delivery of documents.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is implied as the outcome of the certification.'}],\n",
       "  'verb_symbols': ['certifies', 'was served', 'forwarded', 'constitutes'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'The certification by the Secretary must constitute evidence of service upon a named party if the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section.',\n",
       "  'semscore': 0.944215495372715,\n",
       "  'similarity_score': 0.9,\n",
       "  'similarity_score_confidence': 0.85,\n",
       "  'transformation_accuracy': 0.9,\n",
       "  'grammar_syntax_accuracy': 0.95,\n",
       "  'findings': ['The transformed sentence maintains the original meaning and structure, with slight rephrasing to fit the template.',\n",
       "   \"The use of 'must constitute' aligns with the template's requirement for a responsibility signifier.\",\n",
       "   'The conditional clause is correctly placed at the end of the sentence, following the template structure.'],\n",
       "  'type': 'Party rules',\n",
       "  'type_confidence': 0.8,\n",
       "  'type_explanation': \"The statement involves the Secretary's role in certifying service, which is a responsibility linked to a specific role, indicating a party rule.\",\n",
       "  'subtype': 'Responsibility rules',\n",
       "  'subtype_confidence': 0.7,\n",
       "  'subtype_explanation': 'This statement describes a responsibility of the Secretary to certify service of documents, which constitutes evidence of service. It involves a process (certification of service) and a responsible party (Secretary), fitting the responsibility rule template.',\n",
       "  'templates_ids': ['T56']},\n",
       " {'doc_id': '§ 275.0-5',\n",
       "  'statement_id': 1,\n",
       "  'statement_title': 'Notice of proceeding initiation',\n",
       "  'statement': 'Notice of the initiation of the proceeding will be published in the Federal Register and will indicate the earliest date upon which an order disposing of the matter may be entered.',\n",
       "  'sources': ['(a)'],\n",
       "  'terms': [{'term': 'Notice',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term is a general concept used in legal contexts.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as a key part of the procedure.'},\n",
       "   {'term': 'Initiation of the proceeding',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general process in legal proceedings.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is a central part of the statement.'},\n",
       "   {'term': 'Federal Register',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 1.0,\n",
       "    'reason': 'The term is a specific publication used for official notices.',\n",
       "    'extracted_confidence': 1.0,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the publication medium.'},\n",
       "   {'term': 'Order disposing of the matter',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes a general legal outcome.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a key part of the procedure described.'}],\n",
       "  'verb_symbols': ['will be published', 'will indicate'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'The publication of notice for the initiation of the proceeding must occur in the Federal Register and indicate the earliest date upon which an order disposing of the matter may be entered.',\n",
       "  'semscore': 0.9203712785586743,\n",
       "  'similarity_score': 0.95,\n",
       "  'similarity_score_confidence': 0.9,\n",
       "  'transformation_accuracy': 0.9,\n",
       "  'grammar_syntax_accuracy': 0.95,\n",
       "  'findings': ['The transformed sentence maintains the original meaning and structure, with slight modifications to fit the template.',\n",
       "   \"The use of 'must occur' and 'may be entered' aligns with the template's requirement for activity and time limit rules.\",\n",
       "   'The grammar and syntax are correct, with proper use of legal terminology.'],\n",
       "  'type': 'Activity rules',\n",
       "  'type_confidence': 0.9,\n",
       "  'type_explanation': 'The statement describes an activity (publishing notice) that must occur, which is characteristic of an activity obligation rule.',\n",
       "  'subtype': 'Activity time limit rules',\n",
       "  'subtype_confidence': 0.8,\n",
       "  'subtype_explanation': 'The statement specifies that the notice will indicate the earliest date upon which an order may be entered, which aligns with the concept of a time restriction on when an activity (entering an order) can occur. The template T48 is used for rules that define time restrictions for activities.',\n",
       "  'templates_ids': ['T48']},\n",
       " {'doc_id': '§ 275.0-5',\n",
       "  'statement_id': 2,\n",
       "  'statement_title': 'Submission of facts and hearing request',\n",
       "  'statement': 'Any interested person may, within the period of time specified therein, submit to the Commission in writing any facts bearing upon the desirability of a hearing on the matter and may request that a hearing be held, stating his reasons therefor and the nature of his interest in the matter.',\n",
       "  'sources': ['(a)'],\n",
       "  'terms': [{'term': 'Interested person',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term refers to a general category of individuals involved in legal proceedings.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as a participant in the process.'},\n",
       "   {'term': 'Period of time',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general time frame within which actions can be taken.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is a key part of the conditions for submission.'},\n",
       "   {'term': 'Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 1.0,\n",
       "    'reason': 'The term refers to a specific regulatory body.',\n",
       "    'extracted_confidence': 1.0,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the recipient of submissions.'},\n",
       "   {'term': 'Facts',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes general information relevant to the hearing.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a central part of the submission process.'},\n",
       "   {'term': 'Hearing',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes a general legal proceeding.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a key part of the request process.'},\n",
       "   {'term': 'Reasons',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes general justifications for actions.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is part of the requirement for requesting a hearing.'},\n",
       "   {'term': 'Nature of interest',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general aspect of involvement in the matter.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is part of the requirement for requesting a hearing.'}],\n",
       "  'verb_symbols': ['may submit', 'may request', 'stating'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'An interested person may submit to the Commission in writing any facts bearing upon the desirability of a hearing on the matter only if the period of time specified therein has not expired.',\n",
       "  'semscore': 0.8998364630698071,\n",
       "  'similarity_score': 0.85,\n",
       "  'similarity_score_confidence': 0.9,\n",
       "  'transformation_accuracy': 0.8,\n",
       "  'grammar_syntax_accuracy': 0.95,\n",
       "  'findings': ['The transformed sentence captures the essence of the original statement but omits the ability to request a hearing and the requirement to state reasons and nature of interest.',\n",
       "   \"The transformation focuses on the submission of facts within a specified time, aligning with the template's structure.\",\n",
       "   \"The grammar and syntax of the transformed sentence are accurate, but the transformation does not fully encapsulate the original statement's scope.\"],\n",
       "  'type': 'Party rules',\n",
       "  'type_confidence': 0.7,\n",
       "  'type_explanation': 'The statement involves roles (interested person) and their ability to submit facts and request a hearing, indicating a party rule.',\n",
       "  'subtype': 'Party restriction rules',\n",
       "  'subtype_confidence': 0.6,\n",
       "  'subtype_explanation': 'The statement allows any interested person to submit facts and request a hearing, which is a form of party restriction rule. It specifies who may perform the action (interested person) and under what conditions (within a specified time), aligning with the party restriction rule template.',\n",
       "  'templates_ids': ['T53']},\n",
       " {'doc_id': '§ 275.0-5',\n",
       "  'statement_id': 3,\n",
       "  'statement_title': 'Issuance of order disposing of the matter',\n",
       "  'statement': 'An order disposing of the matter will be issued as of course following the expiration of the period of time referred to in paragraph (a) of this section, unless the Commission thereafter orders a hearing on the matter.',\n",
       "  'sources': ['(b)'],\n",
       "  'terms': [{'term': 'Order disposing of the matter',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes a general legal outcome.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a key part of the procedure described.'},\n",
       "   {'term': 'Period of time',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general time frame within which actions can be taken.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is a key part of the conditions for issuance.'},\n",
       "   {'term': 'Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 1.0,\n",
       "    'reason': 'The term refers to a specific regulatory body.',\n",
       "    'extracted_confidence': 1.0,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the entity that may order a hearing.'},\n",
       "   {'term': 'Hearing',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes a general legal proceeding.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a key part of the conditions for issuance.'}],\n",
       "  'verb_symbols': ['will be issued', 'orders'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'An order disposing of the matter may be issued only after the expiration of the period of time referred to in paragraph (a) of this section unless the Commission thereafter orders a hearing on the matter.',\n",
       "  'semscore': 0.9222308405718812,\n",
       "  'similarity_score': 0.95,\n",
       "  'similarity_score_confidence': 0.9,\n",
       "  'transformation_accuracy': 0.9,\n",
       "  'grammar_syntax_accuracy': 1.0,\n",
       "  'findings': ['The transformed sentence accurately reflects the original statement with a slight change in phrasing to fit the template.',\n",
       "   \"The use of 'may be issued only after' instead of 'will be issued as of course following' maintains the original meaning but aligns with the template structure.\",\n",
       "   \"The conditional clause 'unless the Commission thereafter orders a hearing on the matter' is preserved accurately.\",\n",
       "   'The grammar and syntax of the transformed sentence are correct.'],\n",
       "  'type': 'Activity rules',\n",
       "  'type_confidence': 0.8,\n",
       "  'type_explanation': 'The statement describes an activity (issuing an order) that occurs under certain conditions, which is characteristic of an activity rule.',\n",
       "  'subtype': 'Activity pre-condition rules',\n",
       "  'subtype_confidence': 0.7,\n",
       "  'subtype_explanation': 'The statement indicates that the order will be issued following the expiration of a specific time period unless a hearing is ordered, which suggests a pre-condition for the issuance of the order. The template T50 is used for rules that prohibit an activity unless a certain condition is met.',\n",
       "  'templates_ids': ['T50']},\n",
       " {'doc_id': '§ 275.0-5',\n",
       "  'statement_id': 4,\n",
       "  'statement_title': 'Commission orders a hearing',\n",
       "  'statement': 'The Commission will order a hearing on the matter, if it appears that a hearing is necessary or appropriate in the public interest or for the protection of investors.',\n",
       "  'sources': ['(c)'],\n",
       "  'terms': [{'term': 'Commission',\n",
       "    'classification': 'Proper Noun',\n",
       "    'confidence': 1.0,\n",
       "    'reason': 'The term refers to a specific regulatory body.',\n",
       "    'extracted_confidence': 1.0,\n",
       "    'extracted_reason': 'The term is explicitly mentioned as the entity that orders a hearing.'},\n",
       "   {'term': 'Hearing',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.9,\n",
       "    'reason': 'The term describes a general legal proceeding.',\n",
       "    'extracted_confidence': 0.9,\n",
       "    'extracted_reason': 'The term is a key part of the conditions for ordering.'},\n",
       "   {'term': 'Public interest',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general concept related to societal welfare.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is part of the criteria for ordering a hearing.'},\n",
       "   {'term': 'Protection of investors',\n",
       "    'classification': 'Common Noun',\n",
       "    'confidence': 0.8,\n",
       "    'reason': 'The term describes a general concept related to safeguarding investors.',\n",
       "    'extracted_confidence': 0.8,\n",
       "    'extracted_reason': 'The term is part of the criteria for ordering a hearing.'}],\n",
       "  'verb_symbols': ['will order', 'appears', 'is necessary', 'is appropriate'],\n",
       "  'element_name': 'Operative Rule',\n",
       "  'transformed': 'The Commission may order a hearing on the matter only if it appears that a hearing is necessary or appropriate in the public interest or for the protection of investors.',\n",
       "  'semscore': 0.9432317012278398,\n",
       "  'similarity_score': 0.95,\n",
       "  'similarity_score_confidence': 0.9,\n",
       "  'transformation_accuracy': 0.95,\n",
       "  'grammar_syntax_accuracy': 1.0,\n",
       "  'findings': [\"The transformed sentence accurately reflects the original statement with a slight change in modality from 'will' to 'may', which aligns with the template's conditional structure.\",\n",
       "   'The grammar and syntax of the transformed sentence are correct.',\n",
       "   'The transformation maintains the original meaning and conditions for ordering a hearing.'],\n",
       "  'type': 'Activity rules',\n",
       "  'type_confidence': 0.9,\n",
       "  'type_explanation': 'The statement describes an activity (ordering a hearing) that the Commission must perform under certain conditions, which is characteristic of an activity rule.',\n",
       "  'subtype': 'Activity pre-condition rules',\n",
       "  'subtype_confidence': 0.8,\n",
       "  'subtype_explanation': \"The statement describes a condition under which the Commission will order a hearing. It specifies that a hearing will be ordered if it appears necessary or appropriate in the public interest or for the protection of investors. This aligns with the template for Activity pre-condition rules, which involves an activity that may occur only if a certain condition is met. The 'if' clause in the statement matches the 'if <conditional clause>' part of the template.\",\n",
       "  'templates_ids': ['T50']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_operative_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System prompt\n",
    "\n",
    "Formulation is expressed using a template (WITT, 2012, p. 162)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_template_formulation = \"\"\"\n",
    "# How to interpret the templates and subtemplates\n",
    "\n",
    "Each formulation is expressed using a template, in which the various symbols have the following meanings:\n",
    "\n",
    "1. Each item enclosed in \"angle brackets\" (\"<\" and \">\") is a placeholder, in place of which any suitable text may be substituted. For example, any of the following may be substituted in place of <operative rule statement subject> (subtemplate):\n",
    "    a. a term: for example, \"flight booking request\",\n",
    "    b. a term followed by a qualifying clause: for example, \"flight booking request for a one-way journey\",\n",
    "    c. a reference to a combination of items: for example, \"combination of enrollment date and graduation date\", with or without a qualifying clause,\n",
    "    d. a reference to a set of items: for example, \"set of passengers\", with or without a qualifying clause.\n",
    "2. Each pair of braces (\"{\" and \"}\") encloses a set of options (separated from each other by the bar symbol: \"|\"), one of which is included in the rule statement. For example,\n",
    "3. If a pair of braces includes a bar symbol immediately before the closing brace, the null option is allowed: that is, you can, if necessary, include none of the options at that point in the rule statement.\n",
    "4. Sets of options may be nested. For example, in each of the templates above\n",
    "    a. a conditional clause may be included or omitted,\n",
    "    b. if included, the conditional clause should be preceded by either \"if\" or \"unless\".\n",
    "5. A further notation, introduced later in this section, uses square brackets to indicate that a syntactic element may be repeated indefinitely.\n",
    "6. Any text not enclosed in either \"angle brackets\" or braces (i.e., \"must\", \"not\", \"may\", and \"only\") is included in every rule statement conforming to the relevant template.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_transform(element_name, rule_template_formulation, rule_templates_subtemplates):\n",
    "    statement_name = \"definition\" if element_name in [\"Term\", \"Name\"] else \"statement\"\n",
    "    return f\"\"\"\n",
    "Transform each given {element_name} {statement_name} into a structured format by matching it to the specified templates and subtemplates.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Summarize {statement_name}**: Summarize the given {element_name} {statement_name} to understand its structure and content.\n",
    "\n",
    "2. **Use Template**:\n",
    "   - For given expression, use the templates and subtemplates ({\"Fact Type Form\" if element_name in [\"Fact Type\", \"Fact\"] else \"Rule Form\"}) provided for transformation.\n",
    "   - Determine the appropriate template or subtemplate based on the structure of the expression.\n",
    "   \n",
    "3. **Replace Placeholders**:\n",
    "   - Substitute placeholders, such as `<term>`, `<verb phrase>`, `<conditional clause>`, etc., with suitable values as per the expression.\n",
    "   - For terms and names, the statement_id is the term defined by the statement.\n",
    "   \n",
    "4. **Include Qualifying Details**:\n",
    "   - Where placeholders, such as `<qualifying clause>`, require additional details (e.g., attributes or qualifiers to distinguish meaning), ensure that these are included appropriately as per the respective subtemplate.\n",
    "\n",
    "5. **Transform into Structured Format**:\n",
    "   - Once the transformation is complete, ensure it's in the correct template format.\n",
    "\n",
    "6. **Output as Structured JSON**:\n",
    "   - For every transformed expression generate a JSON object as per the specified output format.\n",
    "\n",
    "7. **Review and Validate**:\n",
    "   - Ensure accuracy in grammar and compliance with logical constructs when performing substitutions.\n",
    "   - Ensure the generated JSON is in the correct template format.\n",
    "\n",
    "8. **Assess the Transformation**:\n",
    "   - Record the confidence level and reason for the confidence score in the JSON object.\n",
    "\n",
    "{rule_template_formulation}\n",
    "\n",
    "# Provided templates and subtemplates for transformation\n",
    "\n",
    "{rule_templates_subtemplates}\n",
    "\n",
    "# Output Format\n",
    "\n",
    "[\n",
    "    {{\n",
    "      \"doc_id\": <doc_id>,\n",
    "      \"statement_id\": <statement_id or signifier>,\n",
    "      \"statement_title\": <statement_title>,\n",
    "      \"sources\": [<source>],\n",
    "      \"statement\": <statement or definition>,\n",
    "      \"templates_ids\": [<templates_id>],\n",
    "      \"transformed\": <transformed_statement>,\n",
    "      \"confidence\": <confidence_level>,\n",
    "      \"reason\": <reason_for_confidence>\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\n",
    "- **`doc_id`**: A original identifier of the given document.\n",
    "- **`statement_id or signifier`**: The original identifier of the given {statement_name}. e.g., '1', 'Person'\".\n",
    "- **`statement_title`**: The title of the given {statement_name}.\n",
    "- **`sources`**: The original sources of the given {statement_name}.\n",
    "- **`statement or definition`**: The original text of the given {statement_name}.\n",
    "- **`templates_ids`**: The template(s) used for the transformation (e.g., T1, T2, etc.)\n",
    "- **`transformed`**: The transformed statement according to template.\n",
    "- **`confidence`**: The confidence level of the transformation range from 0 to 1.\n",
    "- **`reason`**: The reason for the confidence score.\n",
    "\n",
    "# Notes\n",
    "- Use only the provided templates and subtemplates for transformation.\n",
    "- If a placeholder within an expression is not applicable or optional, consider whether it should be omitted or replaced by a suitable value.\n",
    "- Each expression may involve nested levels of substitution as indicated by the subtemplate hierarchy (e.g., a qualifying clause that contains sub-elements).\n",
    "- Ensure accuracy in grammar and compliance with logical constructs when performing substitutions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt_transform(element_name, rule):\n",
    "\n",
    "    return f\"\"\"\n",
    "# Here's the {element_name} {\"definition\" if element_name in [\"Term\", \"Name\"] else \"statement\"} you need to transform using template {rule.get(\"templates_ids\")}.\n",
    "\n",
    "{json.dumps(rule, indent=2)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:23:53 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:23:53 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-01-1.json.\n"
     ]
    }
   ],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operative rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for operative rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - System prompts for Operative Rules: 6\n",
      "2024-12-01 01:23:53 - INFO - User prompts for Operative Rules: 6\n"
     ]
    }
   ],
   "source": [
    "system_prompts_operative_rules, user_prompts_operative_rules, element_name = (\n",
    "    get_prompts_for_rule(\n",
    "        rules=pred_operative_rules,\n",
    "        rule_template_formulation=rule_template_formulation,\n",
    "        data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - System prompts for Operative Rules: 6\n",
      "2024-12-01 01:23:53 - INFO - User prompts for Operative Rules: 6\n",
      "2024-12-01 01:23:53 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:23:53 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_operative_rules, user_prompts_operative_rules, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform operative rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:23:53 - INFO - Processing transformation prompt 1 for Operative Rule.\n",
      "2024-12-01 01:23:56 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:23:56 - INFO - Tokes used: CompletionUsage(completion_tokens=200, prompt_tokens=5042, total_tokens=5242, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:23:56 - INFO - Execution time for query_instruct_llm: 2.84 seconds\n",
      "2024-12-01 01:23:56 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-01 01:23:56 - INFO - Processing transformation prompt 2 for Operative Rule.\n",
      "2024-12-01 01:23:59 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:23:59 - INFO - Tokes used: CompletionUsage(completion_tokens=227, prompt_tokens=5049, total_tokens=5276, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:23:59 - INFO - Execution time for query_instruct_llm: 3.06 seconds\n",
      "2024-12-01 01:23:59 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-01 01:23:59 - INFO - Processing transformation prompt 3 for Operative Rule.\n",
      "2024-12-01 01:24:01 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:01 - INFO - Tokes used: CompletionUsage(completion_tokens=185, prompt_tokens=5400, total_tokens=5585, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:01 - INFO - Execution time for query_instruct_llm: 2.32 seconds\n",
      "2024-12-01 01:24:01 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-01 01:24:01 - INFO - Processing transformation prompt 4 for Operative Rule.\n",
      "2024-12-01 01:24:06 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:06 - INFO - Tokes used: CompletionUsage(completion_tokens=232, prompt_tokens=5162, total_tokens=5394, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:06 - INFO - Execution time for query_instruct_llm: 4.89 seconds\n",
      "2024-12-01 01:24:06 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-01 01:24:06 - INFO - Processing transformation prompt 5 for Operative Rule.\n",
      "2024-12-01 01:24:10 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:10 - INFO - Tokes used: CompletionUsage(completion_tokens=220, prompt_tokens=5333, total_tokens=5553, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:10 - INFO - Execution time for query_instruct_llm: 3.95 seconds\n",
      "2024-12-01 01:24:10 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-01 01:24:10 - INFO - Processing transformation prompt 6 for Operative Rule.\n",
      "2024-12-01 01:24:13 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:13 - INFO - Tokes used: CompletionUsage(completion_tokens=185, prompt_tokens=5322, total_tokens=5507, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:13 - INFO - Execution time for query_instruct_llm: 2.35 seconds\n",
      "2024-12-01 01:24:13 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-01 01:24:13 - INFO - Operative Rules: 6\n",
      "2024-12-01 01:24:13 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:24:13 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_operative_rules = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_operative_rules,\n",
    "    system_prompts=system_prompts_operative_rules,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_operative_rules=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:13 - INFO - System prompts for Fact Types: 16\n",
      "2024-12-01 01:24:13 - INFO - User prompts for Fact Types: 16\n"
     ]
    }
   ],
   "source": [
    "system_prompts_facts, user_prompts_facts, element_name = get_prompts_for_rule(\n",
    "    rules=pred_facts,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:13 - INFO - System prompts for Fact Types: 6\n",
      "2024-12-01 01:24:13 - INFO - User prompts for Fact Types: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:13 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:24:13 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_operative_rules, user_prompts_operative_rules, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:13 - INFO - Processing transformation prompt 1 for Fact Type.\n",
      "2024-12-01 01:24:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:19 - INFO - Tokes used: CompletionUsage(completion_tokens=205, prompt_tokens=1940, total_tokens=2145, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:19 - INFO - Execution time for query_instruct_llm: 2.17 seconds\n",
      "2024-12-01 01:24:19 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-01 01:24:19 - INFO - Processing transformation prompt 2 for Fact Type.\n",
      "2024-12-01 01:24:21 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:21 - INFO - Tokes used: CompletionUsage(completion_tokens=236, prompt_tokens=1949, total_tokens=2185, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:21 - INFO - Execution time for query_instruct_llm: 2.48 seconds\n",
      "2024-12-01 01:24:21 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-01 01:24:21 - INFO - Processing transformation prompt 3 for Fact Type.\n",
      "2024-12-01 01:24:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:24 - INFO - Tokes used: CompletionUsage(completion_tokens=164, prompt_tokens=5085, total_tokens=5249, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:24 - INFO - Execution time for query_instruct_llm: 2.48 seconds\n",
      "2024-12-01 01:24:24 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-01 01:24:24 - INFO - Processing transformation prompt 4 for Fact Type.\n",
      "2024-12-01 01:24:27 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:27 - INFO - Tokes used: CompletionUsage(completion_tokens=271, prompt_tokens=1885, total_tokens=2156, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:27 - INFO - Execution time for query_instruct_llm: 3.41 seconds\n",
      "2024-12-01 01:24:27 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-01 01:24:27 - INFO - Processing transformation prompt 5 for Fact Type.\n",
      "2024-12-01 01:24:29 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:29 - INFO - Tokes used: CompletionUsage(completion_tokens=159, prompt_tokens=1604, total_tokens=1763, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:29 - INFO - Execution time for query_instruct_llm: 2.33 seconds\n",
      "2024-12-01 01:24:29 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-01 01:24:29 - INFO - Processing transformation prompt 6 for Fact Type.\n",
      "2024-12-01 01:24:32 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:32 - INFO - Tokes used: CompletionUsage(completion_tokens=158, prompt_tokens=1827, total_tokens=1985, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:32 - INFO - Execution time for query_instruct_llm: 2.49 seconds\n",
      "2024-12-01 01:24:32 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-01 01:24:32 - INFO - Processing transformation prompt 7 for Fact Type.\n",
      "2024-12-01 01:24:34 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:34 - INFO - Tokes used: CompletionUsage(completion_tokens=177, prompt_tokens=5093, total_tokens=5270, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:34 - INFO - Execution time for query_instruct_llm: 2.37 seconds\n",
      "2024-12-01 01:24:34 - INFO - Finished processing classification and templates prompt 7.\n",
      "2024-12-01 01:24:34 - INFO - Processing transformation prompt 8 for Fact Type.\n",
      "2024-12-01 01:24:37 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:37 - INFO - Tokes used: CompletionUsage(completion_tokens=191, prompt_tokens=1895, total_tokens=2086, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:37 - INFO - Execution time for query_instruct_llm: 2.76 seconds\n",
      "2024-12-01 01:24:37 - INFO - Finished processing classification and templates prompt 8.\n",
      "2024-12-01 01:24:37 - INFO - Processing transformation prompt 9 for Fact Type.\n",
      "2024-12-01 01:24:39 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:39 - INFO - Tokes used: CompletionUsage(completion_tokens=149, prompt_tokens=1879, total_tokens=2028, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:39 - INFO - Execution time for query_instruct_llm: 2.27 seconds\n",
      "2024-12-01 01:24:39 - INFO - Finished processing classification and templates prompt 9.\n",
      "2024-12-01 01:24:39 - INFO - Processing transformation prompt 10 for Fact Type.\n",
      "2024-12-01 01:24:41 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:41 - INFO - Tokes used: CompletionUsage(completion_tokens=175, prompt_tokens=1928, total_tokens=2103, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:41 - INFO - Execution time for query_instruct_llm: 1.76 seconds\n",
      "2024-12-01 01:24:41 - INFO - Finished processing classification and templates prompt 10.\n",
      "2024-12-01 01:24:41 - INFO - Processing transformation prompt 11 for Fact Type.\n",
      "2024-12-01 01:24:43 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:43 - INFO - Tokes used: CompletionUsage(completion_tokens=167, prompt_tokens=5077, total_tokens=5244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:43 - INFO - Execution time for query_instruct_llm: 1.96 seconds\n",
      "2024-12-01 01:24:43 - INFO - Finished processing classification and templates prompt 11.\n",
      "2024-12-01 01:24:43 - INFO - Processing transformation prompt 12 for Fact Type.\n",
      "2024-12-01 01:24:45 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:45 - INFO - Tokes used: CompletionUsage(completion_tokens=201, prompt_tokens=5084, total_tokens=5285, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:45 - INFO - Execution time for query_instruct_llm: 2.44 seconds\n",
      "2024-12-01 01:24:45 - INFO - Finished processing classification and templates prompt 12.\n",
      "2024-12-01 01:24:45 - INFO - Processing transformation prompt 13 for Fact Type.\n",
      "2024-12-01 01:24:47 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:47 - INFO - Tokes used: CompletionUsage(completion_tokens=179, prompt_tokens=5083, total_tokens=5262, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:47 - INFO - Execution time for query_instruct_llm: 2.01 seconds\n",
      "2024-12-01 01:24:47 - INFO - Finished processing classification and templates prompt 13.\n",
      "2024-12-01 01:24:47 - INFO - Processing transformation prompt 14 for Fact Type.\n",
      "2024-12-01 01:24:50 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:50 - INFO - Tokes used: CompletionUsage(completion_tokens=240, prompt_tokens=5117, total_tokens=5357, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:50 - INFO - Execution time for query_instruct_llm: 2.38 seconds\n",
      "2024-12-01 01:24:50 - INFO - Finished processing classification and templates prompt 14.\n",
      "2024-12-01 01:24:50 - INFO - Processing transformation prompt 15 for Fact Type.\n",
      "2024-12-01 01:24:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:55 - INFO - Tokes used: CompletionUsage(completion_tokens=152, prompt_tokens=1814, total_tokens=1966, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:55 - INFO - Execution time for query_instruct_llm: 1.88 seconds\n",
      "2024-12-01 01:24:55 - INFO - Finished processing classification and templates prompt 15.\n",
      "2024-12-01 01:24:55 - INFO - Processing transformation prompt 16 for Fact Type.\n",
      "2024-12-01 01:24:57 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:24:57 - INFO - Tokes used: CompletionUsage(completion_tokens=200, prompt_tokens=1844, total_tokens=2044, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:24:57 - INFO - Execution time for query_instruct_llm: 1.88 seconds\n",
      "2024-12-01 01:24:57 - INFO - Finished processing classification and templates prompt 16.\n",
      "2024-12-01 01:24:57 - INFO - Fact Types: 16\n",
      "2024-12-01 01:24:57 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:24:57 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_facts = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_facts,\n",
    "    system_prompts=system_prompts_facts,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_facts=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:57 - INFO - System prompts for Terms: 40\n",
      "2024-12-01 01:24:57 - INFO - User prompts for Terms: 40\n"
     ]
    }
   ],
   "source": [
    "system_prompts_terms, user_prompts_terms, element_name = get_prompts_for_rule(\n",
    "    rules=pred_terms,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:57 - INFO - System prompts for Terms: 40\n",
      "2024-12-01 01:24:57 - INFO - User prompts for Terms: 40\n",
      "2024-12-01 01:24:57 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:24:57 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_terms, user_prompts_terms, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:24:58 - INFO - Processing transformation prompt 1 for Term.\n",
      "2024-12-01 01:25:00 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:00 - INFO - Tokes used: CompletionUsage(completion_tokens=176, prompt_tokens=5068, total_tokens=5244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:00 - INFO - Execution time for query_instruct_llm: 2.08 seconds\n",
      "2024-12-01 01:25:00 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-01 01:25:00 - INFO - Processing transformation prompt 2 for Term.\n",
      "2024-12-01 01:25:02 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:02 - INFO - Tokes used: CompletionUsage(completion_tokens=172, prompt_tokens=5068, total_tokens=5240, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:02 - INFO - Execution time for query_instruct_llm: 2.21 seconds\n",
      "2024-12-01 01:25:02 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-01 01:25:02 - INFO - Processing transformation prompt 3 for Term.\n",
      "2024-12-01 01:25:05 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:05 - INFO - Tokes used: CompletionUsage(completion_tokens=173, prompt_tokens=5068, total_tokens=5241, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:05 - INFO - Execution time for query_instruct_llm: 2.77 seconds\n",
      "2024-12-01 01:25:05 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-01 01:25:05 - INFO - Processing transformation prompt 4 for Term.\n",
      "2024-12-01 01:25:07 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:07 - INFO - Tokes used: CompletionUsage(completion_tokens=173, prompt_tokens=1817, total_tokens=1990, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:07 - INFO - Execution time for query_instruct_llm: 2.15 seconds\n",
      "2024-12-01 01:25:07 - INFO - Finished processing classification and templates prompt 4.\n",
      "2024-12-01 01:25:07 - INFO - Processing transformation prompt 5 for Term.\n",
      "2024-12-01 01:25:09 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:09 - INFO - Tokes used: CompletionUsage(completion_tokens=171, prompt_tokens=1812, total_tokens=1983, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:09 - INFO - Execution time for query_instruct_llm: 1.80 seconds\n",
      "2024-12-01 01:25:09 - INFO - Finished processing classification and templates prompt 5.\n",
      "2024-12-01 01:25:09 - INFO - Processing transformation prompt 6 for Term.\n",
      "2024-12-01 01:25:11 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:11 - INFO - Tokes used: CompletionUsage(completion_tokens=167, prompt_tokens=5070, total_tokens=5237, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:11 - INFO - Execution time for query_instruct_llm: 2.37 seconds\n",
      "2024-12-01 01:25:11 - INFO - Finished processing classification and templates prompt 6.\n",
      "2024-12-01 01:25:11 - INFO - Processing transformation prompt 7 for Term.\n",
      "2024-12-01 01:25:13 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:13 - INFO - Tokes used: CompletionUsage(completion_tokens=161, prompt_tokens=5064, total_tokens=5225, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:13 - INFO - Execution time for query_instruct_llm: 2.38 seconds\n",
      "2024-12-01 01:25:13 - INFO - Finished processing classification and templates prompt 7.\n",
      "2024-12-01 01:25:13 - INFO - Processing transformation prompt 8 for Term.\n",
      "2024-12-01 01:25:16 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:16 - INFO - Tokes used: CompletionUsage(completion_tokens=180, prompt_tokens=5074, total_tokens=5254, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:16 - INFO - Execution time for query_instruct_llm: 2.29 seconds\n",
      "2024-12-01 01:25:16 - INFO - Finished processing classification and templates prompt 8.\n",
      "2024-12-01 01:25:16 - INFO - Processing transformation prompt 9 for Term.\n",
      "2024-12-01 01:25:18 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:18 - INFO - Tokes used: CompletionUsage(completion_tokens=153, prompt_tokens=5060, total_tokens=5213, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:18 - INFO - Execution time for query_instruct_llm: 2.08 seconds\n",
      "2024-12-01 01:25:18 - INFO - Finished processing classification and templates prompt 9.\n",
      "2024-12-01 01:25:18 - INFO - Processing transformation prompt 10 for Term.\n",
      "2024-12-01 01:25:18 - INFO - Retrying request to /chat/completions in 0.380224 seconds\n",
      "2024-12-01 01:25:20 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:20 - INFO - Tokes used: CompletionUsage(completion_tokens=169, prompt_tokens=5064, total_tokens=5233, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:20 - INFO - Execution time for query_instruct_llm: 2.50 seconds\n",
      "2024-12-01 01:25:20 - INFO - Finished processing classification and templates prompt 10.\n",
      "2024-12-01 01:25:20 - INFO - Processing transformation prompt 11 for Term.\n",
      "2024-12-01 01:25:22 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:22 - INFO - Tokes used: CompletionUsage(completion_tokens=141, prompt_tokens=5059, total_tokens=5200, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:22 - INFO - Execution time for query_instruct_llm: 1.81 seconds\n",
      "2024-12-01 01:25:22 - INFO - Finished processing classification and templates prompt 11.\n",
      "2024-12-01 01:25:22 - INFO - Processing transformation prompt 12 for Term.\n",
      "2024-12-01 01:25:24 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:24 - INFO - Tokes used: CompletionUsage(completion_tokens=148, prompt_tokens=5061, total_tokens=5209, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:24 - INFO - Execution time for query_instruct_llm: 2.22 seconds\n",
      "2024-12-01 01:25:24 - INFO - Finished processing classification and templates prompt 12.\n",
      "2024-12-01 01:25:24 - INFO - Processing transformation prompt 13 for Term.\n",
      "2024-12-01 01:25:30 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:30 - INFO - Tokes used: CompletionUsage(completion_tokens=167, prompt_tokens=5078, total_tokens=5245, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:30 - INFO - Execution time for query_instruct_llm: 2.09 seconds\n",
      "2024-12-01 01:25:30 - INFO - Finished processing classification and templates prompt 13.\n",
      "2024-12-01 01:25:30 - INFO - Processing transformation prompt 14 for Term.\n",
      "2024-12-01 01:25:32 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:32 - INFO - Tokes used: CompletionUsage(completion_tokens=159, prompt_tokens=5073, total_tokens=5232, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:32 - INFO - Execution time for query_instruct_llm: 1.88 seconds\n",
      "2024-12-01 01:25:32 - INFO - Finished processing classification and templates prompt 14.\n",
      "2024-12-01 01:25:32 - INFO - Processing transformation prompt 15 for Term.\n",
      "2024-12-01 01:25:34 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:34 - INFO - Tokes used: CompletionUsage(completion_tokens=200, prompt_tokens=5080, total_tokens=5280, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:34 - INFO - Execution time for query_instruct_llm: 2.57 seconds\n",
      "2024-12-01 01:25:34 - INFO - Finished processing classification and templates prompt 15.\n",
      "2024-12-01 01:25:34 - INFO - Processing transformation prompt 16 for Term.\n",
      "2024-12-01 01:25:36 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:36 - INFO - Tokes used: CompletionUsage(completion_tokens=166, prompt_tokens=1819, total_tokens=1985, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:36 - INFO - Execution time for query_instruct_llm: 2.15 seconds\n",
      "2024-12-01 01:25:36 - INFO - Finished processing classification and templates prompt 16.\n",
      "2024-12-01 01:25:36 - INFO - Processing transformation prompt 17 for Term.\n",
      "2024-12-01 01:25:39 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:39 - INFO - Tokes used: CompletionUsage(completion_tokens=147, prompt_tokens=5059, total_tokens=5206, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:39 - INFO - Execution time for query_instruct_llm: 2.06 seconds\n",
      "2024-12-01 01:25:39 - INFO - Finished processing classification and templates prompt 17.\n",
      "2024-12-01 01:25:39 - INFO - Processing transformation prompt 18 for Term.\n",
      "2024-12-01 01:25:40 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:40 - INFO - Tokes used: CompletionUsage(completion_tokens=156, prompt_tokens=5071, total_tokens=5227, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:40 - INFO - Execution time for query_instruct_llm: 1.94 seconds\n",
      "2024-12-01 01:25:40 - INFO - Finished processing classification and templates prompt 18.\n",
      "2024-12-01 01:25:41 - INFO - Processing transformation prompt 19 for Term.\n",
      "2024-12-01 01:25:42 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:42 - INFO - Tokes used: CompletionUsage(completion_tokens=167, prompt_tokens=5077, total_tokens=5244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:42 - INFO - Execution time for query_instruct_llm: 1.87 seconds\n",
      "2024-12-01 01:25:42 - INFO - Finished processing classification and templates prompt 19.\n",
      "2024-12-01 01:25:42 - INFO - Processing transformation prompt 20 for Term.\n",
      "2024-12-01 01:25:45 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:45 - INFO - Tokes used: CompletionUsage(completion_tokens=149, prompt_tokens=5078, total_tokens=5227, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:45 - INFO - Execution time for query_instruct_llm: 2.35 seconds\n",
      "2024-12-01 01:25:45 - INFO - Finished processing classification and templates prompt 20.\n",
      "2024-12-01 01:25:45 - INFO - Processing transformation prompt 21 for Term.\n",
      "2024-12-01 01:25:50 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:50 - INFO - Tokes used: CompletionUsage(completion_tokens=242, prompt_tokens=5112, total_tokens=5354, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:50 - INFO - Execution time for query_instruct_llm: 5.20 seconds\n",
      "2024-12-01 01:25:50 - INFO - Finished processing classification and templates prompt 21.\n",
      "2024-12-01 01:25:50 - INFO - Processing transformation prompt 22 for Term.\n",
      "2024-12-01 01:25:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:55 - INFO - Tokes used: CompletionUsage(completion_tokens=242, prompt_tokens=5112, total_tokens=5354, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:55 - INFO - Execution time for query_instruct_llm: 4.58 seconds\n",
      "2024-12-01 01:25:55 - INFO - Finished processing classification and templates prompt 22.\n",
      "2024-12-01 01:25:55 - INFO - Processing transformation prompt 23 for Term.\n",
      "2024-12-01 01:25:58 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:25:58 - INFO - Tokes used: CompletionUsage(completion_tokens=289, prompt_tokens=1892, total_tokens=2181, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:25:58 - INFO - Execution time for query_instruct_llm: 3.63 seconds\n",
      "2024-12-01 01:25:58 - INFO - Finished processing classification and templates prompt 23.\n",
      "2024-12-01 01:25:58 - INFO - Processing transformation prompt 24 for Term.\n",
      "2024-12-01 01:26:06 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:06 - INFO - Tokes used: CompletionUsage(completion_tokens=175, prompt_tokens=1911, total_tokens=2086, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:06 - INFO - Execution time for query_instruct_llm: 4.37 seconds\n",
      "2024-12-01 01:26:06 - INFO - Finished processing classification and templates prompt 24.\n",
      "2024-12-01 01:26:06 - INFO - Processing transformation prompt 25 for Term.\n",
      "2024-12-01 01:26:11 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:11 - INFO - Tokes used: CompletionUsage(completion_tokens=230, prompt_tokens=5102, total_tokens=5332, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:11 - INFO - Execution time for query_instruct_llm: 5.25 seconds\n",
      "2024-12-01 01:26:11 - INFO - Finished processing classification and templates prompt 25.\n",
      "2024-12-01 01:26:11 - INFO - Processing transformation prompt 26 for Term.\n",
      "2024-12-01 01:26:15 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:15 - INFO - Tokes used: CompletionUsage(completion_tokens=164, prompt_tokens=5079, total_tokens=5243, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:15 - INFO - Execution time for query_instruct_llm: 3.31 seconds\n",
      "2024-12-01 01:26:15 - INFO - Finished processing classification and templates prompt 26.\n",
      "2024-12-01 01:26:15 - INFO - Processing transformation prompt 27 for Term.\n",
      "2024-12-01 01:26:17 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:17 - INFO - Tokes used: CompletionUsage(completion_tokens=164, prompt_tokens=5073, total_tokens=5237, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:17 - INFO - Execution time for query_instruct_llm: 2.18 seconds\n",
      "2024-12-01 01:26:17 - INFO - Finished processing classification and templates prompt 27.\n",
      "2024-12-01 01:26:17 - INFO - Processing transformation prompt 28 for Term.\n",
      "2024-12-01 01:26:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:19 - INFO - Tokes used: CompletionUsage(completion_tokens=165, prompt_tokens=5073, total_tokens=5238, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:19 - INFO - Execution time for query_instruct_llm: 2.13 seconds\n",
      "2024-12-01 01:26:19 - INFO - Finished processing classification and templates prompt 28.\n",
      "2024-12-01 01:26:19 - INFO - Processing transformation prompt 29 for Term.\n",
      "2024-12-01 01:26:21 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:21 - INFO - Tokes used: CompletionUsage(completion_tokens=162, prompt_tokens=5073, total_tokens=5235, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:21 - INFO - Execution time for query_instruct_llm: 2.27 seconds\n",
      "2024-12-01 01:26:21 - INFO - Finished processing classification and templates prompt 29.\n",
      "2024-12-01 01:26:21 - INFO - Processing transformation prompt 30 for Term.\n",
      "2024-12-01 01:26:23 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:23 - INFO - Tokes used: CompletionUsage(completion_tokens=191, prompt_tokens=1844, total_tokens=2035, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:23 - INFO - Execution time for query_instruct_llm: 2.01 seconds\n",
      "2024-12-01 01:26:23 - INFO - Finished processing classification and templates prompt 30.\n",
      "2024-12-01 01:26:23 - INFO - Processing transformation prompt 31 for Term.\n",
      "2024-12-01 01:26:25 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:25 - INFO - Tokes used: CompletionUsage(completion_tokens=194, prompt_tokens=1953, total_tokens=2147, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:25 - INFO - Execution time for query_instruct_llm: 2.08 seconds\n",
      "2024-12-01 01:26:25 - INFO - Finished processing classification and templates prompt 31.\n",
      "2024-12-01 01:26:25 - INFO - Processing transformation prompt 32 for Term.\n",
      "2024-12-01 01:26:27 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:27 - INFO - Tokes used: CompletionUsage(completion_tokens=198, prompt_tokens=1934, total_tokens=2132, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:27 - INFO - Execution time for query_instruct_llm: 2.01 seconds\n",
      "2024-12-01 01:26:27 - INFO - Finished processing classification and templates prompt 32.\n",
      "2024-12-01 01:26:27 - INFO - Processing transformation prompt 33 for Term.\n",
      "2024-12-01 01:26:29 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:29 - INFO - Tokes used: CompletionUsage(completion_tokens=163, prompt_tokens=1925, total_tokens=2088, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:29 - INFO - Execution time for query_instruct_llm: 2.01 seconds\n",
      "2024-12-01 01:26:29 - INFO - Finished processing classification and templates prompt 33.\n",
      "2024-12-01 01:26:29 - INFO - Processing transformation prompt 34 for Term.\n",
      "2024-12-01 01:26:31 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:31 - INFO - Tokes used: CompletionUsage(completion_tokens=175, prompt_tokens=1928, total_tokens=2103, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:31 - INFO - Execution time for query_instruct_llm: 1.95 seconds\n",
      "2024-12-01 01:26:31 - INFO - Finished processing classification and templates prompt 34.\n",
      "2024-12-01 01:26:31 - INFO - Processing transformation prompt 35 for Term.\n",
      "2024-12-01 01:26:34 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:34 - INFO - Tokes used: CompletionUsage(completion_tokens=261, prompt_tokens=1967, total_tokens=2228, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:34 - INFO - Execution time for query_instruct_llm: 2.88 seconds\n",
      "2024-12-01 01:26:34 - INFO - Finished processing classification and templates prompt 35.\n",
      "2024-12-01 01:26:34 - INFO - Processing transformation prompt 36 for Term.\n",
      "2024-12-01 01:26:36 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:36 - INFO - Tokes used: CompletionUsage(completion_tokens=161, prompt_tokens=1816, total_tokens=1977, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:36 - INFO - Execution time for query_instruct_llm: 2.02 seconds\n",
      "2024-12-01 01:26:36 - INFO - Finished processing classification and templates prompt 36.\n",
      "2024-12-01 01:26:36 - INFO - Processing transformation prompt 37 for Term.\n",
      "2024-12-01 01:26:38 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:38 - INFO - Tokes used: CompletionUsage(completion_tokens=126, prompt_tokens=1810, total_tokens=1936, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:38 - INFO - Execution time for query_instruct_llm: 1.44 seconds\n",
      "2024-12-01 01:26:38 - INFO - Finished processing classification and templates prompt 37.\n",
      "2024-12-01 01:26:38 - INFO - Processing transformation prompt 38 for Term.\n",
      "2024-12-01 01:26:43 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:43 - INFO - Tokes used: CompletionUsage(completion_tokens=145, prompt_tokens=1811, total_tokens=1956, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:43 - INFO - Execution time for query_instruct_llm: 1.60 seconds\n",
      "2024-12-01 01:26:43 - INFO - Finished processing classification and templates prompt 38.\n",
      "2024-12-01 01:26:43 - INFO - Processing transformation prompt 39 for Term.\n",
      "2024-12-01 01:26:46 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:46 - INFO - Tokes used: CompletionUsage(completion_tokens=148, prompt_tokens=1811, total_tokens=1959, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:46 - INFO - Execution time for query_instruct_llm: 3.25 seconds\n",
      "2024-12-01 01:26:46 - INFO - Finished processing classification and templates prompt 39.\n",
      "2024-12-01 01:26:46 - INFO - Processing transformation prompt 40 for Term.\n",
      "2024-12-01 01:26:49 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:49 - INFO - Tokes used: CompletionUsage(completion_tokens=221, prompt_tokens=5096, total_tokens=5317, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:49 - INFO - Execution time for query_instruct_llm: 2.44 seconds\n",
      "2024-12-01 01:26:49 - INFO - Finished processing classification and templates prompt 40.\n",
      "2024-12-01 01:26:49 - INFO - Terms: 40\n",
      "2024-12-01 01:26:49 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:26:49 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_terms = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_terms,\n",
    "    system_prompts=system_prompts_terms,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_terms=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 4s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prompts for names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:26:49 - INFO - System prompts for Names: 3\n",
      "2024-12-01 01:26:49 - INFO - User prompts for Names: 3\n"
     ]
    }
   ],
   "source": [
    "system_prompts_names, user_prompts_names, element_name = get_prompts_for_rule(\n",
    "    rules=pred_names,\n",
    "    rule_template_formulation=rule_template_formulation,\n",
    "    data_dir=config[\"DEFAULT_DATA_DIR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a sample of the system prompt and user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:26:49 - INFO - System prompts for Names: 3\n",
      "2024-12-01 01:26:49 - INFO - User prompts for Names: 3\n",
      "2024-12-01 01:26:49 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:26:49 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "save_prompts_samples(\n",
    "    system_prompts_names, user_prompts_names, element_name, manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call LLM to transform names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:26:49 - INFO - Processing transformation prompt 1 for Name.\n",
      "2024-12-01 01:26:51 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:51 - INFO - Tokes used: CompletionUsage(completion_tokens=186, prompt_tokens=1829, total_tokens=2015, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:51 - INFO - Execution time for query_instruct_llm: 1.98 seconds\n",
      "2024-12-01 01:26:51 - INFO - Finished processing classification and templates prompt 1.\n",
      "2024-12-01 01:26:51 - INFO - Processing transformation prompt 2 for Name.\n",
      "2024-12-01 01:26:53 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:53 - INFO - Tokes used: CompletionUsage(completion_tokens=195, prompt_tokens=5071, total_tokens=5266, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:53 - INFO - Execution time for query_instruct_llm: 2.30 seconds\n",
      "2024-12-01 01:26:53 - INFO - Finished processing classification and templates prompt 2.\n",
      "2024-12-01 01:26:53 - INFO - Processing transformation prompt 3 for Name.\n",
      "2024-12-01 01:26:55 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-01 01:26:55 - INFO - Tokes used: CompletionUsage(completion_tokens=176, prompt_tokens=5068, total_tokens=5244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "2024-12-01 01:26:55 - INFO - Execution time for query_instruct_llm: 2.17 seconds\n",
      "2024-12-01 01:26:55 - INFO - Finished processing classification and templates prompt 3.\n",
      "2024-12-01 01:26:55 - INFO - Names: 3\n",
      "2024-12-01 01:26:55 - INFO - DocumentManager state persisted to file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:26:55 - INFO - Checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "responses_names = transform_statement(\n",
    "    element_name=element_name,\n",
    "    user_prompts=user_prompts_names,\n",
    "    system_prompts=system_prompts_names,\n",
    "    manager=manager,\n",
    ")\n",
    "\n",
    "logger.debug(f\"{responses_names=}\")\n",
    "\n",
    "# Persist the state to a file\n",
    "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average execution time 5s per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:26:56 - INFO - DocumentManager restored from file: ../data/checkpoints/documents-2024-12-01-1.json\n",
      "2024-12-01 01:26:56 - INFO - Checkpoint restored from ../data/checkpoints/documents-2024-12-01-1.json.\n"
     ]
    }
   ],
   "source": [
    "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate elements for missing transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 01:26:56 - WARNING - Validation document 'validation_judge_Operative_Rules' not found or empty.\n",
      "2024-12-01 01:26:56 - WARNING - Validation document 'validation_judge_Fact_Types' not found or empty.\n",
      "2024-12-01 01:26:56 - WARNING - Validation document 'validation_judge_Terms' not found or empty.\n",
      "2024-12-01 01:26:56 - WARNING - Validation document 'validation_judge_Names' not found or empty.\n",
      "2024-12-01 01:26:56 - INFO - Empty transformed pred_facts: 0/16\n",
      "2024-12-01 01:26:56 - INFO - Empty transformed pred_terms: 0/40\n",
      "2024-12-01 01:26:56 - INFO - Empty transformed pred_names: 0/3\n",
      "2024-12-01 01:26:56 - INFO - Empty transformed pred_operative_rules: 0/6\n"
     ]
    }
   ],
   "source": [
    "processor = DocumentProcessor(manager, merge=True)\n",
    "\n",
    "pred_operative_rules = processor.get_rules()\n",
    "pred_facts = processor.get_facts()\n",
    "pred_terms = processor.get_terms(definition_filter=\"non_null\")\n",
    "pred_names = processor.get_names(definition_filter=\"non_null\")\n",
    "\n",
    "logger.debug(f\"Rules: {pred_operative_rules}\")\n",
    "logger.debug(f\"Facts: {pred_facts}\")\n",
    "logger.debug(f\"Terms: {pred_terms}\")\n",
    "logger.debug(f\"Names: {pred_names}\")\n",
    "\n",
    "data = [pred_facts, pred_terms, pred_names, pred_operative_rules]\n",
    "data_names = [\"pred_facts\", \"pred_terms\", \"pred_names\", \"pred_operative_rules\"]\n",
    "\n",
    "for element_list, element_name in zip(data, data_names):\n",
    "    empty_transformed_elements = []\n",
    "    for element in element_list:\n",
    "        if not element.get(\"transformed\"):\n",
    "            logger.debug(f\"{element_name} - {element.get('statement_id')}: {element.get('transformed')}\")\n",
    "            empty_transformed_elements.append(element)\n",
    "\n",
    "    logger.info(f\"Empty transformed {element_name}: {len(empty_transformed_elements)}/{len(element_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "For the the first parte (prompt_classify_p1), the assigned confidence levels reflect a calibrated approach to expressions involving multiple classifications where a dominant rule type is not explicitly evident. For instance, when an expression primarily constrains data (Data rule) but also includes specific parties (Party rule), a high confidence level is attributed to Data while a moderate confidence level is applied to Party, acknowledging its secondary relevance.\n",
    "\n",
    "Similarly, expressions referencing roles such as “Secretary” or “interested person” without explicit party restrictions are assigned moderate confidence for Party classification due to interpretive ambiguity. Procedural elements that impact data handling, such as document forwarding, receive high confidence for Data rules; however, a moderate confidence level is assigned for Activity rules when procedural references are indirect. This methodology prioritizes primary rule types while accounting for the interpretive limits of secondary classifications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipt-cfr2sbvr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
