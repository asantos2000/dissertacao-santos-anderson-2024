{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asantos2000/master-degree-santos-anderson/blob/main/code/src/2_b_semantic_annotation-v2-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVnYd6SGNI4V"
      },
      "source": [
        "# 2.B. SEMANTIC ANNOTATION\n",
        "\n",
        "Google colab version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGvXmBtNPEr",
        "outputId": "7fe1cd7f-2431-4e25-d1ea-5dd118f64fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into 'cfr2sbvr'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Counting objects: 100% (281/281), done.\u001b[K\n",
            "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
            "remote: Total 281 (delta 147), reused 212 (delta 93), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (281/281), 9.35 MiB | 20.50 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "GITHUB_REPO = \"https://github.com/asantos2000/master-degree-santos-anderson.git\"  # You can set this with environment variables\n",
        "GITHUB_REPO_BRANCH = \"master\"\n",
        "GITHUB_REPO_CODE_DIR = \"code\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  # backup on Google Drive\n",
        "  # TODO: clone from git repo and change paths\n",
        "  !rm -rf cfr2sbvr\n",
        "  !git clone {GITHUB_REPO} cfr2sbvr\n",
        "  #%pip install -r cfr2sbvr/code/requirements.txt\n",
        "  !cp -r cfr2sbvr/code/src/configuration configuration\n",
        "  !cp -r cfr2sbvr/code/src/checkpoint checkpoint\n",
        "  !cp -r cfr2sbvr/code/config.colab.yaml config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnhg_V5jNI4W",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpxOMz7bNI4W"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import glob\n",
        "import yaml\n",
        "from collections import Counter, defaultdict\n",
        "from datetime import datetime\n",
        "from decimal import Decimal\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from logging.handlers import TimedRotatingFileHandler\n",
        "\n",
        "# Third-party libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pydantic import BaseModel, Field\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from typing import List, Dict, Optional, Any, Tuple, Set\n",
        "\n",
        "# OpenAI and instructor libraries\n",
        "from openai import OpenAI\n",
        "import instructor\n",
        "\n",
        "# Franz AllegroGraph (AG) imports\n",
        "from franz.openrdf.connect import ag_connect\n",
        "from franz.openrdf.repository.repository import Repository, RepositoryConnection\n",
        "from franz.openrdf.query.query import QueryLanguage\n",
        "from franz.openrdf.sail.allegrographserver import AllegroGraphServer, Catalog\n",
        "\n",
        "# inflect library\n",
        "import inflect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o40QEFwNI4X",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Settings\n",
        "\n",
        "Default settings, check them before run the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPwz2hfgNI4Y"
      },
      "source": [
        "### Get configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poARQdZINI4Y"
      },
      "outputs": [],
      "source": [
        "import configuration.main as configuration\n",
        "\n",
        "DEV_MODE = True\n",
        "\n",
        "if DEV_MODE:\n",
        "    # Development mode\n",
        "    import importlib\n",
        "    importlib.reload(configuration)\n",
        "\n",
        "# load config\n",
        "config = configuration.load_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZAWMXD8NI4Y"
      },
      "source": [
        "Generated files for analysis in this run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGmKVJ-tNI4Z",
        "outputId": "53ddd20a-e8c1-4e18-b70d-a4f7a66c13ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "../data/checkpoints/documents-2024-10-29-2.json ../outputs/extraction_report-2024-10-29-1.html ../outputs/compare_items_metrics.xlsx\n"
          ]
        }
      ],
      "source": [
        "print(config[\"DEFAULT_CHECKPOINT_FILE\"],\n",
        "config[\"DEFAULT_EXTRACTION_REPORT_FILE\"],\n",
        "config[\"DEFAULT_EXCEL_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_JfffhbNI4Z"
      },
      "source": [
        "### Logging configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7EGlTDLNI4Z",
        "outputId": "aff0b7cc-d09b-4de2-b986-4698899a2453"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 10:50:00 - INFO - Logging is set up with daily rotation.\n"
          ]
        }
      ],
      "source": [
        "# Ensure the ../logs directory exists\n",
        "log_directory = os.path.join(os.getcwd(), config[\"DEFAULT_LOG_DIR\"])\n",
        "os.makedirs(log_directory, exist_ok=True)\n",
        "\n",
        "# Path for the log file\n",
        "log_file_path = os.path.join(log_directory, 'application.log')\n",
        "\n",
        "# Set up TimedRotatingFileHandler to rotate logs every day\n",
        "file_handler = TimedRotatingFileHandler(\n",
        "    log_file_path, when=\"midnight\", interval=1, backupCount=0  # Rotate every midnight, keep all backups\n",
        ")\n",
        "\n",
        "# Set the file handler's log format\n",
        "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "# Set up logging configuration\n",
        "logging.basicConfig(\n",
        "    level=config[\"LOG_LEVEL\"],  # Set to the desired log level\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',  # Console log format\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',  # Custom date format\n",
        "    handlers=[\n",
        "        file_handler,  # Log to the rotating file in ../logs\n",
        "        logging.StreamHandler()  # Log to console\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Example logger\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Log a test message to verify\n",
        "logger.info(\"Logging is set up with daily rotation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IFcfyRmNI4a"
      },
      "source": [
        "## Checkpoints\n",
        "\n",
        "Documents, annoted datasets, statistics and metrics about the execution of the notebook are stored by checkpoint module.\n",
        "\n",
        "Checkpoints are stored / retrieved at the directory `DEFAULT_CHECKPOINT_FILE` in the configuration file.\n",
        "\n",
        "During the execution, it will restore the checkpoint at the beginning of the section and saved at the end. We can run and restore the checkpoint several times. If the run fails, check the closest checkpoint and restore it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQRUcc26NI4a"
      },
      "source": [
        "### Restore the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ258mrANI4b",
        "outputId": "564ca0f1-a6f6-4429-bbe5-54527f53eb68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:19:38 - ERROR - Checkpoint file '../data/checkpoints/documents-2024-10-29-2.json' not found or is empty, initializing new checkpoint.\n"
          ]
        }
      ],
      "source": [
        "import checkpoint.main as checkpoint\n",
        "from checkpoint.main import save_checkpoint, restore_checkpoint, Document\n",
        "\n",
        "if DEV_MODE:\n",
        "    # Development mode\n",
        "    import importlib\n",
        "    importlib.reload(checkpoint)\n",
        "\n",
        "# Restore the checkpoint\n",
        "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gALx00jLNI4b",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Datasets used in the notebook. They are divided into sections and true tables. The sections are the documents from CFR and true tables are annoted  or \"golden\" datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OyrGfTfNI4b"
      },
      "source": [
        "### General functions and data structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlDK6qNRNI4b"
      },
      "outputs": [],
      "source": [
        "def basic_text_stats(text: str) -> Tuple[int, int, int]:\n",
        "    \"\"\"\n",
        "    Computes basic text statistics: number of lines, words, and average words per line.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[int, int, int]: A tuple containing the number of lines, total words, and average words per line.\n",
        "    \"\"\"\n",
        "    lines=len(text.split(\"\\n\"))\n",
        "    words=len(text.split(\" \"))\n",
        "    avg_words_per_line=round(words/lines)\n",
        "    return lines, words, avg_words_per_line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmZ1HU7BNI4b"
      },
      "outputs": [],
      "source": [
        "def count_elements(data: Dict[str, Any]) -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Counts the occurrences of each entity by category and prints the counts.\n",
        "\n",
        "    Args:\n",
        "        data (dict): A dictionary containing the data to count.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the counts of each entity by category.\n",
        "    \"\"\"\n",
        "    facts_and_fact_types_count = len(data.get('facts_and_fact_types', []))\n",
        "\n",
        "    terms_count = 0\n",
        "    fact_symbols_count = 0\n",
        "\n",
        "    for fact in data.get('facts_and_fact_types', []):\n",
        "        # Count the terms in each fact\n",
        "        terms_count += len(fact.get('terms', []))\n",
        "\n",
        "        # Count the fact symbols in each fact\n",
        "        fact_symbols_count += len(fact.get('fact_symbols', []))\n",
        "\n",
        "    return {\n",
        "        'facts_and_fact_types_count': facts_and_fact_types_count,\n",
        "        'terms_count': terms_count,\n",
        "        'fact_symbols_count': fact_symbols_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlWfWuxrNI4b"
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each entity by category\n",
        "def count_entities(source_list: List[Dict[str, Any]], group_by: str) -> Counter:\n",
        "    \"\"\"\n",
        "    Counts the occurrences of each entity by category and prints the counts.\n",
        "\n",
        "    Args:\n",
        "        true_table (List[Dict[str, Any]]): A list of dictionaries representing entities.\n",
        "\n",
        "    Returns:\n",
        "        Counter: A dictionary containing the counts of each entity by category.\n",
        "    \"\"\"\n",
        "    type_counts = Counter(item[group_by] for item in source_list)\n",
        "\n",
        "    return type_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCXYiYZrNI4b"
      },
      "outputs": [],
      "source": [
        "def get_section_from_kg(conn: Any, section_num: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves a section from the Knowledge Graph based on the section number.\n",
        "\n",
        "    Args:\n",
        "        conn: The connection object to the Knowledge Graph.\n",
        "        section_num (str): The section number to query.\n",
        "\n",
        "    Returns:\n",
        "        str: The retrieved section content as a string.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error executing the query.\n",
        "    \"\"\"\n",
        "    # Query section number from KG\n",
        "    query = \"\"\"\n",
        "    PREFIX fro-cfr: <http://finregont.com/fro/cfr/Code_Federal_Regulations.ttl#>\n",
        "    PREFIX fro-leg-ref: <http://finregont.com/fro/ref/LegalReference.ttl#>\n",
        "\n",
        "    SELECT ?section ?section_seq ?section_num ?section_subject ?section_citation ?section_notes ?divide ?divide_seq ?paragraph_enum ?paragraph_text\n",
        "    WHERE {\n",
        "      ?section a fro-cfr:CFR_Section ;\n",
        "        fro-leg-ref:hasSequenceNumber ?section_seq ;\n",
        "        fro-cfr:hasSectionNumber ?section_num ;\n",
        "        fro-cfr:hasSectionSubject ?section_subject .\n",
        "      OPTIONAL {?section fro-leg-ref:refers_toNote ?section_notes} .\n",
        "      OPTIONAL {?section fro-cfr:hasSectionCitation ?section_citation} .\n",
        "\n",
        "      ?divide fro-leg-ref:divides ?section ; # rdf:type fro-cfr:CFR_Parapraph\n",
        "        fro-leg-ref:hasSequenceNumber ?divide_seq ;\n",
        "        fro-cfr:hasParagraphText ?paragraph_text ;\n",
        "        fro-leg-ref:hasSequenceNumber ?paragraph_seq .\n",
        "      OPTIONAL {?divide fro-cfr:hasParagraphEnumText ?paragraph_enum} .\n",
        "    \"\"\" + f\"\"\"\n",
        "      FILTER(\"{section_num}\" = ?section_num)\n",
        "    \"\"\" + \"\"\"\n",
        "    }\n",
        "    ORDER BY ?section_num ?section ?divide_seq\n",
        "    \"\"\"\n",
        "    tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query)\n",
        "    result = tuple_query.evaluate()\n",
        "\n",
        "    logger.debug(f\"result.metadata: {result.metadata}\")\n",
        "    logger.debug(f\"result.variable_names: {result.variable_names}\")\n",
        "\n",
        "    body_text = \"\"\n",
        "    previous_section = None\n",
        "    previous_paragraph_id = None\n",
        "    with result:\n",
        "      for binding_set in result:\n",
        "          section = binding_set.getValue(\"section\")\n",
        "          section_seq = str(binding_set.getValue(\"section_seq\")).replace('\"', '')\n",
        "          section_num = str(binding_set.getValue(\"section_num\")).replace('\"', '')\n",
        "          section_subject = str(binding_set.getValue(\"section_subject\")).replace('\"', '')\n",
        "          section_citation = str(binding_set.getValue(\"section_citation\")).replace('\"', '')\n",
        "          section_notes = str(binding_set.getValue(\"section_notes\")).replace('\"', '')\n",
        "          divide = binding_set.getValue(\"divide\")\n",
        "          divide_seq = str(binding_set.getValue(\"divide_seq\")).replace('\"', '')\n",
        "          paragraph_enum = str(binding_set.getValue(\"paragraph_enum\")).replace('\"', '')\n",
        "          paragraph_text = str(binding_set.getValue(\"paragraph_text\")).replace('\"', '')\n",
        "          # Header\n",
        "          if previous_section != section:\n",
        "            previous_section = section\n",
        "            header = f\"\"\"\n",
        "    section_number: {section_num}\n",
        "    section_subject: {section_subject}\n",
        "    section_id: {section}\n",
        "    citations: {section_citation}\n",
        "    notes: {section_notes}\n",
        "            \"\"\"\n",
        "          # Body\n",
        "          if paragraph_enum != \"None\":\n",
        "            body_text += f\"\"\"\n",
        "    paragraph_enumeration: {paragraph_enum}\n",
        "    paragraph_text: {paragraph_text}\n",
        "    \"\"\"\n",
        "          else:\n",
        "            body_text += f\"\"\"\n",
        "    paragraph_text: {paragraph_text}\n",
        "    \"\"\"\n",
        "\n",
        "    return header + body_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEwWX_bxNI4c"
      },
      "outputs": [],
      "source": [
        "def calculate_content_quantities_p1(doc_id, content_data, filename):\n",
        "    elements = content_data.get(\"elements\", [])\n",
        "    logger.debug(elements)\n",
        "\n",
        "    # Collect statistics\n",
        "    num_elements = len(elements)\n",
        "    fact_count = 0\n",
        "    fact_type_count = 0\n",
        "    rule_count = 0\n",
        "    verb_count = 0\n",
        "    term_count = 0\n",
        "\n",
        "    # Process each element within the document\n",
        "    for element in elements:\n",
        "        classification = element.get(\"classification\", \"Unknown\")\n",
        "        if classification == \"Fact\":\n",
        "            fact_count += 1\n",
        "        elif classification == \"Fact Type\":\n",
        "            fact_type_count += 1\n",
        "        elif classification == \"Rule\":\n",
        "            rule_count += 1\n",
        "        verb_count += len(element.get(\"verb_symbols\", []))\n",
        "        term_count += len(element.get(\"terms\", []))\n",
        "\n",
        "    return {\n",
        "        \"document_id\": doc_id,\n",
        "        \"quantity_of_elements\": num_elements,\n",
        "        \"quantity_of_facts\": fact_count,\n",
        "        \"quantity_of_fact_types\": fact_type_count,\n",
        "        \"quantity_of_rules\": rule_count,\n",
        "        \"quantity_of_verbs\": verb_count,\n",
        "        \"quantity_of_terms\": term_count,\n",
        "        \"filename\": filename,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEKkXpNKNI4c"
      },
      "outputs": [],
      "source": [
        "def process_documents_p1(file_path, file_name, doc_ids):\n",
        "    # Initialize data containers for the two tables\n",
        "    table_data = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = json.load(file)\n",
        "\n",
        "        # Iterate over each document in the file\n",
        "        for doc_id, content_data in content.items():\n",
        "            logger.debug(doc_id, content_data)\n",
        "            # Check if the document ID is in the list to process\n",
        "            #if doc_id in doc_ids and 'content' in doc_data:\n",
        "            if all([doc_id in doc_ids, 'content' in content_data]):\n",
        "                table_data.append(calculate_content_quantities_p1(doc_id, content_data['content'], file_name))\n",
        "\n",
        "    return table_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90cdkf-ANI4c"
      },
      "outputs": [],
      "source": [
        "def calculate_content_quantities_p2(doc_id, content_data, filename):\n",
        "    terms_relationship = content_data['content'].get('terms_relationship', [])\n",
        "    logger.debug(f\"terms_relationship: {terms_relationship}\")\n",
        "    terms = content_data['content']['terms']\n",
        "    logger.debug(f\"terms: {terms}\")\n",
        "\n",
        "    # Count terms with and without definitions\n",
        "    total_terms = len(terms)\n",
        "    terms_with_definition = sum(1 for term in terms if term.get('definition'))\n",
        "    terms_without_definition = total_terms - terms_with_definition\n",
        "\n",
        "    # Check for term relationships and count them\n",
        "    terms_relationship_count = len(terms_relationship)\n",
        "\n",
        "    # Add data to table\n",
        "    return {\n",
        "        \"document_id\": doc_id,\n",
        "        \"count_of_terms\": total_terms,\n",
        "        \"terms_with_definition\": terms_with_definition,\n",
        "        \"terms_without_definition\": terms_without_definition,\n",
        "        \"terms_relationship_count\": terms_relationship_count,\n",
        "        \"filename\": filename\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb8ryFISNI4c"
      },
      "outputs": [],
      "source": [
        "def process_documents_p2(file_path, file_name, doc_ids):\n",
        "    table_data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = json.load(file)\n",
        "\n",
        "        # Iterate over each document in the file\n",
        "        for doc_id, doc_data in content.items():\n",
        "            # Check if the document has terms in its content\n",
        "            #if doc_id in doc_ids and 'content' in doc_data and 'terms' in doc_data['content']:\n",
        "            if all([doc_id in doc_ids, 'content' in doc_data, 'terms' in doc_data['content']]):\n",
        "                table_data.append(calculate_content_quantities_p2(doc_id, doc_data, file_name))\n",
        "    return table_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvKeXU_nNI4c"
      },
      "source": [
        "### Get section from KG CFR\n",
        "Due the mistakes in the original dataset, we need to correct it. This function will not be used in the final version. Instead we will use variables (document_02, document_05, document_07) from the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5CU46gMX2iT"
      },
      "source": [
        "#### Access allegrograph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ASvEzrCNI4c"
      },
      "outputs": [],
      "source": [
        "# conn = ag_connect(repo=config[\"ALLEGROGRAPH\"][\"REPO\"], catalog=config[\"ALLEGROGRAPH\"][\"CATALOG\"],\n",
        "#                 host=f'https://{config[\"ALLEGROGRAPH\"][\"HOST\"]}:443',\n",
        "#                 user=config[\"ALLEGROGRAPH\"][\"USER\"], password=config[\"ALLEGROGRAPH\"][\"PASSWORD\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8VJE-OUNI4d"
      },
      "outputs": [],
      "source": [
        "# section_num = \"§ 275.0-7\"\n",
        "# logger.info(get_section_from_kg(conn, section_num=section_num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceYxxUXvNI4d"
      },
      "source": [
        "Print results formatted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHXBH5tgNI4d"
      },
      "outputs": [],
      "source": [
        "# conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrNkrFANI4d"
      },
      "source": [
        "### Texts to extract the elements\n",
        "\n",
        "CFR Sections 275.0-2, 275.0-5, 275.0-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQmuCjb0NI4d"
      },
      "source": [
        "Section 275.0-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo_Bj9twNI4g"
      },
      "outputs": [],
      "source": [
        "manager.add_document(\n",
        "    Document(\n",
        "        id=\"§ 275.0-2\",\n",
        "        type=\"section\",\n",
        "content = \"\"\"\n",
        "§ 275.0-2 General procedures for serving non-residents.\n",
        "(a) General procedures for serving process, pleadings, or other papers on non-resident investment advisers, general partners and managing agents.  Under Forms ADV and ADV-NR [17 CFR 279.1 and 279.4], a person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents:\n",
        "  (1) A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\n",
        "  (2) If process, pleadings, or other papers are served on the Commission as described in this section, the Secretary of the Commission (Secretary) will promptly forward a copy to each named party by registered or certified mail at that party's last address filed with the Commission.\n",
        "  (3) If the Secretary certifies that the Commission was served with process, pleadings, or other papers pursuant to paragraph (a)(1) of this section and forwarded these documents to a named party pursuant to paragraph (a)(2) of this section, this certification constitutes evidence of service upon that party.\n",
        "(b) Definitions.  For purposes of this section:\n",
        "  (1) Managing agent  means any person, including a trustee, who directs or manages, or who participates in directing or managing, the affairs of any unincorporated organization or association other than a partnership.\n",
        "  (2) Non-resident  means:\n",
        "    (i) An individual who resides in any place not subject to the jurisdiction of the United States;\n",
        "    (ii) A corporation that is incorporated in or that has its principal office and place of business in any place not subject to the jurisdiction of the United States; and\n",
        "    (iii) A partnership or other unincorporated organization or association that has its principal office and place of business in any place not subject to the jurisdiction of the United States.\n",
        "  (3) Principal office and place of business  has the same meaning as in § 275.203A-3(c) of this chapter.\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af-8pbqZNI4h"
      },
      "source": [
        "Section 275.0-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi0KFeInNI4h"
      },
      "outputs": [],
      "source": [
        "manager.add_document(\n",
        "    Document(\n",
        "        id=\"§ 275.0-5\",\n",
        "        type=\"section\",\n",
        "content = \"\"\"\n",
        "§ 275.0-5 Procedure with respect to applications and other matters.\n",
        "The procedure hereinbelow set forth will be followed with respect to any proceeding initiated by the filing of an application, or upon the Commission's own motion, pursuant to any section of the Act or any rule or regulation thereunder, unless in the particular case a different procedure is provided:\n",
        "(a) Notice of the initiation of the proceeding will be published in the Federal Register and will indicate the earliest date upon which an order disposing of the matter may be entered. The notice will also provide that any interested person may, within the period of time specified therein, submit to the Commission in writing any facts bearing upon the desirability of a hearing on the matter and may request that a hearing be held, stating his reasons therefor and the nature of his interest in the matter.\n",
        "(b) An order disposing of the matter will be issued as of course following the expiration of the period of time referred to in paragraph (a) of this section, unless the Commission thereafter orders a hearing on the matter.\n",
        "(c) The Commission will order a hearing on the matter, if it appears that a hearing is necessary or appropriate in the public interest or for the protection of investors,\n",
        "  (1) upon the request of any interested person or\n",
        "  (2) upon its own motion.\n",
        "(d) Definition of application. For purposes of this rule, an “application” means any application for an order of the Commission under the Act other than an application for registration as an investment adviser.\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vX5oYs2NI4h"
      },
      "source": [
        "Section 275.0-7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnc4fHe8NI4h"
      },
      "outputs": [],
      "source": [
        "manager.add_document(\n",
        "    Document(\n",
        "        id=\"§ 275.0-7\",\n",
        "        type=\"section\",\n",
        "content = \"\"\"\n",
        "§ 275.0-7 Small entities under the Investment Advisers Act for purposes of the Regulatory Flexibility Act.\n",
        "(a) For purposes of Commission rulemaking in accordance with the provisions of Chapter Six of the Administrative Procedure Act (5 U.S.C. 601 et seq.) and unless otherwise defined for purposes of a particular rulemaking proceeding, the term small business or small organization for purposes of the Investment Advisers Act of 1940 shall mean an investment adviser that:\n",
        "  (1) Has assets under management, as defined under Section 203A(a)(3) of the Act (15 U.S.C. 80b-3a(a)(2)) and reported on its annual updating amendment to Form ADV (17 CFR 279.1), of less than $25 million, or such higher amount as the Commission may by rule deem appropriate under Section 203A(a)(1)(A) of the Act (15 U.S.C. 80b-3a(a)(1)(A));\n",
        "  (2) Did not have total assets of $5 million or more on the last day of the most recent fiscal year; and\n",
        "  (3) Does not control, is not controlled by, and is not under common control with another investment adviser that has assets under management of $25 million or more (or such higher amount as the Commission may deem appropriate), or any person (other than a natural person) that had total assets of $5 million or more on the last day of the most recent fiscal year.\n",
        "(b) For purposes of this section:\n",
        "  (1) Control  means the power, directly or indirectly, to direct the management or policies of a person, whether through ownership of securities, by contract, or otherwise.\n",
        "    (i) A person is presumed to control a corporation if the person:\n",
        "      (A) Directly or indirectly has the right to vote 25 percent or more of a class of the corporation's voting securities; or\n",
        "      (B) Has the power to sell or direct the sale of 25 percent or more of a class of the corporation's voting securities.\n",
        "    (ii) A person is presumed to control a partnership if the person has the right to receive upon dissolution, or has contributed, 25 percent or more of the capital of the partnership.\n",
        "    (iii) A person is presumed to control a limited liability company (LLC) if the person:\n",
        "      (A) Directly or indirectly has the right to vote 25 percent or more of a class of the interests of the LLC;\n",
        "      (B) Has the right to receive upon dissolution, or has contributed, 25 percent or more of the capital of the LLC; or\n",
        "      (C) Is an elected manager of the LLC.\n",
        "    (iv) A person is presumed to control a trust if the person is a trustee or managing agent of the trust.\n",
        "  (2) Total assets  means the total assets as shown on the balance sheet of the investment adviser or other person described above under paragraph (a)(3) of this section, or the balance sheet of the investment adviser or such other person with its subsidiaries consolidated, whichever is larger.\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RikOqvzYNI4h"
      },
      "source": [
        "### True tables\n",
        "\n",
        "True tables are annotated or \"golden\" datasets in which entities have been manually identified and labeled within the original source data.\n",
        "\n",
        "True tables for sectiona 275.0-2, 275.0-5 and 275.0-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR_dlFGQNI4h"
      },
      "source": [
        "Load true table for part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb7Vmh0ENI4h"
      },
      "outputs": [],
      "source": [
        "with open(f\"{config['DEFAULT_DATA_DIR']}/p1_true_table.json\", 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-2_P1|true_table\"])\n",
        "    )\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-5_P1|true_table\"])\n",
        "    )\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-7_P1|true_table\"])\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbTcCzJ2NI4h"
      },
      "source": [
        "Load true table for part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qb0s6-ZNI4i"
      },
      "outputs": [],
      "source": [
        "with open(f\"{config['DEFAULT_DATA_DIR']}/p2_true_table.json\", 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-2_P2|true_table\"])\n",
        "    )\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-5_P2|true_table\"])\n",
        "    )\n",
        "\n",
        "    manager.add_document(\n",
        "        Document.model_validate(data[\"§ 275.0-7_P2|true_table\"])\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CRLRlXnZIlh"
      },
      "source": [
        "### Elements classification taxonomy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvkcERkycT8x"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyfJg2GdcyJ7"
      },
      "outputs": [],
      "source": [
        "system_prompt_taxonomy_classification = \"\"\"\n",
        "Classify each element using the provided taxonomy. Use the example of the class to help you.\n",
        "\n",
        "Answer adding taxonomy classification to each element in the following format:\n",
        "\n",
        "\n",
        "elements:\n",
        "  - doc_id: § 275.0-2_P1\n",
        "    - id: 1\n",
        "      expression: \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\"\n",
        "      template_id: T7\n",
        "      template: |\n",
        "      {A|An|The|} <definitional rule statement subject>\n",
        "      {<qualifying clause>|}\n",
        "      <verb phrase> by definition\n",
        "      <definition>\n",
        "      classification\": Formal intensional definitions\n",
        "    - id: 2\n",
        "      expression: \"A person may serve a non-resident investment adviser, non-resident general partner, or non-resident managing agent by furnishing the Commission with one copy of the process, pleadings, or papers, for each named party, and one additional copy for the Commission's records.\"\n",
        "      template_id: T8\n",
        "      template: |\n",
        "      {A|An|The|} <definitional rule statement subject>\n",
        "      {<qualifying clause>|}\n",
        "      <verb phrase> by definition\n",
        "      <definition>\n",
        "      classification\": Formal extensional definitions\n",
        "  - doc_id: § 275.0-5_P1\n",
        "    - id: 1\n",
        "      expression: \"An order disposing of the matter will be issued as of course following the expiration of the period of time referred to in paragraph (a) of this section, unless the Commission thereafter orders a hearing on the matter.\"\n",
        "      template_id: T9\n",
        "      template: |\n",
        "      {A|An|The|} <definitional rule statement subject>\n",
        "      {<qualifying clause>|}\n",
        "      <verb phrase> by definition\n",
        "      <definition>\n",
        "      classification\": Formal extensional definitions\n",
        "    ...\n",
        "  ...\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLrODvDzmKbX"
      },
      "outputs": [],
      "source": [
        "example = {\n",
        "  \"§ 275.0-2_P1\": {\n",
        "    \"id\": \"§ 275.0-2_P1\",\n",
        "    \"type\": \"section\",\n",
        "    \"elements\": {\n",
        "      \"fact_types\": [\n",
        "        {\n",
        "          \"id\": 1,\n",
        "          \"expression\": \"A person may serve process, pleadings, or other papers on a non-resident investment adviser, or on a non-resident general partner or non-resident managing agent of an investment adviser by serving any or all of its appointed agents.\",\n",
        "          \"template_id\": \"T7\",\n",
        "          \"template\": \"{A|An|The|} <definitional rule statement subject> {<qualifying clause>|} <verb phrase> by definition <definition>\",\n",
        "          \"classification\": \"Formal intensional definitions\"\n",
        "        }\n",
        "      ],\n",
        "      \"rules\": [],\n",
        "      \"terms\": []\n",
        "    }\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TEs8gH5ZR4B",
        "outputId": "414c9239-1fa8-4bb8-a941-0741b5f60dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'section_id': '9.2', 'section_title': 'Definitional rules', 'section_definition': 'Definitional rules constrains how we define a construct created or used by the organization or the industry within which it operates. Definitional rules can in turn be categorized as:', 'subsections': [{'section_id': '9.2.1', 'section_title': 'Formal term definitions', 'section_definition': 'A formal term definition defines a particular business term in a formal manner. They are categorized as:', 'subsections': [{'section_id': '9.2.1.1', 'section_title': 'Formal intensional definitions', 'section_definition': 'A formal intensional definition defines the subject business term using an intensional definition: one that cites both a hypernym (a term that refers to a superset of the set referred to by the original term) and the characteristics that distinguish members of the set referred to by the original term.', 'templates': ['T7']}, {'section_id': '9.2.1.2', 'section_title': 'Formal extensional definitions', 'section_definition': 'Formal extensional definition defines the subject business term by using an extensional definition: one that lists a complete set of hyponyms (terms that refer to subsets of the set referred to by the original term).', 'templates': ['T8']}, {'section_id': '9.2.1.3', 'section_title': 'Symbolic literal definitions', 'section_definition': 'A symbolic literal definition defines the subject business term using one or more literals.', 'templates': ['T9']}]}, {'section_id': '9.2.2', 'section_title': 'Categorization scheme enumerations', 'section_definition': 'A categorization scheme enumeration defines the members of a categorization scheme that is both mutually exclusive and jointly exhaustive.', 'templates': ['T10']}, {'section_id': '9.2.3', 'section_title': 'Category transition constraints', 'section_definition': 'A category transition constraint specifies allowed or disallowed transitions between categories or statuses.', 'templates': ['T11']}, {'section_id': '9.2.4', 'section_title': 'Complex concept structure rules', 'section_definition': 'A complex concept structure rule defines a particular constraint on one or more components of a complex concept. They are categorized as:', 'subsections': [{'section_id': '9.2.4.1', 'section_title': 'Complex concept cardinality rules', 'section_definition': 'A complex concept cardinality rule defines the number of (or minimum and/or maximum number of) components of a particular type within a particular concept.', 'templates': ['T12']}, {'section_id': '9.2.4.2', 'section_title': 'Complex concept equivalence rules', 'section_definition': 'A complex concept equivalence rule defines a pair of components within a particular concept that are of necessity the same.', 'templates': ['T13']}, {'section_id': '9.2.4.3', 'section_title': 'Complex concept set constraints', 'section_definition': 'A complex concept set constraint defines two sets of components within a particular concept that must be identical.', 'templates': ['T14']}]}, {'section_id': '9.2.5', 'section_title': 'Valid value definitions', 'section_definition': 'A valid value definition defines the valid values of a particular measure as a range or (occasionally) as a list of discrete values.', 'templates': ['T15']}, {'section_id': '9.2.6', 'section_title': 'Data calculation rules', 'section_definition': 'A data calculation rule defines the algorithm or formula for a particular quantity or a conversion factor between two units. They are categorized as:', 'subsections': [{'section_id': '9.2.6.1', 'section_title': 'Data calculation algorithms', 'section_definition': 'A data calculation algorithm defines how a particular quantity or amount (whether for operational purposes, such as a fee, or for business intelligence purposes, such as a performance measure) is calculated.', 'templates': ['T16']}, {'section_id': '9.2.6.2', 'section_title': 'Conversion factor definitions', 'section_definition': 'A conversion factor definition defines a conversion factor between two units of measurement.', 'templates': ['T17']}]}, {'section_id': '9.2.7', 'section_title': 'Standard format definitions', 'section_definition': 'A standard format definition defines the standard format for data items of a particular type in terms of individual characters and/or component data items.', 'templates': ['T18']}]}, {'section_id': '9.3', 'section_title': 'Data rules', 'section_definition': 'Data rules (all of which are operative rules) constrains the data included in a transaction (a form or message) or a persistent dataset (e.g., a database record). Data rules can in turn be categorized as:', 'subsections': [{'section_id': '9.3.1', 'section_title': 'Data cardinality rules', 'section_definition': 'A data cardinality rule requires the presence or absence of a data item and/or places a restriction on the maximum or minimum number of occurrences of a data item', 'subsections': [{'section_id': '9.3.1.1', 'section_title': 'Mandatory data rules', 'section_definition': 'A mandatory data rule mandates the presence of data:', 'subsections': [{'section_id': '9.3.1.1.1', 'section_title': 'Mandatory data item rules', 'section_definition': 'A mandatory data item rule requires that a particular data item be present.', 'templates': ['T19']}, {'section_id': '9.3.1.1.2', 'section_title': 'Mandatory option selection rules', 'section_definition': 'A mandatory option selection rule requires that one of a set of pre-defined options be specified. Use T20 for multiple options, and T21 for a single option.', 'templates': ['T20', 'T21']}, {'section_id': '9.3.1.1.3', 'section_title': 'Mandatory group rules', 'section_definition': 'A mandatory group rule requires that at least one of a group of data items be present. Use T22 for two data items, and T23 for more than two data items.', 'templates': ['T22', 'T23']}]}, {'section_id': '9.3.1.2', 'section_title': 'Prohibited data rules', 'section_definition': 'A prohibited data rule mandates the absence of some data item in a particular situation.', 'templates': ['T24']}, {'section_id': '9.3.1.3', 'section_title': 'Maximum cardinality rules', 'section_definition': 'A maximum cardinality rule places an upper limit (usually but not necessarily one) on how many instances of a particular data item there may be.', 'templates': ['T25']}, {'section_id': '9.3.1.4', 'section_title': 'Multiple data rules', 'section_definition': 'A multiple data rule mandates the presence of two or more instances of a particular data item in a particular situation. These rule statements `<cardinality>` may only take one of the following forms: 1. exactly `<positive integer>`, where `<positive integer>` is at least two; 2. at least `<positive integer>`, where `<positive integer>` is at least two; 3. at least `<positive integer 1>` and at most `<positive integer 2>`, where `<positive integer 1>` is at least two.', 'templates': ['19']}, {'section_id': '9.3.1.5', 'section_title': 'Dependent cardinality rules', 'section_definition': 'A dependent cardinality rule mandates how many of a particular data item must be present based on the value of another data item.', 'templates': ['T26']}]}, {'section_id': '9.3.2', 'section_title': 'Data content rules', 'section_definition': 'A data content rule places a restriction on the values contained in a data item or set of data items (rather than whether they must be present and how many there may or must be).', 'subsections': [{'section_id': '9.3.2.1', 'section_title': 'Value set rules', 'section_definition': 'A value set rule requires either: that the content of a data item be (or not be) one of a particular set of values (either a fixed set, or a set that may change over time), or; that the content of a combination of data items match or not match a corresponding combination in a set of records;', 'subsections': [{'section_id': '9.3.2.1.1', 'section_title': 'Value set rules constraining single data items', 'section_definition': '', 'templates': ['T27']}, {'section_id': '9.3.2.1.2', 'section_title': 'Value set rules constraining combinations of data items', 'section_definition': '', 'templates': ['T28']}]}, {'section_id': '9.3.2.2', 'section_title': 'Range rules', 'section_definition': 'A range rule requires that the content of a data item be a value within a particular inclusive or exclusive single-bounded or double-bounded range.', 'templates': ['T29']}, {'section_id': '9.3.2.3', 'section_title': 'Equality rules', 'section_definition': 'An equality rule requires that the content of a data item be the same as or not the same as that of some other data item.', 'templates': ['T30']}, {'section_id': '9.3.2.4', 'section_title': 'Uniqueness constraints', 'section_definition': 'AA uniqueness constraint requires that the content of a data item (or combination or set of data items) be different from that of the corresponding data item(s) in the same or other records or transactions;', 'subsections': [{'section_id': '9.3.2.4.1', 'section_title': 'Uniqueness constraints constraining single data items', 'section_definition': '', 'templates': ['T31']}, {'section_id': '9.3.2.4.2', 'section_title': 'Uniqueness constraints constraining combinations of data items', 'section_definition': '', 'templates': ['T32']}, {'section_id': '9.3.2.4.3', 'section_title': 'Uniqueness constraints constraining sets of data items', 'section_definition': '', 'templates': ['T33']}]}, {'section_id': '9.3.2.5', 'section_title': 'Data consistency rules', 'section_definition': 'A data consistency rule requires the content of multiple data items to be consistent with each other, other than as provided for by a value set rule, range rule, or equality rule;', 'subsections': [{'section_id': '9.3.2.5.1', 'section_title': 'Data consistency rules constraining a combination of data items', 'section_definition': '', 'templates': ['T34']}, {'section_id': '9.3.2.5.2', 'section_title': 'Data consistency rules constraining a set function', 'section_definition': '', 'templates': ['T35']}, {'section_id': '9.3.2.5.3', 'section_title': 'Data consistency rules constraining a set', 'section_definition': '', 'templates': ['T36']}]}, {'section_id': '9.3.2.6', 'section_title': 'Temporal data constraints', 'section_definition': 'A temporal data constraint constrains one or more temporal data items (data items that represent time points or time periods). There are various subcategories of temporal constraint:', 'subsections': [{'section_id': '9.3.2.6.1', 'section_title': 'Simple temporal data constraints', 'section_definition': 'A simple temporal data constraint requires that a particular date or time fall within a certain temporal range.', 'templates': ['T29'], 'examples': ['R373']}, {'section_id': '9.3.2.6.2', 'section_title': 'Temporal data non-overlap constraints', 'section_definition': 'Temporal data non-overlap constraint requires that the time periods specified in a set of records do not overlap each other.', 'templates': ['T37']}, {'section_id': '9.3.2.6.3', 'section_title': 'Temporal data completeness constraints', 'section_definition': 'A temporal data completeness constraint requires that the time periods specified in a set of records be contiguous and between them completely span some other time period.', 'templates': ['T38']}, {'section_id': '9.3.2.6.4', 'section_title': 'Temporal data inclusion constraints', 'section_definition': 'AA temporal data inclusion constraint requires that the time periods specified in a set of records do not fall outside some other time period.', 'templates': ['T38']}, {'section_id': '9.3.2.6.5', 'section_title': 'Temporal single record constraints', 'section_definition': 'A temporal single record constraint requires that a temporal state of affairs be recorded using a single record rather than multiple records. Use T39 for single data item and T40 for combination of data items.', 'templates': ['T39', 'T40']}, {'section_id': '9.3.2.6.6', 'section_title': 'Day type constraints', 'section_definition': 'A day type constraint restricts a date to one or more days of the week or a particular type of day such as a working day (typically but not necessarily any day other than a Saturday, Sunday, or public holiday).', 'templates': ['T41']}]}, {'section_id': '9.3.2.7', 'section_title': 'Spatial data constraints', 'section_definition': 'A spatial data constraint prescribes or prohibits relationships between data items representing spatial properties (points, line segments or polygons).', 'templates': ['T41']}, {'section_id': '9.3.2.8', 'section_title': 'Data item format rules', 'section_definition': 'A data item format rule specifies the required format of a data item.', 'templates': ['T43']}]}, {'section_id': '9.3.3', 'section_title': 'Data update rules', 'section_definition': 'A data update rule either prohibits update of a data item or places restrictions on the new value of a data item in terms of its existing value. There are three subcategories of data update rule:', 'subsections': [{'section_id': '9.3.3.1', 'section_title': 'Data update prohibition rules', 'section_definition': 'A data update prohibition rule prohibits update of a particular data item or set of data items. Use T44 for non-transferable relationships and T45 for other data update.', 'templates': ['T44', 'T45']}, {'section_id': '9.3.3.2', 'section_title': 'State transition constraints', 'section_definition': 'A state transition constraint limits the changes in a data item to a set of valid transitions.', 'templates': ['T46']}, {'section_id': '9.3.3.3', 'section_title': 'Monotonic transition constraints', 'section_definition': 'A monotonic transition constraint requires that a numeric value either only increase or only decrease.', 'templates': ['T47']}]}]}, {'section_id': '9.4', 'section_title': 'Activity rules', 'section_definition': 'Activity rules (all of which are operative rules) constrains the operation of one or more business processes or other activities. Activity rules can in turn be categorized as:', 'subsections': [{'section_id': '9.4.1', 'section_title': 'Activity restriction rules', 'section_definition': 'An activity restriction rule restricts a business process or other activity in some way. There are various subcategories of activity restriction rules:', 'subsections': [{'section_id': '9.4.1.1', 'section_title': 'Rules restricting when an activity can occur', 'section_definition': 'Many activity restriction rules place time restrictions on activities.', 'subsections': [{'section_id': '9.4.1.1.1', 'section_title': 'Activity time limit rules', 'section_definition': 'An activity time limit rule restricts a business process or other activity to within a particular time period.', 'templates': ['T48']}, {'section_id': '9.4.1.1.2', 'section_title': 'Activity exclusion period rules', 'section_definition': 'An activity exclusion period rule prohibits a business process or other activity during a particular time period.', 'templates': ['T49']}, {'section_id': '9.4.1.1.3', 'section_title': 'Activity obligation rule', 'section_definition': 'An activity obligation rule requires a business process or other activity to occur either within a maximum time after a particular event (such as the completion of some other process) or as soon as practical after a particular event.', 'templates': ['T49']}]}, {'section_id': '9.4.1.2', 'section_title': 'Activity pre-condition rules', 'section_definition': 'An activity pre-condition rule prohibits a business process or other activity unless some other activity or event has previously occurred or some prerequisite condition exists.', 'templates': ['T50']}, {'section_id': '9.4.1.3', 'section_title': 'Activity prohibition rules', 'section_definition': 'An activity prohibition rule prohibits a business process or other activity if some event or other process has previously occurred or some dangerous or illegal condition exists.', 'templates': ['T51']}, {'section_id': '9.4.1.4', 'section_title': 'Information retention rules', 'section_definition': 'An information retention rule defines the minimum period for which a particular type of information is retained.', 'templates': ['T49']}, {'section_id': '9.4.1.5', 'section_title': 'Activity conflict rules', 'section_definition': 'An activity conflict rule restricts the simultaneous occurrence of multiple processes or other activities.', 'examples': ['R136'], 'templates': ['T?']}]}, {'section_id': '9.4.2', 'section_title': 'Process decision rules', 'section_definition': 'A process decision rule determines what action a business process or device is to take in specific situations;', 'templates': ['T52']}, {'section_id': '9.4.3', 'section_title': 'Activity obligation rules', 'section_definition': 'An activity obligation rule requires a business process or other activity to occur either within a maximum time after a particular event (such as the completion of some other process) or when particular conditions apply.', 'examples': ['R138'], 'templates': ['T?']}]}, {'section_id': '9.5', 'section_title': 'Party rules', 'section_definition': 'Party rules (all of which are operative rules) restricts the parties who can perform a process or activity or play a role. Party rules can in turn be categorized as:', 'subsections': [{'section_id': '9.5.1', 'section_title': 'Party restriction rules', 'section_definition': 'A party restriction rule places restrictions on who can perform some processes or activities or play some roles, based on age, some other physical characteristic or capability, or training, testing, and certification in the appropriate skills.', 'templates': ['T53']}, {'section_id': '9.5.2', 'section_title': 'Role separation and binding rules', 'section_definition': 'A role separation rule prohibits the same party from performing two activities.', 'templates': ['T54']}, {'section_id': '9.5.3', 'section_title': 'Information access rules', 'section_definition': 'An information access rule defines who can view, create, or update particular information.', 'templates': ['T55']}, {'section_id': '9.5.4', 'section_title': 'Responsibility rules', 'section_definition': 'A responsibility rule defines who is responsible for performing a particular process or liable for a particular fee, duty, or tax.', 'templates': ['T56']}]}]\n"
          ]
        }
      ],
      "source": [
        "with open(f\"{config['DEFAULT_DATA_DIR']}/classify_subtypes.json\", 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XurhYi0VaLQR"
      },
      "outputs": [],
      "source": [
        "def find_sections_by_title(data, title):\n",
        "    result = []\n",
        "\n",
        "    # Recursively search for matching section_title\n",
        "    def search_sections(sections):\n",
        "        for section in sections:\n",
        "            if section['section_title'] == title:\n",
        "                result.append(section)\n",
        "            if 'subsections' in section:\n",
        "                search_sections(section['subsections'])\n",
        "\n",
        "    # Start the search from the root level\n",
        "    search_sections(data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4N5gLmWbz3v",
        "outputId": "efb61ff1-e17f-4cf8-dcab-1122b7e4763b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"section_id\": \"9.2\",\n",
            "    \"section_title\": \"Definitional rules\",\n",
            "    \"section_definition\": \"Definitional rules constrains how we define a construct created or used by the organization or the industry within which it operates. Definitional rules can in turn be categorized as:\",\n",
            "    \"subsections\": [\n",
            "      {\n",
            "        \"section_id\": \"9.2.1\",\n",
            "        \"section_title\": \"Formal term definitions\",\n",
            "        \"section_definition\": \"A formal term definition defines a particular business term in a formal manner. They are categorized as:\",\n",
            "        \"subsections\": [\n",
            "          {\n",
            "            \"section_id\": \"9.2.1.1\",\n",
            "            \"section_title\": \"Formal intensional definitions\",\n",
            "            \"section_definition\": \"A formal intensional definition defines the subject business term using an intensional definition: one that cites both a hypernym (a term that refers to a superset of the set referred to by the original term) and the characteristics that distinguish members of the set referred to by the original term.\",\n",
            "            \"templates\": [\n",
            "              \"T7\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"section_id\": \"9.2.1.2\",\n",
            "            \"section_title\": \"Formal extensional definitions\",\n",
            "            \"section_definition\": \"Formal extensional definition defines the subject business term by using an extensional definition: one that lists a complete set of hyponyms (terms that refer to subsets of the set referred to by the original term).\",\n",
            "            \"templates\": [\n",
            "              \"T8\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"section_id\": \"9.2.1.3\",\n",
            "            \"section_title\": \"Symbolic literal definitions\",\n",
            "            \"section_definition\": \"A symbolic literal definition defines the subject business term using one or more literals.\",\n",
            "            \"templates\": [\n",
            "              \"T9\"\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.2\",\n",
            "        \"section_title\": \"Categorization scheme enumerations\",\n",
            "        \"section_definition\": \"A categorization scheme enumeration defines the members of a categorization scheme that is both mutually exclusive and jointly exhaustive.\",\n",
            "        \"templates\": [\n",
            "          \"T10\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.3\",\n",
            "        \"section_title\": \"Category transition constraints\",\n",
            "        \"section_definition\": \"A category transition constraint specifies allowed or disallowed transitions between categories or statuses.\",\n",
            "        \"templates\": [\n",
            "          \"T11\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.4\",\n",
            "        \"section_title\": \"Complex concept structure rules\",\n",
            "        \"section_definition\": \"A complex concept structure rule defines a particular constraint on one or more components of a complex concept. They are categorized as:\",\n",
            "        \"subsections\": [\n",
            "          {\n",
            "            \"section_id\": \"9.2.4.1\",\n",
            "            \"section_title\": \"Complex concept cardinality rules\",\n",
            "            \"section_definition\": \"A complex concept cardinality rule defines the number of (or minimum and/or maximum number of) components of a particular type within a particular concept.\",\n",
            "            \"templates\": [\n",
            "              \"T12\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"section_id\": \"9.2.4.2\",\n",
            "            \"section_title\": \"Complex concept equivalence rules\",\n",
            "            \"section_definition\": \"A complex concept equivalence rule defines a pair of components within a particular concept that are of necessity the same.\",\n",
            "            \"templates\": [\n",
            "              \"T13\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"section_id\": \"9.2.4.3\",\n",
            "            \"section_title\": \"Complex concept set constraints\",\n",
            "            \"section_definition\": \"A complex concept set constraint defines two sets of components within a particular concept that must be identical.\",\n",
            "            \"templates\": [\n",
            "              \"T14\"\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.5\",\n",
            "        \"section_title\": \"Valid value definitions\",\n",
            "        \"section_definition\": \"A valid value definition defines the valid values of a particular measure as a range or (occasionally) as a list of discrete values.\",\n",
            "        \"templates\": [\n",
            "          \"T15\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.6\",\n",
            "        \"section_title\": \"Data calculation rules\",\n",
            "        \"section_definition\": \"A data calculation rule defines the algorithm or formula for a particular quantity or a conversion factor between two units. They are categorized as:\",\n",
            "        \"subsections\": [\n",
            "          {\n",
            "            \"section_id\": \"9.2.6.1\",\n",
            "            \"section_title\": \"Data calculation algorithms\",\n",
            "            \"section_definition\": \"A data calculation algorithm defines how a particular quantity or amount (whether for operational purposes, such as a fee, or for business intelligence purposes, such as a performance measure) is calculated.\",\n",
            "            \"templates\": [\n",
            "              \"T16\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"section_id\": \"9.2.6.2\",\n",
            "            \"section_title\": \"Conversion factor definitions\",\n",
            "            \"section_definition\": \"A conversion factor definition defines a conversion factor between two units of measurement.\",\n",
            "            \"templates\": [\n",
            "              \"T17\"\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.7\",\n",
            "        \"section_title\": \"Standard format definitions\",\n",
            "        \"section_definition\": \"A standard format definition defines the standard format for data items of a particular type in terms of individual characters and/or component data items.\",\n",
            "        \"templates\": [\n",
            "          \"T18\"\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Example: Find sections with the title 'Definitional rules'\n",
        "filtered_sections = find_sections_by_title(data, 'Definitional rules')\n",
        "\n",
        "# Output the filtered sections\n",
        "print(json.dumps(filtered_sections, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiAScTvanC_",
        "outputId": "7b69604b-7a76-4964-f07e-343e6be2f2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"section_id\": \"9.2.1\",\n",
            "    \"section_title\": \"Formal term definitions\",\n",
            "    \"section_definition\": \"A formal term definition defines a particular business term in a formal manner. They are categorized as:\",\n",
            "    \"subsections\": [\n",
            "      {\n",
            "        \"section_id\": \"9.2.1.1\",\n",
            "        \"section_title\": \"Formal intensional definitions\",\n",
            "        \"section_definition\": \"A formal intensional definition defines the subject business term using an intensional definition: one that cites both a hypernym (a term that refers to a superset of the set referred to by the original term) and the characteristics that distinguish members of the set referred to by the original term.\",\n",
            "        \"templates\": [\n",
            "          \"T7\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.1.2\",\n",
            "        \"section_title\": \"Formal extensional definitions\",\n",
            "        \"section_definition\": \"Formal extensional definition defines the subject business term by using an extensional definition: one that lists a complete set of hyponyms (terms that refer to subsets of the set referred to by the original term).\",\n",
            "        \"templates\": [\n",
            "          \"T8\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"section_id\": \"9.2.1.3\",\n",
            "        \"section_title\": \"Symbolic literal definitions\",\n",
            "        \"section_definition\": \"A symbolic literal definition defines the subject business term using one or more literals.\",\n",
            "        \"templates\": [\n",
            "          \"T9\"\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Example: Find sections with the title 'Definitional rules'\n",
        "filtered_sections = find_sections_by_title(data, 'Formal term definitions')\n",
        "\n",
        "# Output the filtered sections\n",
        "print(json.dumps(filtered_sections, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwtCq43uNI4i"
      },
      "source": [
        "### Save checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mShs2YxeNI4i",
        "outputId": "0369eeb1-c858-4f19-bc49-5bc5306b4458"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:20:23 - INFO - Checkpoint saved.\n"
          ]
        }
      ],
      "source": [
        "# Persist the state to a file\n",
        "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ErIwTafNI4i"
      },
      "source": [
        "### Check the content of datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3691GtsNI4i",
        "outputId": "9210ddb5-f4cb-4b6d-c29f-f6c2abf3f757"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:20:55 - INFO - SECTIONS:\n",
            "2024-10-29 11:20:55 - INFO - section docs: ['§ 275.0-2', '§ 275.0-5', '§ 275.0-7']\n",
            "2024-10-29 11:20:55 - INFO - § 275.0-2: Total number of lines: 14, total number of words: 362, and average words per line: 26\n",
            "2024-10-29 11:20:55 - INFO - § 275.0-5: Total number of lines: 10, total number of words: 260, and average words per line: 26\n",
            "2024-10-29 11:20:55 - INFO - § 275.0-7: Total number of lines: 19, total number of words: 513, and average words per line: 27\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-2_P1 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P1\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-5_P1 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P1\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-7_P1 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P1\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-2_P2 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P2\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-5_P2 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P2\n",
            "2024-10-29 11:20:55 - INFO - Processing document: § 275.0-7_P2 ...\n",
            "2024-10-29 11:20:55 - INFO - retrieve P2\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"SECTIONS:\")\n",
        "# List all document ids | type\n",
        "logger.info(f\"section docs: {manager.list_document_ids(doc_type='section')}\")\n",
        "\n",
        "# Retrieve a document by id | type\n",
        "for doc in manager.list_document_ids(doc_type=\"section\"):\n",
        "    retrieved_doc = manager.retrieve_document(doc_id=doc, doc_type=\"section\")\n",
        "    logger.debug(retrieved_doc)\n",
        "    lines, words, avg_words_per_line = basic_text_stats(retrieved_doc.content)\n",
        "    logger.info(\n",
        "        f\"{doc}: Total number of lines: {lines}, total number of words: {words}, and average words per line: {avg_words_per_line}\"\n",
        "    )\n",
        "\n",
        "retrieved_true_table_p1 = []\n",
        "retrieved_true_table_p2 = []\n",
        "\n",
        "for doc in manager.list_document_ids(doc_type=\"true_table\"):\n",
        "    logger.info(f\"Processing document: {doc} ...\")\n",
        "    # Docs type true_table P1\n",
        "    if doc.endswith(\"_P1\"):\n",
        "        retrieved_true_table_p1.append(\n",
        "            calculate_content_quantities_p1(\n",
        "                doc,\n",
        "                manager.retrieve_document(\n",
        "                    doc_id=doc, doc_type=\"true_table\"\n",
        "                ).model_dump()[\"content\"],\n",
        "                filename=\"p1_true_table.json\",\n",
        "            )\n",
        "        )\n",
        "        logger.info(\"retrieve P1\")\n",
        "    # Docs type true_table P2\n",
        "    elif doc.endswith(\"_P2\"):\n",
        "        retrieved_true_table_p2.append(\n",
        "            calculate_content_quantities_p2(\n",
        "                doc,\n",
        "                manager.retrieve_document(\n",
        "                    doc_id=doc, doc_type=\"true_table\"\n",
        "                ).model_dump(),\n",
        "                filename=\"p2_true_table.json\",\n",
        "            )\n",
        "        )\n",
        "        logger.info(\"retrieve P2\")\n",
        "\n",
        "# Convert collected data to a DataFrame\n",
        "table_true_df_p1 = pd.DataFrame(retrieved_true_table_p1)\n",
        "table_true_df_p2 = pd.DataFrame(retrieved_true_table_p2)\n",
        "\n",
        "# Save DataFrames to CSV if needed\n",
        "table_true_df_p1.to_excel(f\"{config['DEFAULT_OUTPUT_DIR']}/P1_summary_true_table.xlsx\", index=False)\n",
        "table_true_df_p2.to_excel(f\"{config['DEFAULT_OUTPUT_DIR']}/P2_summary_true_table.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aHv9aOnNI4j"
      },
      "source": [
        "True table for P1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "dzZhl1U-NI4i",
        "outputId": "8d27b441-42a7-4491-a1a0-adaafcab06bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>quantity_of_elements</th>\n",
              "      <th>quantity_of_facts</th>\n",
              "      <th>quantity_of_fact_types</th>\n",
              "      <th>quantity_of_rules</th>\n",
              "      <th>quantity_of_verbs</th>\n",
              "      <th>quantity_of_terms</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>§ 275.0-2_P1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>73</td>\n",
              "      <td>p1_true_table.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>§ 275.0-5_P1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>41</td>\n",
              "      <td>p1_true_table.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>§ 275.0-7_P1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>46</td>\n",
              "      <td>p1_true_table.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    document_id  quantity_of_elements  quantity_of_facts  \\\n",
              "0  § 275.0-2_P1                     9                  0   \n",
              "1  § 275.0-5_P1                     5                  0   \n",
              "2  § 275.0-7_P1                     9                  0   \n",
              "\n",
              "   quantity_of_fact_types  quantity_of_rules  quantity_of_verbs  \\\n",
              "0                       7                  2                 28   \n",
              "1                       4                  1                 21   \n",
              "2                       5                  4                 21   \n",
              "\n",
              "   quantity_of_terms            filename  \n",
              "0                 73  p1_true_table.json  \n",
              "1                 41  p1_true_table.json  \n",
              "2                 46  p1_true_table.json  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_true_df_p1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "1-A2-DojNI4j",
        "outputId": "d44334a7-53b8-476f-bd40-a2d18edd3b0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">quantity_of_elements</th>\n",
              "      <th colspan=\"2\" halign=\"left\">quantity_of_facts</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">quantity_of_verbs</th>\n",
              "      <th colspan=\"8\" halign=\"left\">quantity_of_terms</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>...</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>document_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>§ 275.0-2_P1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>§ 275.0-5_P1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>§ 275.0-7_P1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 48 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             quantity_of_elements                                    \\\n",
              "                            count mean std  min  25%  50%  75%  max   \n",
              "document_id                                                           \n",
              "§ 275.0-2_P1                  1.0  9.0 NaN  9.0  9.0  9.0  9.0  9.0   \n",
              "§ 275.0-5_P1                  1.0  5.0 NaN  5.0  5.0  5.0  5.0  5.0   \n",
              "§ 275.0-7_P1                  1.0  9.0 NaN  9.0  9.0  9.0  9.0  9.0   \n",
              "\n",
              "             quantity_of_facts       ... quantity_of_verbs        \\\n",
              "                         count mean  ...               75%   max   \n",
              "document_id                          ...                           \n",
              "§ 275.0-2_P1               1.0  0.0  ...              28.0  28.0   \n",
              "§ 275.0-5_P1               1.0  0.0  ...              21.0  21.0   \n",
              "§ 275.0-7_P1               1.0  0.0  ...              21.0  21.0   \n",
              "\n",
              "             quantity_of_terms                                          \n",
              "                         count  mean std   min   25%   50%   75%   max  \n",
              "document_id                                                             \n",
              "§ 275.0-2_P1               1.0  73.0 NaN  73.0  73.0  73.0  73.0  73.0  \n",
              "§ 275.0-5_P1               1.0  41.0 NaN  41.0  41.0  41.0  41.0  41.0  \n",
              "§ 275.0-7_P1               1.0  46.0 NaN  46.0  46.0  46.0  46.0  46.0  \n",
              "\n",
              "[3 rows x 48 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_true_p1 = table_true_df_p1.groupby('document_id').describe()\n",
        "\n",
        "table_true_p1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCmVqziNI4j"
      },
      "source": [
        "True table for P2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "6unKzxPKNI4j",
        "outputId": "52eb2189-4525-446e-eed6-de05deb57ee1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>count_of_terms</th>\n",
              "      <th>terms_with_definition</th>\n",
              "      <th>terms_without_definition</th>\n",
              "      <th>terms_relationship_count</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>§ 275.0-2_P2</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>p2_true_table.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>§ 275.0-5_P2</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>p2_true_table.json</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>§ 275.0-7_P2</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>p2_true_table.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    document_id  count_of_terms  terms_with_definition  \\\n",
              "0  § 275.0-2_P2              37                     34   \n",
              "1  § 275.0-5_P2              29                     29   \n",
              "2  § 275.0-7_P2              26                     26   \n",
              "\n",
              "   terms_without_definition  terms_relationship_count            filename  \n",
              "0                         3                        11  p2_true_table.json  \n",
              "1                         0                         8  p2_true_table.json  \n",
              "2                         0                         2  p2_true_table.json  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_true_df_p2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "GAQ8exN9NI4j",
        "outputId": "0a79e89a-b164-438f-f9fb-8d9fa0d0f42a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">count_of_terms</th>\n",
              "      <th colspan=\"2\" halign=\"left\">terms_with_definition</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">terms_without_definition</th>\n",
              "      <th colspan=\"8\" halign=\"left\">terms_relationship_count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>...</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>document_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>§ 275.0-2_P2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>§ 275.0-5_P2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>§ 275.0-7_P2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             count_of_terms                                          \\\n",
              "                      count  mean std   min   25%   50%   75%   max   \n",
              "document_id                                                           \n",
              "§ 275.0-2_P2            1.0  37.0 NaN  37.0  37.0  37.0  37.0  37.0   \n",
              "§ 275.0-5_P2            1.0  29.0 NaN  29.0  29.0  29.0  29.0  29.0   \n",
              "§ 275.0-7_P2            1.0  26.0 NaN  26.0  26.0  26.0  26.0  26.0   \n",
              "\n",
              "             terms_with_definition        ... terms_without_definition       \\\n",
              "                             count  mean  ...                      75%  max   \n",
              "document_id                               ...                                 \n",
              "§ 275.0-2_P2                   1.0  34.0  ...                      3.0  3.0   \n",
              "§ 275.0-5_P2                   1.0  29.0  ...                      0.0  0.0   \n",
              "§ 275.0-7_P2                   1.0  26.0  ...                      0.0  0.0   \n",
              "\n",
              "             terms_relationship_count                                          \n",
              "                                count  mean std   min   25%   50%   75%   max  \n",
              "document_id                                                                    \n",
              "§ 275.0-2_P2                      1.0  11.0 NaN  11.0  11.0  11.0  11.0  11.0  \n",
              "§ 275.0-5_P2                      1.0   8.0 NaN   8.0   8.0   8.0   8.0   8.0  \n",
              "§ 275.0-7_P2                      1.0   2.0 NaN   2.0   2.0   2.0   2.0   2.0  \n",
              "\n",
              "[3 rows x 32 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table_true_p2 = table_true_df_p2.groupby('document_id').describe()\n",
        "\n",
        "table_true_p2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7w__XtoNI4k"
      },
      "source": [
        "## Processes\n",
        "\n",
        "The execution part of the notebook. These code are in charge of the annotation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHNlHaNnNI4k"
      },
      "source": [
        "### extract / classify elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmaifPRPNI4k"
      },
      "source": [
        "#### General functions and data structures\n",
        "\n",
        "Functions and data structures used in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWra_31jsnow"
      },
      "outputs": [],
      "source": [
        "def measure_time(func):\n",
        "    \"\"\"\n",
        "    Decorator to measure the execution time of a function.\n",
        "    \"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.perf_counter()\n",
        "        elapsed_time = end_time - start_time\n",
        "        logger.info(f\"Execution time for {func.__name__}: {elapsed_time:.2f} seconds\")\n",
        "        return result\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PSo1DCGNI4k"
      },
      "outputs": [],
      "source": [
        "class Term(BaseModel):\n",
        "    term: str = Field(..., description=\"The term is a word or a group of words that represents a specific concept, entity, or subject in a particular context\")\n",
        "    classification: str = Field(..., description=\"The classification of the term, either 'Common Noun' or 'Proper Noun'.\")\n",
        "\n",
        "class Element(BaseModel):\n",
        "    id: int = Field(..., description=\"A unique numeric identifier for each fact, fact type, or rule.\")\n",
        "    expression: str = Field(..., description=\"The full sentence or phrase representing the fact, fact type, or rule.\")\n",
        "    terms: List[Term] = Field(..., description=\"A list of terms involved in the fact, fact type, or rule.\")\n",
        "    verb_symbols: List[str] = Field(..., description=\"A list of vers, verb phrases or prepositions connecting the terms.\")\n",
        "    classification: str = Field(..., description=\"Indicates whether the expression is classified as 'Fact', 'Fact Type', or 'Rule'.\")\n",
        "    source: str = Field(..., description=\"The paragraph ID of the document where the fact, fact type, or rule is located (e.g., '(a)', '(b)(2)').\")\n",
        "\n",
        "class ElementsDocumentModel(BaseModel):\n",
        "    section: str = Field(..., description=\"The section ID of the document.\")\n",
        "    summary: str = Field(..., description=\"The summary of the document.\")\n",
        "    elements: List[Element] = Field(..., description=\"A list of facts, fact types, and rules extracted from the document.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNCirQszNI4k"
      },
      "outputs": [],
      "source": [
        "class Item(BaseModel):\n",
        "    term: str = Field(..., description=\"The term is a word or a group of words that represents a specific concept, entity, or subject in a particular context\")\n",
        "    definition: Optional[str] = Field(None, description=\"Definition is a explanation or description of the meaning of the term.\")\n",
        "\n",
        "class TermsRelationship(BaseModel):\n",
        "    term_1: str = Field(..., description=\"First term in the relationship.\")\n",
        "    term_2: str = Field(..., description=\"Second term in the relationship.\")\n",
        "    relation: str = Field(..., description=\"The typrelationship between the terms.\")\n",
        "\n",
        "class TermsDocumentModel(BaseModel):\n",
        "    terms: List[Item] = Field(..., description=\"A list of terms.\")\n",
        "    terms_relationship: List[TermsRelationship] = Field(..., description=\"A list of relationships between terms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCMSK9tpsnow"
      },
      "outputs": [],
      "source": [
        "# Patching the Gemini client with the instructor for enhanced capabilities\n",
        "import google.generativeai as genai\n",
        "\n",
        "@measure_time\n",
        "def query_instruct_llm_gemini(system_prompt: str, user_prompt: str, document_model: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Queries the LLM with the given system and user prompts.\n",
        "\n",
        "    Args:\n",
        "        system_prompt (str): The system prompt to set the context for the LLM.\n",
        "        user_prompt (str): The user prompt containing the text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        Any: The response from the LLM, parsed into a document_model object.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If the API call fails.\n",
        "    \"\"\"\n",
        "    client = instructor.from_gemini(\n",
        "        client=genai.GenerativeModel(\n",
        "            model_name=\"models/gemini-1.5-flash-latest\",  # model defaults to \"gemini-pro\"\n",
        "        ),\n",
        "        mode=instructor.Mode.GEMINI_JSON,\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        response_model=document_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "    )\n",
        "    return resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK0u_DE0snow"
      },
      "outputs": [],
      "source": [
        "# Patching the Anthropics client with the instructor for enhanced capabilities\n",
        "from anthropic import Anthropic\n",
        "\n",
        "@measure_time\n",
        "def query_instruct_llm_ant(system_prompt: str, user_prompt: str, document_model: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Queries the LLM with the given system and user prompts.\n",
        "\n",
        "    Args:\n",
        "        system_prompt (str): The system prompt to set the context for the LLM.\n",
        "        user_prompt (str): The user prompt containing the text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        Any: The response from the LLM, parsed into a document_model object.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If the API call fails.\n",
        "    \"\"\"\n",
        "    client = instructor.from_anthropic(\n",
        "        Anthropic(),\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"claude-3-5-sonnet-20241022\",\n",
        "        response_model=document_model,\n",
        "        temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
        "        max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "    )\n",
        "    return resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyTq87rMNI4k"
      },
      "outputs": [],
      "source": [
        "@measure_time\n",
        "def query_instruct_llm(system_prompt: str, user_prompt: str, document_model: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Queries the LLM with the given system and user prompts.\n",
        "\n",
        "    Args:\n",
        "        system_prompt (str): The system prompt to set the context for the LLM.\n",
        "        user_prompt (str): The user prompt containing the text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        Any: The response from the LLM, parsed into a document_model object.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If the API call fails.\n",
        "    \"\"\"\n",
        "    client = instructor.from_openai(OpenAI()) #, mode=instructor.Mode.TOOLS_STRICT)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=config[\"LLM\"][\"MODEL\"],\n",
        "        response_model=document_model,\n",
        "        temperature=config[\"LLM\"][\"TEMPERATURE\"],\n",
        "        max_tokens=config[\"LLM\"][\"MAX_TOKENS\"],\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "    )\n",
        "    return resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5aLp8hMNI4k"
      },
      "outputs": [],
      "source": [
        "def save_compare_items_metrics(\n",
        "    section_id: str,\n",
        "    correct_items_len: int,\n",
        "    predicted_items_len: int,\n",
        "    common_items_len: int,\n",
        "    missed_items_len: int,\n",
        "    extra_items_len: int,\n",
        "    precision: float,\n",
        "    recall: float,\n",
        "    f1: float,\n",
        "    file_name: str = 'section_validation_metrics.xlsx'\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Saves comparison metrics to an Excel file.\n",
        "\n",
        "    Args:\n",
        "        section_id (str): The ID of the section being analyzed.\n",
        "        correct_items_len (int): Number of correct items.\n",
        "        predicted_items_len (int): Number of predicted items.\n",
        "        common_items_len (int): Number of items common between correct and predicted.\n",
        "        missed_items_len (int): Number of missed items.\n",
        "        extra_items_len (int): Number of extra items.\n",
        "        precision (float): Precision metric.\n",
        "        recall (float): Recall metric.\n",
        "        f1 (float): F1 score.\n",
        "        file_name (str, optional): The filename to save the metrics. Defaults to 'section_validation_metrics.xlsx'.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error writing to the Excel file.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        'section': [section_id],\n",
        "        'correct_C': [correct_items_len],\n",
        "        'predicted_P': [predicted_items_len],\n",
        "        'C_intersec_P': [common_items_len],\n",
        "        'C_less_P': [missed_items_len],\n",
        "        'P_less_C': [extra_items_len],\n",
        "        'precision': [precision],\n",
        "        'recall': [recall],\n",
        "        'f1': [f1],\n",
        "        'timestamp': [datetime.now()]\n",
        "    }\n",
        "\n",
        "    # Convert the dictionary into a pandas DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(file_name):\n",
        "        # If the file doesn't exist, create it and write the data\n",
        "        df.to_excel(file_name, index=False)\n",
        "    else:\n",
        "        # If the file exists, append the new data without writing the header\n",
        "        with pd.ExcelWriter(file_name, mode='a', if_sheet_exists='overlay', engine='openpyxl') as writer:\n",
        "            df.to_excel(writer, index=False, header=False, startrow=writer.sheets['Sheet1'].max_row)\n",
        "\n",
        "    logger.info(f\"Data appended to {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGRiQb-mNI4l"
      },
      "outputs": [],
      "source": [
        "def compare_items(\n",
        "    doc: str,\n",
        "    llm_response: List[Dict[str, Any]],\n",
        "    true_table: List[Dict[str, Any]],\n",
        "    item_name: str,\n",
        "    item_category: str\n",
        ") -> Tuple[Set[str], Dict[str, str], Set[str], Dict[str, str], Set[str], Set[str], Set[str]]:\n",
        "    \"\"\"\n",
        "    Compares the LLM response with the true table to identify matches, misses, and extras.\n",
        "\n",
        "    Args:\n",
        "        doc (str): The document identifier.\n",
        "        llm_response (List[ItemModel]): The list of items returned by the LLM.\n",
        "        true_table (List[Dict[str, Any]]): The true table containing correct items.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing:\n",
        "            - predicted_items (Set[str]): Set of predicted entity names.\n",
        "            - predicted_dict (Dict[str, str]): Dict mapping predicted entity names to categories.\n",
        "            - correct_items (Set[str]): Set of correct entity names.\n",
        "            - correct_dict (Dict[str, str]): Dict mapping correct entity names to categories.\n",
        "            - common_items (Set[str]): Set of entity names common to both predicted and correct items.\n",
        "            - missed_items (Set[str]): Set of missed entity names (in correct but not in predicted).\n",
        "            - extra_items (Set[str]): Set of extra entity names (in predicted but not in correct).\n",
        "    \"\"\"\n",
        "    # Create dictionaries keyed by 'entity'\n",
        "    correct_dict = {item[item_name].lower(): item[item_category] for item in true_table}\n",
        "    predicted_dict = {item[item_name].lower(): item[item_category] for item in llm_response}\n",
        "\n",
        "    logger.debug(f\"correct_dict: {correct_dict}\")\n",
        "    logger.debug(f\"predicted_dict: {predicted_dict}\")\n",
        "\n",
        "    # Identify Common and Unique entities\n",
        "    # Get sets of entities\n",
        "    correct_items = set(correct_dict.keys())\n",
        "    predicted_items = set(predicted_dict.keys())\n",
        "\n",
        "    # Identify true positives, false negatives, and false positives\n",
        "    common_items = correct_items & predicted_items  # Matched terms\n",
        "    missed_items = correct_items - predicted_items  # Terms missed in predictions\n",
        "    extra_items = predicted_items - correct_items   # Additional terms in predictions\n",
        "\n",
        "    logger.debug(f\"common_items: {common_items}\")\n",
        "    logger.debug(f\"missed_items: {missed_items}\")\n",
        "    logger.debug(f\"extra_items: {extra_items}\")\n",
        "    logger.info(f\"\"\"\n",
        "Document: {doc}\n",
        "Correct items; Predicted items; Common items; Missed items; Extra items; Precision; Recall; F1\n",
        "{len(correct_items)}; {len(predicted_items)}; {len(common_items)}; {len(missed_items)}; {len(extra_items)}; {len(common_items) / len(correct_items)}; {len(common_items) / len(predicted_items)}; {2 * len(common_items) / (len(correct_items) + len(predicted_items))}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    return predicted_items, predicted_dict, correct_items, correct_dict, common_items, missed_items, extra_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GciEhLYNI4l"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(\n",
        "    predicted_items: Set[str],\n",
        "    predicted_dict: Dict[str, str],\n",
        "    correct_items: Set[str],\n",
        "    correct_dict: Dict[str, str]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix and generates a classification report.\n",
        "\n",
        "    Args:\n",
        "        predicted_items (Set[str]): Set of predicted entity names.\n",
        "        predicted_dict (Dict[str, str]): Dict mapping predicted entity names to categories.\n",
        "        correct_items (Set[str]): Set of correct entity names.\n",
        "        correct_dict (Dict[str, str]): Dict mapping correct entity names to categories.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: The classification report as a dictionary.\n",
        "    \"\"\"\n",
        "    # Assuming correct_dict and predicted_dict are already defined\n",
        "    comparison_results = []\n",
        "\n",
        "    # Convert the lists to sets to use the union() method\n",
        "    predicted_items_set = set(predicted_items)\n",
        "    correct_items_set = set(correct_items)\n",
        "\n",
        "    for item in correct_items_set.union(predicted_items_set):\n",
        "        correct_category = correct_dict.get(item)\n",
        "        predicted_category = predicted_dict.get(item)\n",
        "\n",
        "        # Replace None with 'None' string\n",
        "        if correct_category is None:\n",
        "            correct_category = 'None'\n",
        "        if predicted_category is None:\n",
        "            predicted_category = 'None'\n",
        "\n",
        "        # Determine if types match\n",
        "        category_match = correct_category == predicted_category\n",
        "\n",
        "        # Append to comparison_results\n",
        "        comparison_results.append({\n",
        "            'Item': item,\n",
        "            'Correct category': correct_category,\n",
        "            'Predicted category': predicted_category,\n",
        "            'Category match': category_match\n",
        "        })\n",
        "\n",
        "    # Create the DataFrame\n",
        "    df = pd.DataFrame(comparison_results)\n",
        "\n",
        "\n",
        "    # Filter out rows where either the correct or predicted category is 'None'\n",
        "    df_filtered = df[(df['Correct category'] != 'None') & (df['Predicted category'] != 'None')]\n",
        "\n",
        "    # Create the confusion matrix\n",
        "    confusion_matrix = pd.crosstab(\n",
        "        df_filtered['Correct category'],\n",
        "        df_filtered['Predicted category'],\n",
        "        rownames=['Actual'],\n",
        "        colnames=['Predicted'],\n",
        "        margins=True\n",
        "    )\n",
        "\n",
        "    # Visualize the confusion matrix\n",
        "    cm = confusion_matrix.iloc[:-1, :-1] #if 'All' in confusion_matrix.index else confusion_matrix\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion matrix of category predictions')\n",
        "    plt.ylabel('Actual category')\n",
        "    plt.xlabel('Predicted category')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n",
        "\n",
        "    # Prepare data for classification report\n",
        "    types = sorted(set(df_filtered['Correct category']) | set(df_filtered['Predicted category']))\n",
        "    type_to_int = {t: i for i, t in enumerate(types)}\n",
        "\n",
        "    y_true = df_filtered['Correct category'].map(type_to_int)\n",
        "    y_pred = df_filtered['Predicted category'].map(type_to_int)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_true, y_pred, target_names=types, output_dict=True)\n",
        "    return report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roeKyr0xNI4l"
      },
      "outputs": [],
      "source": [
        "def generate_report(checkpoint_file: str, output_file: str) -> None:\n",
        "    \"\"\"\n",
        "    Generates an HTML report from the checkpoint data and saves it to a file.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_file (str): The path to the checkpoint file.\n",
        "        output_file (str): The path to save the HTML report.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error reading the checkpoint file or writing the report.\n",
        "    \"\"\"\n",
        "    # JSON data (you can replace this with reading from a file if needed)\n",
        "    # load json from file\n",
        "    data = json.load(\n",
        "        open(checkpoint_file)\n",
        "    )\n",
        "\n",
        "    # Function to generate HTML report\n",
        "    def generate_html_report(data):\n",
        "        html_content = \"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Term Extraction Report</title>\n",
        "            <style>\n",
        "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
        "                h1 { color: #333; }\n",
        "                h2 { color: #555; }\n",
        "                table { width: 100%; border-collapse: collapse; margin-bottom: 20px; }\n",
        "                th, td { border: 1px solid #ccc; padding: 8px; text-align: left; }\n",
        "                th { background-color: #f5f5f5; }\n",
        "                .section { margin-bottom: 60px; }\n",
        "                .statistics, .classification-report { margin-bottom: 40px; }\n",
        "                pre { background-color: #f5f5f5; padding: 10px; }\n",
        "                ul { list-style-type: disc; margin-left: 20px; }\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>Term Extraction Report</h1>\n",
        "            <p>The algorithm extracted entities from the sections. For each section, there is a table with the true values, followed by the LLM's response, and an analysis comparing the LLM's findings with the expected entities.</p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Iterate over each section\n",
        "        for key in data:\n",
        "            item = data[key]\n",
        "            if item['type'] == 'section':\n",
        "                section_id = item['id']\n",
        "                section_content = item['content']\n",
        "                html_content += f\"<div class='section'>\\n<h2>Section: {section_id}</h2>\\n\"\n",
        "                html_content += f\"<pre>{section_content}</pre>\\n\"\n",
        "\n",
        "                # True table\n",
        "                true_table_key = f\"{section_id}|true_table\"\n",
        "                if true_table_key in data:\n",
        "                    html_content += \"<h3>True Values</h3>\\n\"\n",
        "                    html_content += \"<table>\\n<tr><th>Signifier</th><th>Definition</th><th>Concept classification</th><th>Source</th></tr>\\n\"\n",
        "                    for row in data[true_table_key]['content']:\n",
        "                        signifier = row.get('signifier', 'N/A')\n",
        "                        definition = row.get('definition', 'N/A')\n",
        "                        concept_classification = row.get('concept_classification', 'N/A')\n",
        "                        sources = row.get('sources', {})\n",
        "                        source_text = f\"Section {sources[0].get('section', 'N/A')} Paragraph {sources[0].get('paragraph', 'N/A')}\"\n",
        "                        html_content += f\"<tr><td>{signifier}</td><td>{definition}</td><td>{concept_classification}</td><td>{source_text}</td></tr>\\n\"\n",
        "                    html_content += \"</table>\\n\"\n",
        "\n",
        "                # LLM response\n",
        "                llm_response_key = f\"{section_id}|llm_response\"\n",
        "                if llm_response_key in data:\n",
        "                    html_content += \"<h3>LLM Extracted Entities</h3>\\n\"\n",
        "                    html_content += \"<table>\\n<tr><th>Signifier</th><th>Definition</th><th>Concept classification</th><th>Source</th></tr>\\n\"\n",
        "                    for row in data[llm_response_key]['content']:\n",
        "                        signifier = row.get('signifier', 'N/A')\n",
        "                        definition = row.get('definition', 'N/A')\n",
        "                        concept_classification = row.get('concept_classification', 'N/A')\n",
        "                        sources = row.get('sources', {})\n",
        "                        source_text = f\"Section {sources[0].get('section', 'N/A')} Paragraph {sources[0].get('paragraph', 'N/A')}\"\n",
        "                        html_content += f\"<tr><td>{signifier}</td><td>{definition}</td><td>{concept_classification}</td><td>{source_text}</td></tr>\\n\"\n",
        "                    html_content += \"</table>\\n\"\n",
        "\n",
        "                # Statistics\n",
        "                statistics_key = f\"{section_id}|statistics\"\n",
        "                if statistics_key in data:\n",
        "                    html_content += \"<h3>Comparison Statistics</h3>\\n\"\n",
        "                    stats = data[statistics_key]['content']\n",
        "                    html_content += \"<div class='statistics'>\\n\"\n",
        "                    html_content += \"<h4>Common Items</h4>\\n<ul>\\n\"\n",
        "                    for item_name in stats.get('common_items', []):\n",
        "                        html_content += f\"<li>{item_name}</li>\\n\"\n",
        "                    html_content += \"</ul>\\n\"\n",
        "\n",
        "                    html_content += \"<h4>Missed Items</h4>\\n<ul>\\n\"\n",
        "                    for item_name in stats.get('missed_items', []):\n",
        "                        html_content += f\"<li>{item_name}</li>\\n\"\n",
        "                    html_content += \"</ul>\\n\"\n",
        "\n",
        "                    html_content += \"<h4>Extra Items</h4>\\n<ul>\\n\"\n",
        "                    for item_name in stats.get('extra_items', []):\n",
        "                        html_content += f\"<li>{item_name}</li>\\n\"\n",
        "                    html_content += \"</ul>\\n\"\n",
        "\n",
        "                    # Add Type Mismatches\n",
        "                    predicted_dict = stats.get('predicted_dict', {})\n",
        "                    correct_dict = stats.get('correct_dict', {})\n",
        "                    common_items = stats.get('common_items', [])\n",
        "\n",
        "                    mismatches = []\n",
        "                    correctly_concept_classification_matched = 0\n",
        "                    for signifier in common_items:\n",
        "                        predicted_concept_classification = predicted_dict.get(signifier)\n",
        "                        correct_concept_classification = correct_dict.get(signifier)\n",
        "                        if predicted_concept_classification != correct_concept_classification:\n",
        "                            mismatches.append((signifier, correct_concept_classification, predicted_concept_classification))\n",
        "                        else:\n",
        "                            correctly_concept_classification_matched += 1\n",
        "\n",
        "                    html_content += \"<h4>Type Mismatches</h4>\\n<ul>\\n\"\n",
        "                    for signifier, correct_cat, predicted_cat in mismatches:\n",
        "                        html_content += f\"<li>Type mismatch for '{signifier}': Correct concept_classification='{correct_cat}', Predicted concept_classification='{predicted_cat}'</li>\\n\"\n",
        "                    html_content += \"</ul>\\n\"\n",
        "\n",
        "                    # Totals\n",
        "                    total_matched = len(common_items)\n",
        "                    total_correctly_concept_classification_matched = correctly_concept_classification_matched\n",
        "                    total_missed = len(stats.get('missed_items', []))\n",
        "                    total_extra = len(stats.get('extra_items', []))\n",
        "\n",
        "                    html_content += f\"<p>Total matched: {total_matched}, Correctly classification matched: {total_correctly_concept_classification_matched}, Missed: {total_missed}, Extra: {total_extra}</p>\\n\"\n",
        "\n",
        "                    html_content += \"</div>\\n\"\n",
        "\n",
        "                # Classification Report\n",
        "                classification_key = f\"{section_id}|classification_report\"\n",
        "                if classification_key in data:\n",
        "                    html_content += \"<h3>Classification Report</h3>\\n\"\n",
        "                    report = data[classification_key]['content']\n",
        "                    html_content += \"<div class='classification-report'>\\n\"\n",
        "                    html_content += \"<table>\\n<tr><th>concept_classification</th><th>Precision</th><th>Recall</th><th>F1-Score</th><th>Support</th></tr>\\n\"\n",
        "                    for concept_classification, metrics in report.items():\n",
        "                        if concept_classification in ['accuracy', 'macro avg', 'weighted avg']:\n",
        "                            continue\n",
        "\n",
        "                        precision = metrics.get('precision', 0.0)\n",
        "                        recall = metrics.get('recall', 0.0)\n",
        "                        f1_score = metrics.get('f1-score', 0.0)\n",
        "                        support = metrics.get('support', 0)\n",
        "\n",
        "                        html_content += f\"<tr><td>{concept_classification}</td><td>{precision:.2f}</td><td>{recall:.2f}</td><td>{f1_score:.2f}</td><td>{support}</td></tr>\\n\"\n",
        "                    html_content += \"</table>\\n\"\n",
        "                    html_content += \"</div>\\n\"\n",
        "\n",
        "                html_content += \"</div>\\n\"\n",
        "\n",
        "        html_content += \"\"\"\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "        return html_content\n",
        "\n",
        "    # Generate the HTML report\n",
        "    html_report = generate_html_report(data)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(html_report)\n",
        "\n",
        "    logger.info(f\"Report generated and saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMQXP0V6NI4l"
      },
      "outputs": [],
      "source": [
        "def normalize_words(text: str) -> str:\n",
        "    p = inflect.engine()\n",
        "    return p.singular_noun(text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01gkvNXtNI4l"
      },
      "outputs": [],
      "source": [
        "def extract_unique_terms(document: ElementsDocumentModel) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extracts unique terms from the 'terms' attribute of elements within an ElementsDocumentModel instance.\n",
        "\n",
        "    Args:\n",
        "        document (ElementsDocumentModel): The document containing elements, each with a list of terms.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of unique terms found across all elements in the document.\n",
        "\n",
        "    This function iterates through each element of the document, accesses the terms list in each element, and collects\n",
        "    the unique terms. It uses a set to ensure that the terms are unique before converting it back to a list for the output.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a set to store unique terms\n",
        "    unique_terms: Set[str] = set()\n",
        "\n",
        "    # Loop through each element in the 'elements' list of the document\n",
        "    for element in document.elements:\n",
        "        # Loop through the 'terms' list in each element\n",
        "        for term_info in element.terms:\n",
        "            # Add the term to the set\n",
        "            unique_terms.add(term_info.term)\n",
        "\n",
        "    # Convert the set to a list and return it\n",
        "    return list(unique_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOU0Wpm_NI4m",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Prompt to extract / classify elements.\n",
        "\n",
        "Prompt strucuture is based on [1]. It is a zero-shot prompt following the concept of chain of thought.\n",
        "\n",
        "Following the approaches are taken."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYbsDrCwNI4m"
      },
      "source": [
        "##### 1. facts and fact types\n",
        "Try to extract all facts and fact types from a given document.\n",
        "\n",
        "This approach has successful results. It is focused on extracting the elements, and achive the best results, similar to the approach 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYd3tmTJNI4m"
      },
      "outputs": [],
      "source": [
        "system_prompt_facts = \"\"\"\n",
        "\n",
        "You are tasked with extracting **facts**, **fact types**, and their **relationships** from a given document. Follow these steps carefully:\n",
        "\n",
        "#### Steps to Perform:\n",
        "\n",
        "1. **Identify Facts and Fact Types**:\n",
        "   - A **fact** is a specific instance or statement that describes an event or condition.\n",
        "   - A **fact type** is a general template or relationship that defines how entities interact.\n",
        "   - For each fact or fact type:\n",
        "     - Extract the **expression** that represents the fact or fact type.\n",
        "     - List the **terms** (Nouns or Proper nouns) involved in the fact or fact type.\n",
        "     - Identify the **fact symbols** (verbs, verb phrases, or prepositions) connecting the terms.\n",
        "     - Classify the expression as either a **Fact** or **Fact Type**.\n",
        "     - Note the section or paragraph where the fact or fact type appears as the **source**.\n",
        "\n",
        "2. **Classify Terms**:\n",
        "   - For each fact or fact type, classify all **terms**:\n",
        "     - Label each term as either a **Noun** or **Proper Noun**.\n",
        "   - Ensure that the terms are extracted accurately and classified correctly.\n",
        "\n",
        "3. **Define term**:\n",
        "   - For each term look in the document for the term definition. If the term definition is not found, use \"missing\".:\n",
        "\n",
        "4. **Identify Fact Symbols**:\n",
        "   - Extract the verbs or prepositions that define the relationships between the terms. These are referred to as **fact symbols**.\n",
        "   - Each fact or fact type should have a list of fact symbols.\n",
        "\n",
        "5. **Source Information**:\n",
        "   - Record the paragraph or section of the document where each fact or fact type is found as **source** information (e.g., “(a)(1)”, “(b)”).\n",
        "\n",
        "6. **Recognize Term Relationships**:\n",
        "   - Identify relationships between terms:\n",
        "     - **Synonyms**: Terms that can be used interchangeably without changing the meaning.\n",
        "     - **Hypernym-Hyponym**: A broader term (hypernym) that includes a more specific term (hyponym).\n",
        "   - For each pair of terms:\n",
        "     - Identify the relationship (either \"Synonym\" or \"Hypernym-Hyponym\").\n",
        "     - Ensure that both terms involved in the relationship are valid terms from the document.\n",
        "\n",
        "7. **Structure the Output in JSON Format**:\n",
        "   - Create a JSON object with the following structure:\n",
        "     - **facts_and_fact_types**: A list of dictionaries, where each dictionary contains:\n",
        "       - **id**: A unique identifier for the fact or fact type.\n",
        "       - **expression**: The extracted fact or fact type.\n",
        "       - **terms**: A list of dictionaries, where each dictionary has a term and its classification (either \"Noun\" or \"Proper Noun\").\n",
        "       - **fact_symbols**: A list of verb phrases or prepositions connecting the terms.\n",
        "       - **classification**: Either \"Fact\" or \"Fact Type\".\n",
        "       - **source**: The section or paragraph where the fact or fact type appears.\n",
        "     - **terms_relationship**: A list of dictionaries, where each dictionary contains:\n",
        "       - **terms**: A list of two related terms.\n",
        "       - **relation**: Either \"Synonym\" or \"Hypernym-Hyponym\".\n",
        "\n",
        "#### Example Output:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"facts_and_fact_types\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"A person serves a non-resident investment adviser by furnishing the Commission with process, pleadings, or papers.\",\n",
        "      \"terms\": [\n",
        "        {\"Person\": \"Noun\"},\n",
        "        {\"Non-resident investment adviser\": \"Noun\"},\n",
        "        {\"Commission\": \"Proper Noun\"},\n",
        "        {\"Process\": \"Noun\"},\n",
        "        {\"Pleadings\": \"Noun\"},\n",
        "        {\"Papers\": \"Noun\"}\n",
        "      ],\n",
        "      \"fact_symbols\": [\"serves\", \"by furnishing\", \"with\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)\"\n",
        "    }\n",
        "  ],\n",
        "  \"terms_relationship\": [\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Principal office\",\n",
        "        \"Place of business\"\n",
        "      ],\n",
        "      \"relation\": \"Synonym\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "#### Guidelines:\n",
        "- Be precise in identifying **terms** and **fact symbols**.\n",
        "- Classify the relationships between terms accurately as **Synonym** or **Hypernym-Hyponym**.\n",
        "- Ensure the final output adheres to the specified JSON structure.\n",
        "\n",
        "#### Start of the document\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_etiOBANI4m"
      },
      "source": [
        "##### 2. facts, fact types, rules, and terms with definitions\n",
        "\n",
        "Try to extract all facts, fact types, rules, and terms with definitions from a given document. Try to extract the relationships for each term  as well.\n",
        "\n",
        "**Results**\n",
        "\n",
        "The result are fairly consistent, but it failed to extract term's definitions, even when the definition was clear in the text, like in the document 275.0-7 from the fragment \"... the **term** small business or small organization for purposes of the Investment Advisers Act of 1940 shall **mean** an investment adviser that: ...\". The prompt failed to define small business and small organization, what are the main purpose of the document. It also failed to recognize that small business and small organization are synonyms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rVsO4OGNI4m"
      },
      "outputs": [],
      "source": [
        "system_prompt_v1 = \"\"\"\n",
        "You are tasked with extracting **facts**, **fact types**, **rules**, and their **relationships** from a given document. Follow these steps carefully:\n",
        "\n",
        "<steps>\n",
        "\n",
        "1. Summarize the document. Use the summary to verify if all important facts, fact types, and rules are present.\n",
        "\n",
        "2. **Identify Facts, Fact Types, and Rules**:\n",
        "   - A **fact** is a specific instance or statement that describes an event or condition. Facts are statements of truth without any directive element. They are often associated with relationships between terms or entities. e.g., \"John works for X Inc.\".\n",
        "   - A **fact type** is a general, abstract template that describes the potential relationships between terms or entities. It serves as a model for generating specific facts. e.g., \"Person works for Company\".\n",
        "   - A **rule** rule is generally defined as a statement that governs or constrains some aspect of the business. It specifies what must be done or what is not allowed, often guiding actions, decisions, and behaviors within an organization. Rules enforce compliance, limit possibilities, or prescribe specific behaviors in response to business situations. e.g., \"A customer must provide identification before opening an account.\".\n",
        "   - For each fact, fact type, or rule:\n",
        "     - Extract the **expression** that represents the fact, fact type, or rule.\n",
        "     - List the **terms** involved in the fact, fact type, or rule.\n",
        "     - Identify the **verb symbols** (verbs, verb phrases, or prepositions) connecting the terms.\n",
        "     - Classify the expression as either a **Fact**, **Fact Type**, or **Rule**.\n",
        "     - Note the section or paragraph where the fact, fact type, or rule appears as the **source**.\n",
        "     - For each term look in the document for the term definition. If the term definition is not found, use \"missing\".:\n",
        "\n",
        "3. Classify Terms:\n",
        "   - For each fact, fact type, or rule classify all **terms**:\n",
        "     - Label each term as either a **Common Noun** or **Proper Noun**.\n",
        "   - Ensure that the terms are extracted accurately and classified correctly.\n",
        "\n",
        "4. Define term:\n",
        "   - For each term look in the document for the term definition, explaining, or meaning. If the term definition is not found, use \"missing\".:\n",
        "\n",
        "4. Identify Verb Symbols:\n",
        "   - Extract the verbs or prepositions that define the relationships between the terms. These are referred to as **verb symbols**.\n",
        "   - Each fact, fact type, or rule should have a list of verb symbols.\n",
        "\n",
        "5. Source Information:\n",
        "   - Record the paragraph or section of the document where each fact, fact type, or rule is found as **source** information (e.g., \"(a)(1)\", \"(b)\").\n",
        "\n",
        "6. Recognize term relationships:\n",
        "   - Identify relationships between terms:\n",
        "     - **Synonyms**: Terms that can be used interchangeably without changing the meaning.\n",
        "     - **Hypernym-Hyponym**: A broader term (hypernym) that includes a more specific term (hyponym).\n",
        "   - For each pair of terms:\n",
        "     - Identify the relationship (either \"Synonym\" or \"Hypernym-Hyponym\").\n",
        "     - Ensure that both terms involved in the relationship are valid terms from the document.\n",
        "\n",
        "7. Answer only with the output example structure in JSON format. All the values are optional.\n",
        "\n",
        "<output_example>\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"section\": \"§ 123.4-5\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"A person serves a non-resident investment adviser by furnishing the Commission with process, pleadings, or papers.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "            \"term\": \"Person\",\n",
        "            \"classification\": \"Noun\",\n",
        "            \"definition\": \"missing\"\n",
        "        },\n",
        "      ...\n",
        "      ],\n",
        "      \"verb_symbols\": [\"serves\", \"by furnishing\", \"with\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)\"\n",
        "    }\n",
        "  ],\n",
        "  \"terms_relationship\": [\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Principal office\",\n",
        "        \"Place of business\"\n",
        "      ],\n",
        "      \"relation\": \"Synonym\"\n",
        "    }\n",
        "  ]\n",
        "},\n",
        "...\n",
        "```\n",
        "</output_example>\n",
        "\n",
        "</steps>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11OuKtl7NI4m"
      },
      "source": [
        "The v2 is a variation of the v1, with more concise description of the steps, and changing the organization of the text. The results are the same, but there was miss classification of the expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVuECq_8NI4n"
      },
      "outputs": [],
      "source": [
        "system_prompt_v2 = \"\"\"\n",
        "Extract facts, fact types, and their relationships from a given document, and structure the output in a specified JSON format.\n",
        "\n",
        "Follow the steps to identify and classify expressions, using document details to find definitions and source information.\n",
        "\n",
        "# Steps\n",
        "\n",
        "1. **Summarize the Document:**\n",
        "   - Provide a summary to ensure the completeness of identified facts, fact types, and rules.\n",
        "\n",
        "2. **Identify Facts, Fact Types, and Rules:**\n",
        "   - Define and extract each:\n",
        "     - **Fact:** Instance or statement of event/condition, e.g., \"John works for X Inc.\"\n",
        "     - **Fact Type:** Template for relationships, e.g., \"Person works for Company.\"\n",
        "     - **Rule:** Governing statement, e.g., \"A customer must provide identification before opening an account.\"\n",
        "   - For each, document:\n",
        "     - **Expression**\n",
        "     - **Terms** involved\n",
        "     - **Verb Symbols** connecting the terms\n",
        "     - **Classification** as Fact, Fact Type, or Rule\n",
        "     - **Source** paragraph or section in the document\n",
        "\n",
        "3. **Classify Terms:**\n",
        "   - Classify each term as **Common Noun** or **Proper Noun**.\n",
        "\n",
        "4. **Define Term:**\n",
        "   - Locate definitions for terms in the document, or mark as \"missing.\"\n",
        "\n",
        "5. **Identify Verb Symbols:**\n",
        "   - Extract verbs or prepositions (verb symbols) that define term relationships.\n",
        "\n",
        "6. **Source Information:**\n",
        "   - Note the document source (section/paragraph) for each expression.\n",
        "\n",
        "7. **Recognize Term Relationships:**\n",
        "   - Identify pairs of terms with relationships:\n",
        "     - **Synonyms:** interchangeable terms.\n",
        "     - **Hypernym-Hyponym:** broader (hypernym) includes more specific (hyponym).\n",
        "   - Ensure relationship validity using document terms.\n",
        "\n",
        "# Output Format\n",
        "\n",
        "Produce a structured JSON format based on the specified template. Ensure all necessary fields are populated accurately, even if some fields are optional or marked as \"missing\".\n",
        "\n",
        "# Examples\n",
        "\n",
        "**Example JSON Structure:**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"section\": \"§ 123.4-5\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"A person serves a non-resident investment adviser by furnishing the Commission with process, pleadings, or papers.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "            \"term\": \"Person\",\n",
        "            \"classification\": \"Noun\",\n",
        "            \"definition\": \"missing\"\n",
        "        },\n",
        "        // Additional terms...\n",
        "      ],\n",
        "      \"verb_symbols\": [\"serves\", \"by furnishing\", \"with\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)\"\n",
        "    }\n",
        "  ],\n",
        "  \"terms_relationship\": [\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Principal office\",\n",
        "        \"Place of business\"\n",
        "      ],\n",
        "      \"relation\": \"Synonym\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "# Notes\n",
        "\n",
        "- Ensure extracted expressions are fully detailed and clearly classified.\n",
        "- Pay careful attention to identifying and classifying terms accurately.\n",
        "- Follow the precise JSON format for all outputs, populating fields as required.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw3NoyOdNI4n"
      },
      "source": [
        "The v3 is back to v1, changing the organization of the text.\n",
        "\n",
        "**Results**\n",
        "\n",
        "The results are the same of v1 and v2. 5 elements were extracted. 16 terms were extracted with 2 definitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Cu0pLxNI4n"
      },
      "outputs": [],
      "source": [
        "system_prompt_v3 = \"\"\"\n",
        "You are tasked with extracting elements and **relationships** from a given legal document. Please follow these steps carefully and ensure all instructions are adhered to:\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "1. **Summarize the document**:\n",
        "   - Summarize the document to understand its purpose and use it to verify if all important terms, term definitions, facts, fact types, and rules are identified in subsequent steps.\n",
        "\n",
        "2. **Identify Facts, Fact Types, and Rules**:\n",
        "   - **Definitions**:\n",
        "     - **Fact**: A specific instance or statement that describes an event or condition without any directive element. Facts often involve relationships between terms or entities. Example: \"John works for X Inc.\"\n",
        "     - **Fact Type**: A general, abstract template that describes potential relationships between terms or entities, serving as a model for generating specific facts. Example: \"Person works for Company.\"\n",
        "     - **Rule**: A statement that governs or constrains some aspect of the business, specifying what must be done or what is not allowed. Rules enforce compliance, limit possibilities, or prescribe specific behaviors in response to business situations. Example: \"A customer must provide identification before opening an account.\"\n",
        "   - **For each fact, fact type, or rule**:\n",
        "     - **Extract the Expression**: Identify the exact sentence or phrase from the document representing the fact, fact type, or rule.\n",
        "     - **Extract Terms**: List all the terms involved in the expression.\n",
        "     - **Extract Verb Symbols**: Identify verbs, verb phrases, or prepositions that connect the terms in the expression.\n",
        "     - **Classification**: Classify the expression as either a **Fact**, **Fact Type**, or **Rule**.\n",
        "     - **Source**: Note the specific paragraph or section of the document where the expression is found (e.g., \"(a)(1)\", \"(b)\").\n",
        "\n",
        "3. **Classify Terms**:\n",
        "   - For each term extracted classify it as either a **Common Noun** or a **Proper Noun**.\n",
        "\n",
        "4. **Define Terms**:\n",
        "   - For each term:\n",
        "     - Search the entire document for the term's definition, explanation, or meaning. Also, look in the document summary.\n",
        "     - If the definition is found, include it.\n",
        "     - If the definition is not found in the document, use **None**.\n",
        "\n",
        "5. **Identify Relationships Between Terms**:\n",
        "   - **Types of Relationships**:\n",
        "     - **Synonym**: Terms that can be used interchangeably without changing the meaning.\n",
        "     - **Hypernym-Hyponym**: A broader term (hypernym) that includes a more specific term (hyponym).\n",
        "   - **For each pair of terms in the document**:\n",
        "     - Identify if a relationship exists as either \"Synonym\" or \"Hypernym-Hyponym\".\n",
        "     - Only include relationships where both terms are present in the document.\n",
        "\n",
        "6. **Provide JSON Output**:\n",
        "   - Format your answer as per the output example below.\n",
        "   - **All values are optional**: Include as much information as is available based on the document.\n",
        "   - **Do not include any additional text or explanation outside the JSON structure**.\n",
        "\n",
        "**Output Example**:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"section\": \"§ 123.4-5\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"A person serves a non-resident investment adviser by furnishing the Commission with process, pleadings, or papers.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": \"An individual or legal entity.\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Non-resident investment adviser\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": null\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"verb_symbols\": [\"serves\", \"by furnishing\", \"with\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)\"\n",
        "    },\n",
        "    ...\n",
        "  ],\n",
        "  \"terms_relationship\": [\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Principal office\",\n",
        "        \"Place of business\"\n",
        "      ],\n",
        "      \"relation\": \"Synonym\"\n",
        "    },\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Person\",\n",
        "        \"Individual\"\n",
        "      ],\n",
        "      \"relation\": \"Synonym\"\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAlVXStZNI4n"
      },
      "outputs": [],
      "source": [
        "response_prompt_v3 = {\n",
        "  \"section\": \"§ 275.0-7\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"An investment adviser that has assets under management of less than $25 million is considered a small business for the purposes of the Investment Advisers Act of 1940.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Assets under management\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$25 million\",\n",
        "          \"classification\": \"Proper Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Small business\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"has\", \"is considered\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)(1)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2,\n",
        "      \"expression\": \"An investment adviser is considered a small organization if it did not have total assets of $5 million or more on the last day of the most recent fiscal year.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Total assets\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$5 million\",\n",
        "          \"classification\": \"Proper Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Small organization\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Fiscal year\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"did not have\", \"is considered\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)(2)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 3,\n",
        "      \"expression\": \"An investment adviser is not considered a small business if it controls, is controlled by, or is under common control with another investment adviser that has assets under management of $25 million or more.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Control\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": \"The power, directly or indirectly, to direct the management or policies of a person.\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Common control\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$25 million\",\n",
        "          \"classification\": \"Proper Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Small business\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"controls\", \"is controlled by\", \"is under\"],\n",
        "      \"classification\": \"Rule\",\n",
        "      \"source\": \"(a)(3)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 4,\n",
        "      \"expression\": \"Control means the power, directly or indirectly, to direct the management or policies of a person, whether through ownership of securities, by contract, or otherwise.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Control\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": \"The power, directly or indirectly, to direct the management or policies of a person.\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Securities\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Contract\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"means\", \"to direct\", \"whether through\"],\n",
        "      \"classification\": \"Fact\",\n",
        "      \"source\": \"(b)(1)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 5,\n",
        "      \"expression\": \"A person is presumed to control a corporation if the person has the right to vote 25 percent or more of a class of the corporation's voting securities.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Corporation\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Voting securities\",\n",
        "          \"classification\": \"Common Noun\",\n",
        "          \"definition\": None\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"25 percent\",\n",
        "          \"classification\": \"Proper Noun\",\n",
        "          \"definition\": None\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"is presumed\", \"to control\", \"has the right to vote\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(b)(1)(i)(A)\"\n",
        "    }\n",
        "  ],\n",
        "  \"terms_relationship\": [\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Investment adviser\",\n",
        "        \"Small business\"\n",
        "      ],\n",
        "      \"relation\": \"Hypernym-Hyponym\"\n",
        "    },\n",
        "    {\n",
        "      \"terms\": [\n",
        "        \"Investment adviser\",\n",
        "        \"Small organization\"\n",
        "      ],\n",
        "      \"relation\": \"Hypernym-Hyponym\"\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RbFwEuKNI4n",
        "outputId": "26898624-5bd6-4f75-e038-2fb4a21aec68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 2)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response_prompt_v3[\"elements\"]), len(response_prompt_v3[\"terms_relationship\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH-K-o0pNI4o"
      },
      "source": [
        "##### 3. facts, fact types, rules, and terms\n",
        "\n",
        "Try to extract all facts, fact types, rules, and terms without definitions from a given document, and do not try to extract the relationships for each term.\n",
        "\n",
        "This approach is very similar to the approach used in the previous, but it is more focused on extracting the elements. It is divided in two parts:\n",
        "- Extract the elements\n",
        "- Extract the definitions and relationships\n",
        "\n",
        "**Results**\n",
        "\n",
        "The result are consistents, 7 elements and 21 terms with definitions are extracted. in contrast, the previous approach, 5 elements and 16 terms with 2 definitions were extracted. An improvement of 40% extracting facts and rules, 31% extracting terms, and 1050% extracting definitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Sn9a3VNI4o"
      },
      "source": [
        "ts are extracted in the first part. For the second part the result are much better than the previous approach, more definitions and relationships are extracted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TZ-V3rONI4o"
      },
      "source": [
        "The prompt for the first part is similar to the previous one, but without the steps 4 and 5. The definition and relationships elements are removed from the output json.\n",
        "\n",
        "> The summary of the document was added to the output json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgGnT0BJNI4o"
      },
      "outputs": [],
      "source": [
        "system_prompt_v4_1 = \"\"\"\n",
        "You are tasked with extracting elements from a given legal document. Please follow these steps carefully and ensure all instructions are adhered to:\n",
        "\n",
        "# Steps\n",
        "\n",
        "1. **Summarize the document** to understand its purpose and use it to verify if all important terms,facts, fact types, and rules are identified in subsequent steps.\n",
        "\n",
        "2. **Identify elements**:\n",
        "   - **About the elements**:\n",
        "     - **Fact**: A specific instance or statement that describes an event or condition without any directive element. Facts often involve relationships between terms or entities. Example: \"John works for X Inc.\"\n",
        "     - **Fact Type**: A general, abstract template that describes potential relationships between terms or entities, serving as a model for generating specific facts. Example: \"Person works for Company.\"\n",
        "     - **Rule**: A statement that governs or constrains some aspect of the business, specifying what must be done or what is not allowed. Rules enforce compliance, limit possibilities, or prescribe specific behaviors in response to business situations. Example: \"A customer must provide identification before opening an account.\"\n",
        "     - **Term**: A word or a group of words that represents a specific concept, entity, or subject in a particular context.\n",
        "   - **For each fact, fact type, or rule**:\n",
        "     - **Extract the Expression**: Identify the exact sentence or phrase from the document representing the fact, fact type, or rule.\n",
        "     - **Extract and classify Terms**:\n",
        "       - **Extract all the terms involved in the expression.\n",
        "       - **Classify each term** as either **Common Noun** or **Proper Noun**.\n",
        "       - If a Term contains nouns separated by \"and,\" \",\", or \"or,\" split it into two or more terms. For example, \"Principal office and place of business\" should be split into \"Principal office\" and \"Place of business\".\n",
        "     - **Extract Verb Symbols**: Identify verbs, verb phrases, or prepositions that connect the terms in the expression.\n",
        "     - **Classification**: Classify the expression as either a **Fact**, **Fact Type**, or **Rule**.\n",
        "     - **Source**: Note the specific paragraph or section of the document where the expression is found (e.g., \"(a)(1)\", \"(b)\").\n",
        "\n",
        "3. **Provide JSON Output**:\n",
        "   - Format your answer as per the output example below.\n",
        "   - **All values are optional**: Include as much information as is available based on the document.\n",
        "   - **Do not include any additional text or explanation outside the JSON structure**.\n",
        "\n",
        "**Output Example**:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"section\": \"§ 123.4-5\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"A person serves a non-resident investment adviser by furnishing the Commission with process, pleadings, or papers.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Non-resident investment adviser\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"verb_symbols\": [\"serves\", \"by furnishing\", \"with\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(a)\"\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nx9JcGzNI4o"
      },
      "outputs": [],
      "source": [
        "response_prompt_v4_1 = {\n",
        "  \"section\": \"§ 275.0-7\",\n",
        "  \"summary\": \"The definition of small entities under the Investment Advisers Act for the purposes of the Regulatory Flexibility Act. It details criteria for qualifying as a small business or organization and provides definitions for 'control' and 'total assets' within this context.\",\n",
        "  \"elements\": [\n",
        "    {\n",
        "      \"id\": 1,\n",
        "      \"expression\": \"The term small business or small organization for purposes of the Investment Advisers Act of 1940 shall mean an investment adviser that has assets under management of less than $25 million.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Small business\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Small organization\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Assets under management\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$25 million\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"mean\", \"has\"],\n",
        "      \"classification\": \"Fact\",\n",
        "      \"source\": \"(a)(1)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 2,\n",
        "      \"expression\": \"An investment adviser did not have total assets of $5 million or more on the last day of the most recent fiscal year.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Total assets\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$5 million\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Fiscal year\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"did not have\"],\n",
        "      \"classification\": \"Fact\",\n",
        "      \"source\": \"(a)(2)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 3,\n",
        "      \"expression\": \"An investment adviser does not control, is not controlled by, and is not under common control with another investment adviser that has assets under management of $25 million or more.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Control\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"$25 million\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"does not control\", \"is not controlled by\", \"is not under common control with\"],\n",
        "      \"classification\": \"Fact\",\n",
        "      \"source\": \"(a)(3)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 4,\n",
        "      \"expression\": \"Control means the power, directly or indirectly, to direct the management or policies of a person, whether through ownership of securities, by contract, or otherwise.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Control\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Power\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Management\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Policies\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"means\", \"to direct\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(b)(1)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 5,\n",
        "      \"expression\": \"A person is presumed to control a corporation if the person directly or indirectly has the right to vote 25 percent or more of a class of the corporation's voting securities.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Corporation\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Voting securities\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"25 percent\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"is presumed to control\", \"has the right to vote\"],\n",
        "      \"classification\": \"Rule\",\n",
        "      \"source\": \"(b)(1)(i)(A)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 6,\n",
        "      \"expression\": \"A person is presumed to control a partnership if the person has the right to receive upon dissolution, or has contributed, 25 percent or more of the capital of the partnership.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Person\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Partnership\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Dissolution\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Capital\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"25 percent\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"is presumed to control\", \"has the right to receive\", \"has contributed\"],\n",
        "      \"classification\": \"Rule\",\n",
        "      \"source\": \"(b)(1)(ii)\"\n",
        "    },\n",
        "    {\n",
        "      \"id\": 7,\n",
        "      \"expression\": \"Total assets means the total assets as shown on the balance sheet of the investment adviser or other person with its subsidiaries consolidated, whichever is larger.\",\n",
        "      \"terms\": [\n",
        "        {\n",
        "          \"term\": \"Total assets\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Balance sheet\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Investment adviser\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        },\n",
        "        {\n",
        "          \"term\": \"Subsidiaries\",\n",
        "          \"classification\": \"Common Noun\"\n",
        "        }\n",
        "      ],\n",
        "      \"verb_symbols\": [\"means\", \"shown on\"],\n",
        "      \"classification\": \"Fact Type\",\n",
        "      \"source\": \"(b)(2)\"\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAeHJIQMNI4o",
        "outputId": "42727107-5854-48b7-aad7-d79a1a4f05d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response_prompt_v4_1[\"elements\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QnYsgEmNI4p"
      },
      "source": [
        "The steps 4 and 5 are adapted from the previous approach. The system prompt for the second part is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c11rygwNI4p"
      },
      "outputs": [],
      "source": [
        "system_prompt_v4_2 = \"\"\"\n",
        "You are tasked with extracting definitions and **relationships** of terms in the terms list searching a given legal document. Please follow these steps carefully and ensure all instructions are adhered to:\n",
        "\n",
        "# Steps\n",
        "\n",
        "1. **Summarize the document** to understand its purpose and use it to verify if all important terms, term definitions, facts, fact types, and rules are identified in subsequent steps.\n",
        "\n",
        "2. **Define terms**:\n",
        "  - For each term:\n",
        "    - Search the entire document for the term's definition, explanation, or meaning. Also, look in the document summary.\n",
        "    - If the definition is found, include it.\n",
        "    - If the definition is not found in the document, use null.\n",
        "\n",
        "3. **Identify synonym relationships between terms**:\n",
        "  - For each term in the terms list:\n",
        "    - Compare it against other terms in the text to find synonyms.\n",
        "    - Ensure both terms exist within the same document context.\n",
        "  - List all valid synonym pairs identified.\n",
        "\n",
        "4. **Provide JSON Output**:\n",
        "  - Format your answer as per the output example below.\n",
        "  - **All values are optional**: Include as much information as is available based on the document.\n",
        "  - **Do not include any additional text or explanation outside the JSON structure**.\n",
        "\n",
        "**Output Example**:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"terms\": [\n",
        "    {\n",
        "      \"term\": \"Person\",\n",
        "      \"definition\": \"A person is a person.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Capital\",\n",
        "      \"definition\": \"The total assets of a person.\"\n",
        "    },\n",
        "    ...\n",
        "  ],\n",
        "  \"relationships\": [\n",
        "    {\n",
        "      \"term_1\": \"Person\",\n",
        "      \"term_2\": \"Capital\",\n",
        "      \"relationship\": \"Synonym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"Capital\",\n",
        "      \"term_2\": \"Person\",\n",
        "      \"relationship\": \"Synonym\"\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUj0qs56NI4p"
      },
      "source": [
        "In the \"user prompt\", along with the document, a unique list of terms from the result of the previous part, is provided. The drawback of this approach is the document needs to be provided again. It means spending more tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXzRGbC-NI4p"
      },
      "source": [
        "As commented above, the output is better than the previous approach. 21 terms are extracted with definitions, and 6 relationships are identified. More important that the terms small business, and, small organization are extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sU6fhaPNI4p"
      },
      "outputs": [],
      "source": [
        "response_prompt_v4_2 = {\n",
        "  \"terms\": [\n",
        "    {\n",
        "      \"term\": \"$5 million\",\n",
        "      \"definition\": \"An amount referenced as a threshold for total assets of an investment adviser or other entity on the last day of the most recent fiscal year.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Control\",\n",
        "      \"definition\": \"The power, directly or indirectly, to direct the management or policies of a person, whether through ownership of securities, by contract, or otherwise.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Capital\",\n",
        "      \"definition\": \"The amount of financial contribution or investment in a partnership or LLC, particularly relevant to the right to receive upon dissolution or contribution of 25 percent or more.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Dissolution\",\n",
        "      \"definition\": \"The act of formally ending a partnership or LLC, at which point capital contributions may be distributed.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"25 percent\",\n",
        "      \"definition\": \"A threshold used to presume control over a corporation, partnership, or LLC, based on ownership, voting rights, or capital contribution.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Subsidiaries\",\n",
        "      \"definition\": \"Companies that are controlled by another company, typically through ownership of more than 50% of the subsidiary’s voting stock.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Management\",\n",
        "      \"definition\": \"The act of overseeing and controlling the policies or operations of an entity.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Corporation\",\n",
        "      \"definition\": \"A legal entity that is presumed to be controlled if a person has the right to vote or sell 25 percent or more of its voting securities.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Balance sheet\",\n",
        "      \"definition\": \"A financial statement that reports total assets, used to determine control and asset thresholds for investment advisers.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Assets under management\",\n",
        "      \"definition\": \"The total market value of investments that an investment adviser manages on behalf of clients.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"$25 million\",\n",
        "      \"definition\": \"An amount referenced as a threshold for assets under management to determine whether an entity qualifies as a small business or small organization under the Investment Advisers Act.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Fiscal year\",\n",
        "      \"definition\": \"A one-year period used for accounting purposes and preparing financial statements, relevant to determining total assets.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Voting securities\",\n",
        "      \"definition\": \"Securities that give the holder the right to vote on matters of corporate policy or management, used to determine control.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Power\",\n",
        "      \"definition\": \"The ability to influence or direct the management or policies of a person or entity, often associated with control.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Total assets\",\n",
        "      \"definition\": \"The total value of all assets as shown on an entity's balance sheet, including those of subsidiaries, used to assess financial thresholds.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Investment adviser\",\n",
        "      \"definition\": \"An individual or firm that manages the investments of clients, subject to regulations under the Investment Advisers Act of 1940.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Person\",\n",
        "      \"definition\": \"An individual, corporation, partnership, LLC, trust, or other entity, potentially subject to control rules under the Investment Advisers Act.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Small business\",\n",
        "      \"definition\": \"An investment adviser with less than $25 million in assets under management and less than $5 million in total assets, or as otherwise defined by the Commission.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Partnership\",\n",
        "      \"definition\": \"A business structure where control is presumed if a person owns or contributes 25 percent or more of the partnership's capital.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Small organization\",\n",
        "      \"definition\": \"An entity, such as an investment adviser, that qualifies as a small business under the Investment Advisers Act by meeting specific asset thresholds.\"\n",
        "    },\n",
        "    {\n",
        "      \"term\": \"Policies\",\n",
        "      \"definition\": \"The principles or rules governing the management and control of an entity, relevant to determining control under the Investment Advisers Act.\"\n",
        "    }\n",
        "  ],\n",
        "  \"relationships\": [\n",
        "    {\n",
        "      \"term_1\": \"Small business\",\n",
        "      \"term_2\": \"Small organization\",\n",
        "      \"relationship\": \"Synonym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"$5 million\",\n",
        "      \"term_2\": \"Total assets\",\n",
        "      \"relationship\": \"Hypernym-Hyponym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"$25 million\",\n",
        "      \"term_2\": \"Assets under management\",\n",
        "      \"relationship\": \"Hypernym-Hyponym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"Person\",\n",
        "      \"term_2\": \"Corporation\",\n",
        "      \"relationship\": \"Hypernym-Hyponym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"Person\",\n",
        "      \"term_2\": \"Partnership\",\n",
        "      \"relationship\": \"Hypernym-Hyponym\"\n",
        "    },\n",
        "    {\n",
        "      \"term_1\": \"Person\",\n",
        "      \"term_2\": \"Investment adviser\",\n",
        "      \"relationship\": \"Hypernym-Hyponym\"\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKC7ggC6NI4p",
        "outputId": "78ec7265-41f3-4f09-f238-3bb129592452"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21, 6)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(response_prompt_v4_2[\"terms\"]), len(response_prompt_v4_2[\"relationships\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mSGRAKiNI4p"
      },
      "source": [
        "##### Save checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCxr7w8dNI4q"
      },
      "source": [
        "Define which prompt will be used in the experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-9OhOkHNI4q"
      },
      "outputs": [],
      "source": [
        "system_prompt_part_1 = system_prompt_v4_1\n",
        "system_prompt_part_2 = system_prompt_v4_2\n",
        "\n",
        "manager.add_document(\n",
        "    Document(\n",
        "        id=\"prompt-v4-P1\",\n",
        "        type=\"prompt\",\n",
        "        content=f\"\"\"\n",
        "{system_prompt_part_1}\n",
        "        \"\"\",\n",
        "    )\n",
        ")\n",
        "\n",
        "manager.add_document(\n",
        "    Document(\n",
        "        id=\"prompt-v4-P2\",\n",
        "        type=\"prompt\",\n",
        "        content=f\"\"\"\n",
        "{system_prompt_part_2}\n",
        "        \"\"\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxqNhEMYNI4q",
        "outputId": "7dbd96ba-fed3-40a9-a551-763e378af027"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-28 23:04:54 - INFO - Checkpoint saved.\n"
          ]
        }
      ],
      "source": [
        "# Persist the state to a file\n",
        "save_checkpoint(manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhX_VNGgNI4q",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Query LLM with documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKjeZ3wVNI4q",
        "outputId": "7e3b9c94-3f93-4cf9-dad4-d6a07e1c54cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:09:33 - INFO - Checkpoint restored from ../checkpoints/documents-2024-10-29-1.json.\n"
          ]
        }
      ],
      "source": [
        "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90H-4KDjNI4q",
        "outputId": "99d46cee-40fd-4304-c775-5740885c0671"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-28 23:08:29 - INFO - Processing document: § 275.0-2\n",
            "2024-10-28 23:08:29 - INFO - P1. Extracting elements...\n",
            "2024-10-28 23:08:32 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out\n",
            "2024-10-28 23:08:36 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: timed out\n",
            "2024-10-28 23:08:41 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: timed out\n",
            "2024-10-28 23:08:41 - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
            "2024-10-28 23:08:44 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out\n",
            "2024-10-28 23:08:48 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: timed out\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[72], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m     user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m# Document\u001b[39m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mmanager\u001b[38;5;241m.\u001b[39mretrieve_document(doc_id\u001b[38;5;241m=\u001b[39mdoc,\u001b[38;5;250m \u001b[39mdoc_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP1. Extracting elements...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     response_part_1 \u001b[38;5;241m=\u001b[39m \u001b[43mquery_instruct_llm_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt_part_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mElementsDocumentModel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(response_part_1)\n\u001b[1;32m     17\u001b[0m     doc_1 \u001b[38;5;241m=\u001b[39m Document(\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_P1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_response\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m         content\u001b[38;5;241m=\u001b[39mresponse_part_1\n\u001b[1;32m     21\u001b[0m     )\n",
            "Cell \u001b[0;32mIn[39], line 7\u001b[0m, in \u001b[0;36mmeasure_time.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      6\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 7\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      9\u001b[0m     elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
            "Cell \u001b[0;32mIn[71], line 25\u001b[0m, in \u001b[0;36mquery_instruct_llm_gemini\u001b[0;34m(system_prompt, user_prompt, document_model)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mQueries the LLM with the given system and user prompts.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Exception: If the API call fails.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m client \u001b[38;5;241m=\u001b[39m instructor\u001b[38;5;241m.\u001b[39mfrom_gemini(\n\u001b[1;32m     20\u001b[0m     client\u001b[38;5;241m=\u001b[39mgenai\u001b[38;5;241m.\u001b[39mGenerativeModel(\n\u001b[1;32m     21\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/gemini-1.5-flash-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# model defaults to \"gemini-pro\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     ),\n\u001b[1;32m     23\u001b[0m     mode\u001b[38;5;241m=\u001b[39minstructor\u001b[38;5;241m.\u001b[39mMode\u001b[38;5;241m.\u001b[39mGEMINI_JSON,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/instructor/client.py:172\u001b[0m, in \u001b[0;36mInstructor.create\u001b[0;34m(self, response_model, messages, max_retries, validation_context, context, strict, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     response_model: \u001b[38;5;28mtype\u001b[39m[T] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    169\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m Any \u001b[38;5;241m|\u001b[39m Awaitable[T] \u001b[38;5;241m|\u001b[39m Awaitable[Any]:\n\u001b[1;32m    170\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_kwargs(kwargs)\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/instructor/patch.py:188\u001b[0m, in \u001b[0;36mpatch.<locals>.new_create_sync\u001b[0;34m(response_model, validation_context, context, max_retries, strict, hooks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m response_model, new_kwargs \u001b[38;5;241m=\u001b[39m handle_response_model(\n\u001b[1;32m    183\u001b[0m     response_model\u001b[38;5;241m=\u001b[39mresponse_model, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    184\u001b[0m )\n\u001b[1;32m    186\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m handle_templating(new_kwargs, context)\n\u001b[0;32m--> 188\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/instructor/retry.py:134\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRetrying, attempt: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mattempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattempt_number\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/tenacity/__init__.py:443\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/instructor/retry.py:139\u001b[0m, in \u001b[0;36mretry_sync\u001b[0;34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     hooks\u001b[38;5;241m.\u001b[39memit_completion_arguments(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 139\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     hooks\u001b[38;5;241m.\u001b[39memit_completion_response(response)\n\u001b[1;32m    141\u001b[0m     response \u001b[38;5;241m=\u001b[39m update_total_usage(\n\u001b[1;32m    142\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse, total_usage\u001b[38;5;241m=\u001b[39mtotal_usage\n\u001b[1;32m    143\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/generativeai/generative_models.py:317\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    314\u001b[0m     request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_generative_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     request_options \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/generativeai/client.py:358\u001b[0m, in \u001b[0;36mget_default_generative_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_generative_client\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m glm\u001b[38;5;241m.\u001b[39mGenerativeServiceClient:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_client\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/generativeai/client.py:287\u001b[0m, in \u001b[0;36m_ClientManager.get_default_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients[name] \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/generativeai/client.py:239\u001b[0m, in \u001b[0;36m_ClientManager.make_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch_colab_gce_credentials():\n\u001b[0;32m--> 239\u001b[0m         client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:687\u001b[0m, in \u001b[0;36mGenerativeServiceClient.__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    678\u001b[0m transport_init: Union[\n\u001b[1;32m    679\u001b[0m     Type[GenerativeServiceTransport],\n\u001b[1;32m    680\u001b[0m     Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport], transport)\n\u001b[1;32m    685\u001b[0m )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:154\u001b[0m, in \u001b[0;36mGenerativeServiceGrpcTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[1;32m    150\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m    151\u001b[0m             )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:100\u001b[0m, in \u001b[0;36mGenerativeServiceTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[1;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[0;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/_default.py:659\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    647\u001b[0m checkers \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: _get_gce_credentials(request, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id),\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checker \u001b[38;5;129;01min\u001b[39;00m checkers:\n\u001b[0;32m--> 659\u001b[0m     credentials, project_id \u001b[38;5;241m=\u001b[39m \u001b[43mchecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         credentials \u001b[38;5;241m=\u001b[39m with_scopes_if_required(\n\u001b[1;32m    662\u001b[0m             credentials, scopes, default_scopes\u001b[38;5;241m=\u001b[39mdefault_scopes\n\u001b[1;32m    663\u001b[0m         )\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/_default.py:655\u001b[0m, in \u001b[0;36mdefault.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CredentialsWithQuotaProject\n\u001b[1;32m    643\u001b[0m explicit_project_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    644\u001b[0m     environment_vars\u001b[38;5;241m.\u001b[39mPROJECT, os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(environment_vars\u001b[38;5;241m.\u001b[39mLEGACY_PROJECT)\n\u001b[1;32m    645\u001b[0m )\n\u001b[1;32m    647\u001b[0m checkers \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# Avoid passing scopes here to prevent passing scopes to user credentials.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# with_scopes_if_required() below will ensure scopes/default scopes are\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# safely set on the returned credentials since requires_scopes will\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# guard against setting scopes on user credentials.\u001b[39;00m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: _get_explicit_environ_credentials(quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id),\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: _get_gcloud_sdk_credentials(quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id),\n\u001b[1;32m    654\u001b[0m     _get_gae_credentials,\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43m_get_gce_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checker \u001b[38;5;129;01min\u001b[39;00m checkers:\n\u001b[1;32m    659\u001b[0m     credentials, project_id \u001b[38;5;241m=\u001b[39m checker()\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/_default.py:328\u001b[0m, in \u001b[0;36m_get_gce_credentials\u001b[0;34m(request, quota_project_id)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     request \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mtransport\u001b[38;5;241m.\u001b[39m_http_client\u001b[38;5;241m.\u001b[39mRequest()\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_on_gce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Get the project ID.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m         project_id \u001b[38;5;241m=\u001b[39m _metadata\u001b[38;5;241m.\u001b[39mget_project_id(request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/compute_engine/_metadata.py:78\u001b[0m, in \u001b[0;36mis_on_gce\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_on_gce\u001b[39m(request):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks to see if the code runs on Google Compute Engine\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        bool: True if the code runs on Google Compute Engine, False otherwise.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;66;03m# TODO: implement GCE residency detection on Windows\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/compute_engine/_metadata.py:131\u001b[0m, in \u001b[0;36mping\u001b[0;34m(request, timeout, retry_count)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m backoff:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_METADATA_IP_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m         metadata_flavor \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(_METADATA_FLAVOR_HEADER)\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    137\u001b[0m             response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m http_client\u001b[38;5;241m.\u001b[39mOK\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m metadata_flavor \u001b[38;5;241m==\u001b[39m _METADATA_FLAVOR_VALUE\n\u001b[1;32m    139\u001b[0m         )\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/site-packages/google/auth/transport/_http_client.py:104\u001b[0m, in \u001b[0;36mRequest.__call__\u001b[0;34m(self, url, method, body, headers, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method, url)\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Response(response)\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:1303\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1301\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1349\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1298\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:1058\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1056\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1058\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1061\u001b[0m \n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1064\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:996\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 996\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    998\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/http/client.py:962\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/ipt-cfr2sbvr/lib/python3.11/socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 836\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    838\u001b[0m exceptions\u001b[38;5;241m.\u001b[39mclear()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for doc in manager.list_document_ids(doc_type=\"section\"):\n",
        "    logger.info(f\"Processing document: {doc}\")\n",
        "    retrieved_doc = manager.retrieve_document(doc_id=doc, doc_type=\"section\")\n",
        "\n",
        "    # Part 1 - Extraction of elements\n",
        "    user_prompt = f\"\"\"\n",
        "# Document\n",
        "\n",
        "{manager.retrieve_document(doc_id=doc, doc_type=\"section\").content}\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"P1. Extracting elements...\")\n",
        "    response_part_1 = query_instruct_llm(system_prompt_part_1, user_prompt, ElementsDocumentModel)\n",
        "\n",
        "    logger.debug(response_part_1)\n",
        "\n",
        "    doc_1 = Document(\n",
        "        id=f\"{doc}_P1\",\n",
        "        type=\"llm_response\",\n",
        "        content=response_part_1\n",
        "    )\n",
        "    manager.add_document(doc_1)\n",
        "\n",
        "    # Part 2 - Definition of terms and relationships\n",
        "    terms_list_part_1 = extract_unique_terms(response_part_1)\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "# Terms list\n",
        "\n",
        "{terms_list_part_1}\n",
        "\n",
        "# Document\n",
        "{manager.retrieve_document(doc_id=doc, doc_type=\"section\").content}\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"P2. Extracting terms and relationships...\")\n",
        "    response_part_2 = query_instruct_llm(system_prompt_part_2, user_prompt, TermsDocumentModel)\n",
        "\n",
        "    logger.debug(response_part_2)\n",
        "\n",
        "    doc_2 = Document(\n",
        "        id=f\"{doc}_P2\",\n",
        "        type=\"llm_response\",\n",
        "        content=response_part_2\n",
        "    )\n",
        "    manager.add_document(doc_2)\n",
        "\n",
        "    logger.info(\"Saving llm_response to checkpoint...\")\n",
        "\n",
        "    # Save each document to save money.\n",
        "    save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)\n",
        "\n",
        "logger.info(\"Finished processing documents.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiWIfLLLNI4q"
      },
      "source": [
        "Avarage execution time: 32s / per document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beCnjH-9NI4r"
      },
      "source": [
        "#### Restore checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP4unlYlNI4r"
      },
      "outputs": [],
      "source": [
        "# Restore checkpoint\n",
        "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnsB1aOPNI4r"
      },
      "source": [
        "#### Check content of llm_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfmi4S3DNI4r"
      },
      "source": [
        "Create P1 dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CnDX1jXNI4r"
      },
      "outputs": [],
      "source": [
        "# Define the path where your JSON files are located\n",
        "json_files_path = f\"{config['DEFAULT_CHECKPOINT_DIR']}/*.json\"\n",
        "\n",
        "# List of all JSON files in the directory\n",
        "all_files = glob.glob(json_files_path)\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Loop through each file\n",
        "for file_path in all_files:\n",
        "    with open(file_path, \"r\") as file:\n",
        "        # Load JSON content\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error reading {file_path}, skipping this file.\")\n",
        "            continue\n",
        "\n",
        "        # Filter keys that end with '_P1|llm_response'\n",
        "        filtered_data = {\n",
        "            key: value\n",
        "            for key, value in data.items()\n",
        "            if key.endswith(\"_P1|llm_response\")\n",
        "        }\n",
        "\n",
        "        # Check if filtered_data is empty\n",
        "        if not filtered_data:\n",
        "            print(f\"No matching keys in {file_path}, skipping this file.\")\n",
        "            continue\n",
        "\n",
        "        # Normalize the JSON data to create a DataFrame, expand elements, terms, and verb_symbols\n",
        "        try:\n",
        "            df = pd.json_normalize(\n",
        "                filtered_data.values(),\n",
        "                sep=\"_\",\n",
        "                record_path=[\n",
        "                    \"content\",\n",
        "                    \"elements\",\n",
        "                    \"terms\",\n",
        "                ],  # Expands elements -> terms\n",
        "                meta=[\n",
        "                    \"id\",\n",
        "                    \"type\",\n",
        "                    [\"content\", \"section\"],\n",
        "                    [\"content\", \"summary\"],\n",
        "                    [\"content\", \"elements\", \"id\"],\n",
        "                    [\"content\", \"elements\", \"expression\"],\n",
        "                    [\"content\", \"elements\", \"classification\"],\n",
        "                    [\"content\", \"elements\", \"source\"],\n",
        "                ],\n",
        "                meta_prefix=\"meta_\",\n",
        "            )\n",
        "\n",
        "            # Expand verb_symbols into separate columns (as a list is in the elements, but not nested further)\n",
        "            df_verb_symbols = pd.json_normalize(\n",
        "                filtered_data.values(),\n",
        "                sep=\"_\",\n",
        "                record_path=[\"content\", \"elements\"],\n",
        "                meta=[\"id\", \"type\", [\"content\", \"section\"], [\"content\", \"summary\"]],\n",
        "                meta_prefix=\"meta_\",\n",
        "            )\n",
        "\n",
        "            # Join verb_symbols with the original df\n",
        "            df[\"verb_symbols\"] = df_verb_symbols[\"verb_symbols\"].apply(\n",
        "                lambda x: \", \".join(x) if isinstance(x, list) else x\n",
        "            )\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"Error normalizing data from {file_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Extract just the filename without directory\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        # Add a column for the filename\n",
        "        df[\"filename\"] = filename\n",
        "\n",
        "        # Append the DataFrame to the list\n",
        "        dataframes.append(df)\n",
        "\n",
        "# Check if there are any dataframes to concatenate\n",
        "if dataframes:\n",
        "    # Concatenate all DataFrames into one\n",
        "    elements_p1_df = pd.concat(dataframes, ignore_index=True)\n",
        "else:\n",
        "    print(\"No valid dataframes to concatenate.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-80LXzrNI4r"
      },
      "outputs": [],
      "source": [
        "elements_p1_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZlihJZrNI4r"
      },
      "outputs": [],
      "source": [
        "elements_p1_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEQbhLnCNI4s"
      },
      "source": [
        "Create dataframe for P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZVGFK_mNI4s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Define the path where your JSON files are located\n",
        "json_files_path = f\"{config['DEFAULT_CHECKPOINT_DIR']}/*.json\"\n",
        "\n",
        "# List of all JSON files in the directory\n",
        "all_files = glob.glob(json_files_path)\n",
        "\n",
        "# Initialize an empty list to store DataFrames for terms and relationships\n",
        "terms_dataframes = []\n",
        "terms_relationship_dataframes = []\n",
        "\n",
        "# Loop through each file\n",
        "for file_path in all_files:\n",
        "    with open(file_path, \"r\") as file:\n",
        "        # Load JSON content\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error reading {file_path}, skipping this file.\")\n",
        "            continue\n",
        "\n",
        "        # Filter keys that end with '_P2|llm_response'\n",
        "        filtered_data = {\n",
        "            key: value\n",
        "            for key, value in data.items()\n",
        "            if key.endswith(\"_P2|llm_response\")\n",
        "        }\n",
        "\n",
        "        # Check if filtered_data is empty\n",
        "        if not filtered_data:\n",
        "            print(f\"No matching keys in {file_path}, skipping this file.\")\n",
        "            continue\n",
        "\n",
        "        # Process each matched entry in filtered_data\n",
        "        for key, value in filtered_data.items():\n",
        "            try:\n",
        "                # Extract the terms\n",
        "                terms = value['content']['terms']\n",
        "                terms_df = pd.DataFrame(terms)\n",
        "                terms_df['response_id'] = value['id']  # Add response ID to track origin\n",
        "                terms_dataframes.append(terms_df)\n",
        "\n",
        "                # Extract the terms_relationship if available\n",
        "                terms_relationship = value['content'].get('terms_relationship', [])\n",
        "                if terms_relationship:\n",
        "                    terms_relationship_df = pd.DataFrame(terms_relationship)\n",
        "                    terms_relationship_df['response_id'] = value['id']  # Add response ID to track origin\n",
        "                    terms_relationship_dataframes.append(terms_relationship_df)\n",
        "\n",
        "            except KeyError as e:\n",
        "                print(f\"Error processing data from {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "# Concatenate all the terms DataFrames\n",
        "if terms_dataframes:\n",
        "    terms_p2_df = pd.concat(terms_dataframes, ignore_index=True)\n",
        "    print(\"Terms DataFrame:\")\n",
        "else:\n",
        "    print(\"No valid terms dataframes to concatenate.\")\n",
        "\n",
        "# Concatenate all the terms_relationship DataFrames\n",
        "if terms_relationship_dataframes:\n",
        "    relationship_p2_df = pd.concat(terms_relationship_dataframes, ignore_index=True)\n",
        "    print(\"Terms Relationship DataFrame:\")\n",
        "else:\n",
        "    print(\"No valid terms relationship dataframes to concatenate.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDsqzpVWNI4s"
      },
      "outputs": [],
      "source": [
        "terms_p2_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DESXKrD6NI4s"
      },
      "outputs": [],
      "source": [
        "terms_pred_df = pd.DataFrame(manager.retrieve_document(\"§ 275.0-2_P2\", doc_type=\"llm_response\").model_dump()[\"content\"][\"terms\"])\n",
        "\n",
        "terms_pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw9qldSINI4s"
      },
      "outputs": [],
      "source": [
        "terms_true_df = pd.DataFrame(manager.retrieve_document(\"§ 275.0-2_P2\", doc_type=\"true_table\").model_dump()[\"content\"][\"terms\"])\n",
        "\n",
        "terms_true_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bVxqVfvNI4s"
      },
      "outputs": [],
      "source": [
        "# List of document IDs to process\n",
        "document_ids_to_process_p1 = ['§ 275.0-2_P1|llm_response', '§ 275.0-5_P1|llm_response', '§ 275.0-7_P1|llm_response']\n",
        "document_ids_to_process_p2 = ['§ 275.0-2_P2|llm_response', '§ 275.0-5_P2|llm_response', '§ 275.0-7_P2|llm_response']\n",
        "\n",
        "table_pred_data_p1 = []\n",
        "table_pred_data_p2 = []\n",
        "# Loop through the directory and process each JSON file\n",
        "for filename in os.listdir(config['DEFAULT_CHECKPOINT_DIR']):\n",
        "    if filename.endswith(\".json\"):\n",
        "        file_path = os.path.join(config['DEFAULT_CHECKPOINT_DIR'], filename)\n",
        "        table_pred_data_p1 += process_documents_p1(file_path, filename, document_ids_to_process_p1)\n",
        "        table_pred_data_p2 += process_documents_p2(file_path, filename, document_ids_to_process_p2)\n",
        "\n",
        "# Convert collected data to a DataFrame\n",
        "table_pred_df_p1 = pd.DataFrame(table_pred_data_p1)\n",
        "table_pred_df_p2 = pd.DataFrame(table_pred_data_p2)\n",
        "\n",
        "# Save DataFrames to CSV if needed\n",
        "table_pred_df_p1.to_excel(f\"{config['DEFAULT_OUTPUT_DIR']}/P1_summary_table.xlsx\", index=False)\n",
        "table_pred_df_p2.to_excel(f\"{config['DEFAULT_OUTPUT_DIR']}/P2_summary_table.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5WlD0xoNI4s"
      },
      "source": [
        "Count of all runs in the checkpoints for P1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot59h2GMNI4t"
      },
      "outputs": [],
      "source": [
        "table_pred_df_p1.tail(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhRDDLZpNI4t"
      },
      "outputs": [],
      "source": [
        "table_pred_p1 = table_pred_df_p1.groupby('document_id').aggregate([\"min\", \"max\", \"sum\"])\n",
        "table_pred_p1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x4xgsrGNI4t"
      },
      "source": [
        "Count of all runs in the checkpoints for P2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRZWcY4XNI4t"
      },
      "outputs": [],
      "source": [
        "table_pred_df_p2.tail(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBswbIQlNI4t"
      },
      "outputs": [],
      "source": [
        "table_pred_p2 = table_pred_df_p2.groupby('document_id').describe()\n",
        "\n",
        "table_pred_p2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qp-q1IANI4t"
      },
      "source": [
        "Compare true tables with predicted tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blZaHtw0NI4t"
      },
      "outputs": [],
      "source": [
        "true_table = table_true_df_p1.groupby('document_id').describe()\n",
        "pred_table = table_pred_df_p1.groupby('document_id').describe()\n",
        "true_table.index = true_table.index.map(lambda x: x.replace(\"|true_table\", \"\"))  # Example: renaming '§' to 'Section'\n",
        "pred_table.index = pred_table.index.map(lambda x: x.replace(\"|llm_response\", \"\"))  # Example: renaming '§' to 'Section'\n",
        "\n",
        "true_table.compare(pred_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzxueoOoNI4u"
      },
      "outputs": [],
      "source": [
        "# Stop here. Next sections still in progress.\n",
        "raise SystemExit(\"Stop here. Next sections still in progress.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdT1w-z2NI4u"
      },
      "source": [
        "#### Evaluate documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifmxI73dNI4u"
      },
      "outputs": [],
      "source": [
        "for doc in manager.list_document_ids(doc_type=\"section\"):\n",
        "    logger.info(f\"Processing document: {doc}\")\n",
        "    retrieved_llm_response = manager.retrieve_document(doc_id=doc, doc_type=\"llm_response\")\n",
        "    true_table_doc = manager.retrieve_document(doc_id=doc, doc_type=\"true_table\")\n",
        "\n",
        "\n",
        "    logger.debug(retrieved_llm_response)\n",
        "\n",
        "    (\n",
        "        predicted_items,\n",
        "        predicted_dict,\n",
        "        correct_items,\n",
        "        correct_dict,\n",
        "        common_items,\n",
        "        missed_items,\n",
        "        extra_items,\n",
        "    ) = compare_items(doc, retrieved_llm_response.content, true_table_doc.content, \"signifier\", \"concept_classification\")\n",
        "\n",
        "    content = {\n",
        "        \"predicted_items\": predicted_items,\n",
        "        \"predicted_dict\": predicted_dict,\n",
        "        \"correct_items\": correct_items,\n",
        "        \"correct_dict\": correct_dict,\n",
        "        \"common_items\": common_items,\n",
        "        \"missed_items\": missed_items,\n",
        "        \"extra_items\": extra_items\n",
        "    }\n",
        "\n",
        "    # Save statistics\n",
        "    document = Document(\n",
        "        id=doc,\n",
        "        type=\"statistics\",\n",
        "        content=content\n",
        "    )\n",
        "\n",
        "\n",
        "    logger.debug(document)\n",
        "\n",
        "    # Save statistics\n",
        "    manager.add_document(document)\n",
        "\n",
        "    logger.info(\"Saving statistics to checkpoint...\")\n",
        "    save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)\n",
        "\n",
        "    # Save metrics to excel for further analysis\n",
        "    save_compare_items_metrics(\n",
        "        doc,\n",
        "        len(correct_items),\n",
        "        len(predicted_items),\n",
        "        len(common_items),\n",
        "        len(missed_items),\n",
        "        len(extra_items),\n",
        "        len(common_items) / len(correct_items),\n",
        "        len(common_items) / len(predicted_items),\n",
        "        2 * len(common_items) / (len(correct_items) + len(predicted_items)),\n",
        "        #file_name=f'../outputs/section_{doc.replace(\".\", \"_\").replace(\"-\", \"_\")}_validation_metrics.xlsx'\n",
        "        file_name=config[\"DEFAULT_EXCEL_FILE\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZMeh1E6NI4u",
        "outputId": "a22bc9dd-d66a-4d7e-94bf-e9d8c187894d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:10:59 - INFO - Checkpoint restored from ../checkpoints/documents-2024-10-29-1.json.\n"
          ]
        }
      ],
      "source": [
        "# Restore checkpoint\n",
        "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-tc7C_GNI4u"
      },
      "source": [
        "#### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVjc4h1RNI4u"
      },
      "outputs": [],
      "source": [
        "for doc in manager.list_document_ids(doc_type=\"statistics\"):\n",
        "    logger.info(f\"Processing document: {doc}\")\n",
        "    retrieved_statistics = manager.retrieve_document(doc_id=doc, doc_type=\"statistics\")\n",
        "\n",
        "    logger.debug(retrieved_statistics)\n",
        "\n",
        "    predicted_dict = retrieved_statistics.content[\"predicted_dict\"]\n",
        "    predicted_items = retrieved_statistics.content[\"predicted_items\"]\n",
        "    correct_items = retrieved_statistics.content[\"correct_items\"]\n",
        "    correct_dict = retrieved_statistics.content[\"correct_dict\"]\n",
        "\n",
        "    report = plot_confusion_matrix(predicted_items, predicted_dict, correct_items, correct_dict)\n",
        "\n",
        "    # Save statistics\n",
        "    document = Document(\n",
        "        id=doc,\n",
        "        type=\"classification_report\",\n",
        "        content=report\n",
        "    )\n",
        "\n",
        "\n",
        "    logger.debug(document)\n",
        "\n",
        "    # Save statistics\n",
        "    manager.add_document(document)\n",
        "\n",
        "save_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"], manager=manager)\n",
        "logger.info(\"Statistic's checkpoint saved...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBSCnEIXNI4v"
      },
      "source": [
        "#### Generate report\n",
        "\n",
        "Generate report with the content of an checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZOEZaySNI4v"
      },
      "outputs": [],
      "source": [
        "generate_report(config[\"DEFAULT_CHECKPOINT_FILE\"], config[\"DEFAULT_EXTRACTION_REPORT_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sma6Fz3NI4v"
      },
      "source": [
        "### define vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3OeVGlgNI4v"
      },
      "source": [
        "#### General functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VofSvmjNI4v"
      },
      "outputs": [],
      "source": [
        "def remove_section_symbol(input_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes the '§' symbol from the input string and trims whitespace.\n",
        "\n",
        "    Args:\n",
        "        input_string (str): The string from which to remove the '§' symbol.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned string without the '§' symbol and leading/trailing whitespace.\n",
        "\n",
        "    Raises:\n",
        "        TypeError: If 'input_string' is not a string.\n",
        "    \"\"\"\n",
        "    if not isinstance(input_string, str):\n",
        "        raise TypeError(\"input_string must be a string\")\n",
        "    return input_string.replace(\"§\", \"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEn3b6oSNI4x"
      },
      "outputs": [],
      "source": [
        "def define_vocabulary(section_id: str, source_section: str) -> str:\n",
        "    \"\"\"\n",
        "    Determines the vocabulary section ID based on the term's source section.\n",
        "\n",
        "    Args:\n",
        "        section_id (str): The section ID of the current document.\n",
        "        source_section: The section id.\n",
        "\n",
        "    Returns:\n",
        "        str: The appropriate vocabulary section ID.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If 'source' or 'section' key is missing in the term.\n",
        "        TypeError: If 'section_id' is not a string or 'term' is not a dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    # if not isinstance(section_id, str):\n",
        "    #     raise TypeError(\"section_id must be a string\")\n",
        "    # if not isinstance(term, dict):\n",
        "    #     raise TypeError(\"term must be a dictionary\")\n",
        "    # if \"sources\" not in term or \"section\" not in term[\"source\"]:\n",
        "    #     raise KeyError(\"term must contain 'source' with 'section'\")\n",
        "\n",
        "    section_id = remove_section_symbol(section_id)\n",
        "\n",
        "    try:\n",
        "        term_section_id = remove_section_symbol(source_section)\n",
        "    except KeyError:\n",
        "        term_section_id = section_id\n",
        "\n",
        "    return section_id if term_section_id == section_id else term_section_id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNMcOF3gNI4x"
      },
      "source": [
        "#### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g09WY5TLNI4x"
      },
      "outputs": [],
      "source": [
        "\n",
        "correct_dict = {}\n",
        "predicted_dict = {}\n",
        "for doc in manager.list_document_ids(doc_type=\"llm_response\"):\n",
        "    logger.info(f\"Processing document: {doc} ...\")\n",
        "    retrieved_llm_response = manager.retrieve_document(doc_id=doc, doc_type=\"llm_response\")\n",
        "    retrieved_true_table = manager.retrieve_document(doc_id=doc, doc_type=\"true_table\")\n",
        "\n",
        "    correct_dict.update({item['signifier']: item.get(\"sources\")[0][\"section\"] for item in retrieved_true_table.content})\n",
        "    predicted_dict.update({item['signifier']: item.get(\"sources\")[0][\"section\"] for item in retrieved_llm_response.content})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYQDa6BZNI4x"
      },
      "outputs": [],
      "source": [
        "# Identify Common and Unique Signifiers\n",
        "# Get sets of signifiers\n",
        "correct = set(correct_dict.keys())\n",
        "predicted = set(predicted_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbwew5K2NI4y"
      },
      "outputs": [],
      "source": [
        "# Assuming correct_dict and predicted_dict are already defined\n",
        "comparison_results = []\n",
        "\n",
        "for term in correct.union(predicted):\n",
        "    correct_section = correct_dict.get(term)\n",
        "    predicted_section = predicted_dict.get(term)\n",
        "\n",
        "    # Determine if types match\n",
        "    type_match = correct_section == predicted_section\n",
        "\n",
        "    # Append to comparison_results\n",
        "    comparison_results.append({\n",
        "        'Term': term,\n",
        "        'Correct source': correct_section,\n",
        "        'Predicted source': predicted_section,\n",
        "        'Section Match': type_match\n",
        "    })\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(comparison_results)\n",
        "\n",
        "# Create the confusion matrix\n",
        "confusion_matrix = pd.crosstab(\n",
        "    df['Correct source'],\n",
        "    df['Predicted source'],\n",
        "    rownames=['Actual'],\n",
        "    colnames=['Predicted'],\n",
        "    margins=True\n",
        ")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "cm = confusion_matrix.iloc[:-1, :-1] if 'All' in confusion_matrix.index else confusion_matrix\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix of source predictions')\n",
        "plt.ylabel('Actual source')\n",
        "plt.xlabel('Predicted source')\n",
        "plt.show()\n",
        "\n",
        "# Replace None values with a placeholder\n",
        "df['Correct source'].fillna('Unknown', inplace=True)\n",
        "df['Predicted source'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Prepare data for classification report\n",
        "types = sorted(set(df['Correct source']) | set(df['Predicted source']))\n",
        "type_to_int = {t: i for i, t in enumerate(types)}\n",
        "\n",
        "y_true = df['Correct source'].map(type_to_int)\n",
        "y_pred = df['Predicted source'].map(type_to_int)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=types))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4IAe8BoNI4y"
      },
      "source": [
        "### similarity search (P5)\n",
        "\n",
        "Try a similarity search to find the entity in the graph. If not found, create a new entity and corresponding embedding. If exists, create a link between the two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHdi64yjNI4y"
      },
      "source": [
        "Use similarity search to find similar terms in the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rSO41w9NI4y"
      },
      "source": [
        "#### General functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7L7Dy4lNI4y"
      },
      "outputs": [],
      "source": [
        "def signifier_sources(sources: list) -> list:\n",
        "    \"\"\"\n",
        "    Extract desgnations sources\n",
        "\n",
        "    Args:\n",
        "        sources (list): List of sources\n",
        "\n",
        "    Returns:\n",
        "        list: List of sources\n",
        "    \"\"\"\n",
        "    # Extract desgnations sources\n",
        "    sources_lst = []\n",
        "    for source in sources:\n",
        "        source_section = str(source.get(\"section\"))\n",
        "        source_paragraph = str(source.get(\"paragraph\"))\n",
        "        sources_lst.append(source_section + source_paragraph)\n",
        "    return sources_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_dRKz-pNI4y"
      },
      "outputs": [],
      "source": [
        "def transform_title_cased(input_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Transform the input string to title case, which capitalizes the first letter of each word.\n",
        "\n",
        "    Args:\n",
        "        input_string (str): The string to transform.\n",
        "\n",
        "    Returns:\n",
        "        title_case_string (str): The transformed string.\n",
        "    \"\"\"\n",
        "    title_case_string = input_string.title()\n",
        "    # Remove all spaces\n",
        "    transformed_string = title_case_string.replace(\" \", \"\")\n",
        "    return transformed_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TM7dUR3NI4y"
      },
      "outputs": [],
      "source": [
        "def normalize_ns_string(input_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Transform the input string to title case, which capitalizes the first letter of each word.\n",
        "\n",
        "    Args:\n",
        "        input_string (str): The string to normalize.\n",
        "\n",
        "    Returns:\n",
        "        normalized_string (str): The normalized string.\n",
        "    \"\"\"\n",
        "    normalized_string = remove_section_symbol(input_string)\n",
        "\n",
        "    # Remove all spaces, change points and hyphens to underscores\n",
        "    return normalized_string.replace(\" \", \"\").replace(\"-\", \"_\").replace(\".\", \"_\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e_XBAX2NI4y"
      },
      "outputs": [],
      "source": [
        "def upsert_fact_to_kg(conn, fact):\n",
        "    \"\"\"\n",
        "    Add a fact to the knowledge graph. If exists, replace it.\n",
        "    Context:\n",
        "        Facts build on concepts: Facts are statements or assertions about the relationships\n",
        "        between these concepts. They describe how terms relate to each other in specific ways.\n",
        "        Example \"A customer places an order.\".\n",
        "\n",
        "    Args:\n",
        "        conn (Connection): The connection to the knowledge graph database.\n",
        "        fact (str): The fact to add to the knowledge graph.\n",
        "\n",
        "    Returns:\n",
        "        True if the fact was added successfully, False otherwise.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpO_2y8mNI4z"
      },
      "outputs": [],
      "source": [
        "def upsert_rule_to_kg(conn: RepositoryConnection, fact:Dict[str, Any]) -> bool:\n",
        "    \"\"\"\n",
        "    Add a rule to the knowledge graph. If exists, replace it.\n",
        "\n",
        "    Context:\n",
        "        Rules build on facts: Rules are constructed based on these facts to enforce\n",
        "        certain conditions, constraints, or actions within the business.\n",
        "        Rules dictate what must or must not happen under certain circumstances by referencing\n",
        "        the relationships described by facts\n",
        "        Example \"A customer must not place more than one order at a time.\"\n",
        "    Args:\n",
        "        conn (RepositoryConnection): The connection to the knowledge graph database.\n",
        "        fact (str): The fact to add to the knowledge graph.\n",
        "\n",
        "    Returns:\n",
        "        True if the rule was added successfully, False otherwise.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNo_T4tLNI4z"
      },
      "outputs": [],
      "source": [
        "class Designation(BaseModel):\n",
        "    signifier: str\n",
        "    expression: str\n",
        "    concept_type: str\n",
        "    closeMatch: Optional[List[str]]\n",
        "    exactMatch: Optional[List[str]]\n",
        "    vocabulary_name: str\n",
        "    sources: Optional[List[str]]\n",
        "\n",
        "def upsert_designation_to_kg(conn: RepositoryConnection, designation: Designation) -> bool:\n",
        "    \"\"\"\n",
        "    Add a term to the knowledge graph. If exists, replace it.\n",
        "\n",
        "    Args:\n",
        "        conn (RepositoryConnection): The connection to the knowledge graph database.\n",
        "        term (Term): The term to add to the knowledge graph.\n",
        "\n",
        "    Returns:\n",
        "        True if the term was added successfully, False otherwise.\n",
        "    \"\"\"\n",
        "    signifier = designation.signifier\n",
        "    expression = designation.expression\n",
        "    designation_class = transform_title_cased(signifier)\n",
        "    concept_type = designation.concept_type\n",
        "    vocabulary_namespace = f\"cfr-sbvr:CFR_SBVR_{designation.vocabulary_name}_NS\"\n",
        "\n",
        "    if concept_type == \"IndividualNounConcept\":\n",
        "        designation_type = \"Name\"\n",
        "    else:\n",
        "        designation_type = \"Term\"\n",
        "\n",
        "    logger.info(f\"Format {signifier} to {designation_class}.\")\n",
        "\n",
        "    # Constructing closeMatch triples\n",
        "    close_matches_triples = \"\"\n",
        "    if designation.closeMatch:\n",
        "        for close_match in designation.closeMatch:\n",
        "            close_matches_triples += f\"sbvr:closeMatch {close_match} ;\\n\"\n",
        "\n",
        "    # Construct exactMatch triple if exactMatch is provided\n",
        "    exact_match_triples = \"\"\n",
        "    if designation.exactMatch:\n",
        "        for exact_match in designation.exactMatch:\n",
        "            exact_match_triples += f\"sbvr:exactMatch {exact_match} ;\\n\"\n",
        "\n",
        "    # Construct surces triple if sources is provided\n",
        "    sources_triples = \"\"\n",
        "    if designation.sources:\n",
        "        for source in designation.sources:\n",
        "            sources_triples += f'sbvr:referenceSupportsMeaning \"{source}\" ;\\n'\n",
        "\n",
        "    designation_upsert_query = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "WITH cfr-sbvr:CFR_SBVR\n",
        "DELETE {{\n",
        "    cfr-sbvr:{designation_class} ?p ?o .\n",
        "}}\n",
        "INSERT {{\n",
        "    cfr-sbvr:{designation_class} a sbvr:{designation_type},\n",
        "            sbvr:IntensionalDefinition,\n",
        "            sbvr:{concept_type} ;\n",
        "        sbvr:signifier \"{signifier}\" ;\n",
        "        {exact_match_triples}\n",
        "        {close_matches_triples}\n",
        "        {sources_triples}\n",
        "        sbvr:isImplicitlyUnderstood \"false\"^^xsd:boolean ;\n",
        "        sbvr:expression \"{expression}\" ;\n",
        "        sbvr:designationIsInNamespace {vocabulary_namespace} .\n",
        "}}\n",
        "WHERE {{\n",
        "    # Match all existing triples related to {designation_class}\n",
        "    OPTIONAL {{ cfr-sbvr:{designation_class} ?p ?o . }}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    logger.debug(f\"SPARQL Query: {designation_upsert_query}\")\n",
        "\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, designation_upsert_query).evaluate()\n",
        "        logger.info(f\"Designation '{signifier}' upserted successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to upsert designation {signifier}: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbOnR825NI4z"
      },
      "outputs": [],
      "source": [
        "def create_vocabulary(conn: RepositoryConnection, vocabulary_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Create a new vocabulary in the knowledge graph.\n",
        "\n",
        "    Args:\n",
        "        conn (RepositoryConnection): The connection to the knowledge graph database.\n",
        "        vocabulary (str): The name of the vocabulary to create.\n",
        "\n",
        "    Returns:\n",
        "        True if the vocabulary was created successfully, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    query_remove_association = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "DELETE DATA {{\n",
        "GRAPH cfr-sbvr:CFR_SBVR {{\n",
        "    cfr-sbvr:CFR_SBVR_VOC sbvr:vocabulary1IncorporatesVocabulary2 cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC .\n",
        "}}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    query_add_triples = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "WITH cfr-sbvr:CFR_SBVR\n",
        "DELETE {{\n",
        "    cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC ?p ?o .\n",
        "}}\n",
        "\n",
        "INSERT {{\n",
        "    cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC\n",
        "        a owl:Class, sbvr:Vocabulary .\n",
        "}}\n",
        "WHERE {{\n",
        "    # Match all existing triples related to cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC\n",
        "    OPTIONAL {{ cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC ?p ?o . }}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    query_add_association = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "INSERT DATA {{\n",
        "GRAPH cfr-sbvr:CFR_SBVR {{\n",
        "    cfr-sbvr:CFR_SBVR_VOC sbvr:vocabulary1IncorporatesVocabulary2 cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC .\n",
        "}}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    logger.debug(f\"SPARQL Query: {query_remove_association}\")\n",
        "\n",
        "    logger.debug(f\"SPARQL Query: {query_add_triples}\")\n",
        "\n",
        "    logger.debug(f\"Vocabulary name: cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC\")\n",
        "\n",
        "    # Remove associated vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_remove_association).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} delete associated successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to delete associated vocabulary {vocabulary_name}: {e}\")\n",
        "\n",
        "    # create new vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_add_triples).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} created successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create vocabulary {vocabulary_name}: {e}\")\n",
        "\n",
        "    # Add association with new vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_add_association).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} associated successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to associate vocabulary {vocabulary_name}: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D7MiyhJNI4z"
      },
      "outputs": [],
      "source": [
        "def create_vocabulary_namespace(conn: RepositoryConnection, vocabulary_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Create a new vocabulary namespace in the knowledge graph.\n",
        "\n",
        "    Args:\n",
        "        conn (RepositoryConnection): The connection to the knowledge graph database.\n",
        "        vocabulary_namespace (str): The name of the vocabulary namespace to create.\n",
        "\n",
        "    Returns:\n",
        "        True if the vocabulary namespace was created successfully, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    query_remove_association = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "DELETE DATA {{\n",
        "GRAPH cfr-sbvr:CFR_SBVR {{\n",
        "    cfr-sbvr:CFR_SBVR_NS sbvr:namespace1IncorporatesNamespace2 cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS .\n",
        "}}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    query_add_triples = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "PREFIX dct: <http://purl.org/dc/terms/>\n",
        "\n",
        "WITH cfr-sbvr:CFR_SBVR\n",
        "DELETE {{\n",
        "    cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS ?p ?o .\n",
        "}}\n",
        "\n",
        "INSERT {{\n",
        "cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS\n",
        "        a owl:Class, sbvr:VocabularyNamespace;\n",
        "    sbvr:namespaceHasURI <http://cfr2sbvr.com/cfr/CFR_SBVR_{vocabulary_name}_NS#> ;\n",
        "    sbvr:vocabularyIsExpressedInLanguage cfr-sbvr:EnglishLanguage ;\n",
        "    sbvr:vocabularyNamespaceIsDerivedFromVocabulary cfr-sbvr:CFR_SBVR_{vocabulary_name}_VOC ;\n",
        "    dct:title \"Semantics of Business Vocabulary and Business Rules (SBVR) for Code of Federal Regulations (CFR)\" ;\n",
        "    skos:definition \"SBVR-CFR is an adopted standard of the Object Management Group (OMG) intended to be the basis for formal and detailed natural language declarative description of CFR regulations\" ;\n",
        "    dct:source <https://github.com/asantos2000/dissertacao-santos-anderson-2024> .\n",
        "}}\n",
        "WHERE {{\n",
        "    # Match all existing triples related to cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS\n",
        "    OPTIONAL {{ cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS ?p ?o . }}\n",
        "}}\n",
        "    \"\"\"\n",
        "    query_add_association = f\"\"\"\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "\n",
        "INSERT DATA {{\n",
        "GRAPH cfr-sbvr:CFR_SBVR {{\n",
        "    cfr-sbvr:CFR_SBVR_NS sbvr:namespace1IncorporatesNamespace2 cfr-sbvr:CFR_SBVR_{vocabulary_name}_NS .\n",
        "}}\n",
        "}}\n",
        "    \"\"\"\n",
        "\n",
        "    logger.debug(f\"SPARQL Query: {query_remove_association}\")\n",
        "    logger.debug(f\"SPARQL Query: {query_add_triples}\")\n",
        "    logger.debug(f\"SPARQL Query: {query_add_association}\")\n",
        "\n",
        "    # Remove associated vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_remove_association).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} delete associated successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to delete associated vocabulary {vocabulary_name}: {e}\")\n",
        "\n",
        "    # create new vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_add_triples).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} created successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to create vocabulary {vocabulary_name}: {e}\")\n",
        "\n",
        "    # Add association with new vocabulary\n",
        "    try:\n",
        "        conn.prepareUpdate(QueryLanguage.SPARQL, query_add_association).evaluate()\n",
        "        logger.info(f\"Vocabulary {vocabulary_name} associated successfully.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to associate vocabulary {vocabulary_name}: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlAtLdl6NI4z"
      },
      "outputs": [],
      "source": [
        "def get_from_kg(conn: RepositoryConnection, signifier: str, kg: str, vector_db: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Queries the knowledge graph to retrieve similar terms to the given term.\n",
        "\n",
        "    Args:\n",
        "        conn (RepositoryConnection): The AllegroGraph repository connection.\n",
        "        term (str): The term to search for similar terms in the knowledge graph.\n",
        "        kg (str): The name of the knowledge graph to query.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, Any]]: A list of dictionaries containing information about similar terms,\n",
        "        including URIs, scores, definitions, and related predicates.\n",
        "    \"\"\"\n",
        "\n",
        "    if kg not in {config[\"FIBO_GRAPH\"], config[\"CFR_SBVR_GRAPH\"]}:\n",
        "        raise ValueError(f\"Unsupported knowledge graph: {kg}\")\n",
        "\n",
        "    query_string = f\"\"\"\n",
        "PREFIX llm: <http://franz.com/ns/allegrograph/8.0.0/llm/>\n",
        "PREFIX fibo: <https://spec.edmcouncil.org/fibo/ontology/master/2024Q2/QuickFIBOProd#>\n",
        "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
        "PREFIX cfr-sbvr: <http://cfr2sbvr.com/cfr#>\n",
        "PREFIX sbvr: <https://www.omg.org/spec/SBVR/20190601#>\n",
        "\n",
        "SELECT ?uri (xsd:decimal(?score) as ?score_percent) ?s ?p ?definition\n",
        "FROM {kg}\n",
        "WHERE {{\n",
        "    (?uri ?score ?originalText ?p) llm:nearestNeighbor (\"{signifier}\" \"{vector_db}\" 5 0.8) .\n",
        "    ?s ?p ?originalText .\n",
        "\n",
        "    OPTIONAL {{ ?s skos:definition ?definition . }}\n",
        "    OPTIONAL {{ ?s sbvr:expression ?definition . }}\n",
        "}}\n",
        "ORDER BY DESC(?score)\n",
        "    \"\"\"\n",
        "\n",
        "    logger.debug(f\"SPARQL Query: {query_string}\")\n",
        "\n",
        "    tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
        "\n",
        "    try:\n",
        "        result = tuple_query.evaluate()\n",
        "        logger.debug(f\"Result metadata: {result.metadata}\")\n",
        "\n",
        "        with result:\n",
        "            similar_signifiers = [\n",
        "                {\n",
        "                    \"uri\": str(binding.getValue(\"uri\")),\n",
        "                    \"score_percent\": Decimal(binding.getValue(\"score_percent\").getLabel()),\n",
        "                    \"located_signifier_uri\": str(binding.getValue(\"s\")),\n",
        "                    \"located_signifier_uri_local_name\": binding.getValue(\"s\").getLocalName(),\n",
        "                    \"located_signifier_predicate\": str(binding.getValue(\"p\")),\n",
        "                    \"definition\": str(binding.getValue(\"definition\"))\n",
        "                }\n",
        "                for binding in result\n",
        "            ]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error evaluating SPARQL query: {e}\")\n",
        "        raise\n",
        "\n",
        "    logger.info(f\"Found {len(similar_signifiers)} similar signifier(s) for '{signifier}' on {kg}.\")\n",
        "\n",
        "    return similar_signifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0070OunMNI4z"
      },
      "outputs": [],
      "source": [
        "def get_similar_signifiers(conn: RepositoryConnection, signifier: str) -> Tuple[list]:\n",
        "    \"\"\"\n",
        "    Get similar signifiers for a given signifier.\n",
        "\n",
        "    Args:\n",
        "        conn (allegrograph.AllegroGraphConnection): An AllegroGraph connection object.\n",
        "        signifier (str): The signifier to search for.\n",
        "\n",
        "    Returns:\n",
        "        list (Tuple[list]): A list of exact and close matches for the signifier.\n",
        "    \"\"\"\n",
        "    fibo_similarity =  get_from_kg(conn, signifier, config[\"FIBO_GRAPH\"], config[\"FIBO_GRAPH_VECTOR_STORE\"])\n",
        "    cfr_sbvr_similarity = get_from_kg(conn, signifier, config[\"CFR_SBVR_GRAPH\"], config[\"CFR_SBVR_GRAPH_VECTOR_STORE\"])\n",
        "\n",
        "    exact_match = []\n",
        "    close_match = []\n",
        "\n",
        "    for item in fibo_similarity:\n",
        "        if item[\"score_percent\"] > config[\"SIMILARITY_THRESHOLD\"]:\n",
        "            exact_match.append(item.get(\"located_signifier_uri\"))\n",
        "        else:\n",
        "            close_match.append(item.get(\"located_signifier_uri\"))\n",
        "\n",
        "    for item in cfr_sbvr_similarity:\n",
        "        if item[\"score_percent\"] > config[\"SIMILARITY_THRESHOLD\"]:\n",
        "            exact_match.append(item.get(\"located_signifier_uri\"))\n",
        "        else:\n",
        "            close_match.append(item.get(\"located_signifier_uri\"))\n",
        "\n",
        "    logger.info(f\"Found {len(exact_match)} exact matche(s) and {len(close_match)} close matche(s) for '{signifier}'.\")\n",
        "\n",
        "    return exact_match, close_match\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00kWNyS2NI40",
        "outputId": "ab4484f8-9545-49b1-b72c-bcca73b11bee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-29 11:13:12 - INFO - Checkpoint restored from ../checkpoints/documents-2024-10-29-1.json.\n"
          ]
        }
      ],
      "source": [
        "# Restore checkpoint\n",
        "manager = restore_checkpoint(filename=config[\"DEFAULT_CHECKPOINT_FILE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojyl6o8xNI40"
      },
      "source": [
        "### Main\n",
        "\n",
        "Orchestrates the process of the semantic annotation.\n",
        "\n",
        "Processing terms, names, vocabularies and vocabulary namespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JWZtF79NI40",
        "outputId": "71bffd99-0893-4a2a-9713-71d7366a987d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ag_connect' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Connect to AllegroGraph\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mag_connect\u001b[49m(\n\u001b[1;32m      3\u001b[0m     repo\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPO\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m     catalog\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCATALOG\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     host\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHOST\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     port\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPORT\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m     user\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     password\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALLEGROGRAPH_CLOUD\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPASSWORD\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ag_connect' is not defined"
          ]
        }
      ],
      "source": [
        "# Connect to AllegroGraph\n",
        "conn = ag_connect(\n",
        "    repo=config[\"ALLEGROGRAPH_CLOUD\"][\"REPO\"],\n",
        "    catalog=config[\"ALLEGROGRAPH_CLOUD\"][\"CATALOG\"],\n",
        "    host=config[\"ALLEGROGRAPH_CLOUD\"][\"HOST\"],\n",
        "    port=config[\"ALLEGROGRAPH_CLOUD\"][\"PORT\"],\n",
        "    user=config[\"ALLEGROGRAPH_CLOUD\"][\"USER\"],\n",
        "    password=config[\"ALLEGROGRAPH_CLOUD\"][\"PASSWORD\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "femfZSwYNI40"
      },
      "outputs": [],
      "source": [
        "for doc in manager.list_document_ids(doc_type=\"llm_response\"):\n",
        "    logger.info(f\"Processing document: {doc} ...\")\n",
        "    retrieved_llm_response = manager.retrieve_document(doc_id=doc, doc_type=\"llm_response\")\n",
        "\n",
        "    for response in retrieved_llm_response.content:\n",
        "\n",
        "        logger.debug(response)\n",
        "\n",
        "        signifier = response['signifier']\n",
        "        expression = response['definition']\n",
        "        concept_type = response['concept_classification']\n",
        "        sources = response.get(\"sources\")\n",
        "\n",
        "        logger.info(f\"Processing '{signifier}' ...\")\n",
        "\n",
        "        # define vocabulary\n",
        "        # Assume first occorrence of section is the correct section\n",
        "        # In case do not have section, use section_id.\n",
        "        # TODO: Improve this\n",
        "        vocabulary = define_vocabulary(doc, sources[0][\"section\"])\n",
        "        vocabulary = normalize_ns_string(vocabulary)\n",
        "\n",
        "        logger.info(f\"Processing vocabulary {vocabulary}\")\n",
        "\n",
        "        if create_vocabulary(conn, vocabulary):\n",
        "            logger.info(f\"Vocabulary {vocabulary} upserted\")\n",
        "            if create_vocabulary_namespace(conn, vocabulary):\n",
        "                logger.info(f\"Vocabulary namespace {vocabulary} upserted\")\n",
        "            else:\n",
        "                logger.info(f\"Vocabulary namespace {vocabulary} not upserted\")\n",
        "        else:\n",
        "            logger.info(f\"Vocabulary {vocabulary} not upserted\")\n",
        "\n",
        "        # similar search\n",
        "        exact_match, close_match = get_similar_signifiers(conn, signifier)\n",
        "\n",
        "        # create designation\n",
        "        designation = Designation(\n",
        "            signifier=signifier,\n",
        "            expression=expression,\n",
        "            concept_type=concept_type,\n",
        "            closeMatch=close_match,\n",
        "            exactMatch=exact_match,\n",
        "            vocabulary_name=vocabulary,\n",
        "            sources=signifier_sources(sources) # Associate desgnations the their sources\n",
        "        )\n",
        "\n",
        "        upsert_designation_to_kg(conn, designation)\n",
        "\n",
        "        logger.debug(f\"Processed {designation}\")\n",
        "        logger.info(f\"Signifier '{signifier}' done.\")\n",
        "\n",
        "    logger.info(f\"{doc} done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EVdyCMYNI40"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR_XeDEjNI40"
      },
      "source": [
        "## Notes\n",
        "\n",
        "- Kernel conda environment: ipt-cfr2sbvr - Python version 3.11.9"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ipt-cfr2sbvr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}